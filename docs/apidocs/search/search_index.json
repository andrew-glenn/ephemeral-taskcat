{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"https://aws-ia.github.io Installation Usage Support What is taskcat? taskcat is a tool that tests AWS CloudFormation templates. It deploys your AWS CloudFormation template in multiple AWS Regions and generates a report with a pass/fail grade for each region. You can specify the regions and number of Availability Zones you want to include in the test, and pass in parameter values from your AWS CloudFormation template. taskcat is implemented as a Python class that you import, instantiate, and run. taskcat was developed by the aws-ia team to test AWS CloudFormation templates that automatically deploy workloads on AWS. We\u2019re pleased to make the tool available to all developers who want to validate their custom AWS CloudFormation templates across AWS Regions Support Installation Currently only installation via pip is supported. Installation via docker coming soon. Requirements The host taskcat is run on requires access to an AWS account, this can be done by any of the following mechanisms: Environment variables Shared credential file (~/.aws/credentials) AWS config file (~/.aws/config) Assume Role provider Boto2 config file (/etc/boto.cfg and ~/.boto) Instance metadata service on an Amazon EC2 instance that has an IAM role configured. for more info see the boto3 credential configuration documentation . Note: docker is only required if building lambda functions using a Dockerfile Installing via pip3 pip3 install taskcat Installing via pip3 --user will install taskcat into homedir, useful if you get permissions errors with the regular method pip3 install taskcat --user Note: the user install dir is platform specific For Example: (On Mac: ~/Library/Python/3.x/bin/taskcat) For Example: (On Linux: ~/.local/bin) Warning: Be sure to add the python bin dir to your $PATH Windows taskcat on Windows is not supported . If you are running Windows 10 we recommend that you install Windows Subsystem for Linux (WSL) and then install taskcat inside the WSL environment using the steps above. Usage CLI The cli is self documenting by using --help . The most common use of taskcat is for executing function tests of CloudFormation templates. The command for this is: taskcat test run add --help to see the supported flags and arguments Python Taskcat can be imported into Python and used in the testing framework of your choice. from taskcat.testing import CFNTest test = CFNTest . from_file ( project_root = './template_dir' ) with test as stacks : # Calling 'with' or 'test.run()' will deploy the stacks. for stack in stacks : print ( f \"Testing { stack . name } \" ) bucket_name = \"\" for output in stack . outputs : if output . key == \"LogsBucketName\" : bucket_name = output . value break assert \"logs\" in bucket_name assert stack . region . name in bucket_name print ( f \"Created bucket: { bucket_name } \" ) The example used here is very simple, you would most likely leverage other python modules like boto3 to do more advanced testing. The CFNTest object can be passed the same arguments as taskcat test run . See the docs for more details. Config files taskcat has several configuration files which can be used to set behaviors in a flexible way. Global config ~/.taskcat.yml provides global settings that become defaults for all projects. # General configuration settings general auth # AWS authentication section < AUTH_NAME > parameters : # Parameter key-values to pass to cfn (global parameters take precedence) < PARAMETER_NAME > s3_bucket : # Name of S3 bucket to upload project to (if left out a bucket will be auto-generated) s3_regional_buckets : # Boolean flag to upload the project to a bucket (generated in each region specified) tags : # Tags to apply to CloudFormation template TAG_NAME Project config File location: /.taskcat.yml` provides project specific configuration. project # Project specific configuration section auth # AWS authentication section < AUTH_NAME > az_blacklist # List of Availability Zones ID's to exclude when generating availability zones build_submodules # Build Lambda zips recursively for submodules, set to false to disable lambda_source_path # Path relative to the project root containing Lambda zip files, default is 'lambda_functions/source' lambda_zip_path # Path relative to the project root to place Lambda zip files, default is 'lambda_functions/zips' name # Project name, used as s3 key prefix when uploading objects owner # Email address for project owner (not used at present) package_lambda # Package Lambda functions into zips before uploading to s3, set to false to disable parameters # Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence < PARAMETER_NAME > regions # List of AWS regions s3_bucket # Name of S3 bucket to upload project to, if left out a bucket will be auto-generated s3_enable_sig_v2 # Enable (deprecated) sigv2 access to auto-generated buckets s3_object_acl # ACL for uploaded s3 objects, defaults to 'private' tags # Tags to apply to CloudFormation template < TAG_NAME > template # path to template file relative to the project config file path tests : auth # AWS authentication section < AUTH_NAME > az_blacklist # List of Availability Zones ID's to exclude when generating availability zones parameters # Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence < PARAMETER_NAME > regions # List of AWS regions s3_bucket # Name of S3 bucket to upload project to, if left out a bucket will be auto-generated tags # Tags to apply to CloudFormation template < TAG_NAME > template # Path to template file relative to the project config file path > At minimum it must provide a project name , list of regions , template name and one test . Minimal example : ``` yaml project : name : my - cfn - project regions : - us - west - 2 - eu - north - 1 tests : default : template : ./ templates / my - template . yaml Complete example with comments: tests/data/config_full_example/.taskcat.yml Parameter overrides a parameter override file can be created in <PROJECT_ROOT>/.taskcat_overrides.yml . Parameter Keys/Values specified in this file take precedence over values defined in all other configuration files. For example: KeyPair : my-overriden-keypair VpcId : vpc-1234abcd Warning: it is recommended to add .taskcat_overrides.yml to .gitignore to ensure it is not accidentally checked into source control Precedence With the exception of the parameters section, more specific config with the same key takes precedence. The rationale behind having parameters function this way is so that values can be overridden at a system level outside of a project, that is likely committed to source control. parameters that define account specific things like VPC details, Key Pairs, or secrets like API keys can be defined per host outside of source control. For example, consider this global config: ~/.taskcat.yml general : s3_bucket : my-globally-defined-bucket parameters : KeyPair : my-global-ec2-keypair Given a simple project config: project : name : my-project regions : - us-east-2 tests : default : template : ./template.yaml The effective test configuration would become: tests : default : template : ./template.yaml s3_bucket : my-globally-defined-bucket parameters : KeyPair : my-global-ec2-keypair If any item is re-defined in a project it takes precedence over the global value. Anything defined in a test takes precedence over what is defined in the project or global configuration. with the exception of the parameters section which works in reverse. For example, using the same global config as above, given this project config: project : name : my-project regions : - us-east-2 s3_bucket : my-project-s3-bucket tests : default : template : ./template.yaml parameters : KeyPair : my-test-ec2-keypair Would result in this effective test configuration: tests : default : template : ./template.yaml s3_bucket : my-project-s3-bucket parameters : KeyPair : my-global-ec2-keypair Notice that s3_bucket took the most specific value and KeyPair the most general. CLI interface taskcat adopts a similar cli command structure to git with a taskcat command subcommand --flag style. The cli is also designed to be simplest if run from the root of a project. Let's have a look at equivalent command to run a test: cd into the project root and type test run : cd ./quickstart-aws-vpc taskcat test run or run it from anywhere by providing the path to the project root taskcat test run -p ./quickstart-aws-vpc Non-standard credentials taskcat leverages the credential mechanisms of the AWS CLI, with the exception of environment variables. To integrate advanced credential handling (such as AWS SSO), please see issue #596 for an example Configuration files The configuration files required for taskcat have changed, to ease migration, if taskcat is run and legacy config files are found, they are converted and written to new file locations. For more information on the new format, see the config file docs . Dynamic values The example below shows an input file for a stack that requires six parameters , InstanceType , AvailablityZones , RandomString , RandomNumbers , GenerateUUID and Password Note: Value that matches the following pattern will be replaced: * All runtime injection parameters must start with $[ * Parameters must end with ] (see examples below) From: (defined in taskcat.yaml') InstanceType : t2 . small AvailablityZones : $ [ taskcat_genaz_2 ] RandomString : $ [ taskcat_random-string ] RandomNumbers : $ [ taskcat_random-numbers ] GenerateUUID : $ [ taskcat_genuuid ] Password : $ [ taskcat_genpass_8A ] PasswordConfirm : $ [ taskcat_getval_Password ] To: (At runtime passed to cloudformation API) InstanceType: t2.small AvailablityZones: us-east-1a: us-east1b RandomString: yysuawpwubvotiqgwjcu RandomNumbers: 56188163597280820763 GenerateUUID: 1c2e3483-2c99-45bb-801d-8af68a3b907b Password: tI8zN3iX8 PasswordConfirm: tI8zN3iX8 Gen Passwords More info on Passwords Generation To generate a random 8 character alpha-numeric password for testing use $[taskcat_genpass_8] as the value in the json input file * The number (8) in the injection string tells taskcat you want a password that character long. * Changing the 8 to 12 would result in a 12 character string (Optionally - you can specify the type of password by adding A or S) A alpha-numeric passwords S passwords with special characters Example: $[taskcat_genpass_8A] Generates: tI8zN3iX8 Example: $[taskcat_genpass_8S] Generates: mA5@cB5! (Retrieve previously generated value based on parameter name) UseCase: Need to confirm a dynamically generated password Example MyAppPassword $[taskcat_genpass_8A] Generates: pI8zN4iX8 Example ConfirmMyAppPassword: $[taskcat_getval_MyAppPassword] Generates: pI8zN4iX8 Auto input AvailablityZones More info on passsing in AvailablityZones based on test region Value that matches the following pattern will be replaced Parameters must end with ] genaz in invoked when taskcat_genaz_X is found A number of AZ's will be selected from the region the stack is attempting to launch Example: $[taskcat_genaz_2] Generates: us-east-1a, us-east-2b (if the region is us-east-1) Auto generated s3 bucket Example: $[taskcat_autobucket] Generates: evaluates to auto generated bucket name (taskcat-tag-sample-taskcat-project-5fba6597) Auto generate UUID String Example: $[taskcat_genuuid] Generates: 1c2e3483-2c99-45bb-801d-8af68a3b907b A generate Random Values String: Example: $[taskcat_random-string] Generates: yysuawpwubvotiqgwjcu Numbers: Example: $[taskcat_random-numbers] Generates: 56188163597280820763 GitHub PyPi","title":"Home"},{"location":"index.html#what-is-taskcat","text":"taskcat is a tool that tests AWS CloudFormation templates. It deploys your AWS CloudFormation template in multiple AWS Regions and generates a report with a pass/fail grade for each region. You can specify the regions and number of Availability Zones you want to include in the test, and pass in parameter values from your AWS CloudFormation template. taskcat is implemented as a Python class that you import, instantiate, and run. taskcat was developed by the aws-ia team to test AWS CloudFormation templates that automatically deploy workloads on AWS. We\u2019re pleased to make the tool available to all developers who want to validate their custom AWS CloudFormation templates across AWS Regions","title":"What is taskcat?"},{"location":"index.html#support","text":"","title":"Support"},{"location":"index.html#installation","text":"Currently only installation via pip is supported. Installation via docker coming soon.","title":"Installation"},{"location":"index.html#requirements","text":"The host taskcat is run on requires access to an AWS account, this can be done by any of the following mechanisms: Environment variables Shared credential file (~/.aws/credentials) AWS config file (~/.aws/config) Assume Role provider Boto2 config file (/etc/boto.cfg and ~/.boto) Instance metadata service on an Amazon EC2 instance that has an IAM role configured. for more info see the boto3 credential configuration documentation . Note: docker is only required if building lambda functions using a Dockerfile","title":"Requirements"},{"location":"index.html#installing-via-pip3","text":"pip3 install taskcat","title":"Installing via pip3"},{"location":"index.html#installing-via-pip3-user","text":"will install taskcat into homedir, useful if you get permissions errors with the regular method pip3 install taskcat --user Note: the user install dir is platform specific For Example: (On Mac: ~/Library/Python/3.x/bin/taskcat) For Example: (On Linux: ~/.local/bin) Warning: Be sure to add the python bin dir to your $PATH","title":"Installing via pip3 --user"},{"location":"index.html#windows","text":"taskcat on Windows is not supported . If you are running Windows 10 we recommend that you install Windows Subsystem for Linux (WSL) and then install taskcat inside the WSL environment using the steps above.","title":"Windows"},{"location":"index.html#usage","text":"","title":"Usage"},{"location":"index.html#cli","text":"The cli is self documenting by using --help . The most common use of taskcat is for executing function tests of CloudFormation templates. The command for this is: taskcat test run add --help to see the supported flags and arguments","title":"CLI"},{"location":"index.html#python","text":"Taskcat can be imported into Python and used in the testing framework of your choice. from taskcat.testing import CFNTest test = CFNTest . from_file ( project_root = './template_dir' ) with test as stacks : # Calling 'with' or 'test.run()' will deploy the stacks. for stack in stacks : print ( f \"Testing { stack . name } \" ) bucket_name = \"\" for output in stack . outputs : if output . key == \"LogsBucketName\" : bucket_name = output . value break assert \"logs\" in bucket_name assert stack . region . name in bucket_name print ( f \"Created bucket: { bucket_name } \" ) The example used here is very simple, you would most likely leverage other python modules like boto3 to do more advanced testing. The CFNTest object can be passed the same arguments as taskcat test run . See the docs for more details.","title":"Python"},{"location":"index.html#config-files","text":"taskcat has several configuration files which can be used to set behaviors in a flexible way.","title":"Config files"},{"location":"index.html#global-config","text":"~/.taskcat.yml provides global settings that become defaults for all projects. # General configuration settings general auth # AWS authentication section < AUTH_NAME > parameters : # Parameter key-values to pass to cfn (global parameters take precedence) < PARAMETER_NAME > s3_bucket : # Name of S3 bucket to upload project to (if left out a bucket will be auto-generated) s3_regional_buckets : # Boolean flag to upload the project to a bucket (generated in each region specified) tags : # Tags to apply to CloudFormation template TAG_NAME","title":"Global config"},{"location":"index.html#project-config","text":"File location: /.taskcat.yml` provides project specific configuration. project # Project specific configuration section auth # AWS authentication section < AUTH_NAME > az_blacklist # List of Availability Zones ID's to exclude when generating availability zones build_submodules # Build Lambda zips recursively for submodules, set to false to disable lambda_source_path # Path relative to the project root containing Lambda zip files, default is 'lambda_functions/source' lambda_zip_path # Path relative to the project root to place Lambda zip files, default is 'lambda_functions/zips' name # Project name, used as s3 key prefix when uploading objects owner # Email address for project owner (not used at present) package_lambda # Package Lambda functions into zips before uploading to s3, set to false to disable parameters # Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence < PARAMETER_NAME > regions # List of AWS regions s3_bucket # Name of S3 bucket to upload project to, if left out a bucket will be auto-generated s3_enable_sig_v2 # Enable (deprecated) sigv2 access to auto-generated buckets s3_object_acl # ACL for uploaded s3 objects, defaults to 'private' tags # Tags to apply to CloudFormation template < TAG_NAME > template # path to template file relative to the project config file path tests : auth # AWS authentication section < AUTH_NAME > az_blacklist # List of Availability Zones ID's to exclude when generating availability zones parameters # Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence < PARAMETER_NAME > regions # List of AWS regions s3_bucket # Name of S3 bucket to upload project to, if left out a bucket will be auto-generated tags # Tags to apply to CloudFormation template < TAG_NAME > template # Path to template file relative to the project config file path > At minimum it must provide a project name , list of regions , template name and one test . Minimal example : ``` yaml project : name : my - cfn - project regions : - us - west - 2 - eu - north - 1 tests : default : template : ./ templates / my - template . yaml Complete example with comments: tests/data/config_full_example/.taskcat.yml","title":"Project config"},{"location":"index.html#parameter-overrides","text":"a parameter override file can be created in <PROJECT_ROOT>/.taskcat_overrides.yml . Parameter Keys/Values specified in this file take precedence over values defined in all other configuration files. For example: KeyPair : my-overriden-keypair VpcId : vpc-1234abcd Warning: it is recommended to add .taskcat_overrides.yml to .gitignore to ensure it is not accidentally checked into source control","title":"Parameter overrides"},{"location":"index.html#precedence","text":"With the exception of the parameters section, more specific config with the same key takes precedence. The rationale behind having parameters function this way is so that values can be overridden at a system level outside of a project, that is likely committed to source control. parameters that define account specific things like VPC details, Key Pairs, or secrets like API keys can be defined per host outside of source control. For example, consider this global config: ~/.taskcat.yml general : s3_bucket : my-globally-defined-bucket parameters : KeyPair : my-global-ec2-keypair Given a simple project config: project : name : my-project regions : - us-east-2 tests : default : template : ./template.yaml The effective test configuration would become: tests : default : template : ./template.yaml s3_bucket : my-globally-defined-bucket parameters : KeyPair : my-global-ec2-keypair If any item is re-defined in a project it takes precedence over the global value. Anything defined in a test takes precedence over what is defined in the project or global configuration. with the exception of the parameters section which works in reverse. For example, using the same global config as above, given this project config: project : name : my-project regions : - us-east-2 s3_bucket : my-project-s3-bucket tests : default : template : ./template.yaml parameters : KeyPair : my-test-ec2-keypair Would result in this effective test configuration: tests : default : template : ./template.yaml s3_bucket : my-project-s3-bucket parameters : KeyPair : my-global-ec2-keypair Notice that s3_bucket took the most specific value and KeyPair the most general.","title":"Precedence"},{"location":"index.html#cli-interface","text":"taskcat adopts a similar cli command structure to git with a taskcat command subcommand --flag style. The cli is also designed to be simplest if run from the root of a project. Let's have a look at equivalent command to run a test: cd into the project root and type test run : cd ./quickstart-aws-vpc taskcat test run or run it from anywhere by providing the path to the project root taskcat test run -p ./quickstart-aws-vpc","title":"CLI interface"},{"location":"index.html#non-standard-credentials","text":"taskcat leverages the credential mechanisms of the AWS CLI, with the exception of environment variables. To integrate advanced credential handling (such as AWS SSO), please see issue #596 for an example","title":"Non-standard credentials"},{"location":"index.html#configuration-files","text":"The configuration files required for taskcat have changed, to ease migration, if taskcat is run and legacy config files are found, they are converted and written to new file locations. For more information on the new format, see the config file docs .","title":"Configuration files"},{"location":"index.html#dynamic-values","text":"The example below shows an input file for a stack that requires six parameters , InstanceType , AvailablityZones , RandomString , RandomNumbers , GenerateUUID and Password Note: Value that matches the following pattern will be replaced: * All runtime injection parameters must start with $[ * Parameters must end with ] (see examples below)","title":"Dynamic values"},{"location":"index.html#from-defined-in-taskcatyaml","text":"InstanceType : t2 . small AvailablityZones : $ [ taskcat_genaz_2 ] RandomString : $ [ taskcat_random-string ] RandomNumbers : $ [ taskcat_random-numbers ] GenerateUUID : $ [ taskcat_genuuid ] Password : $ [ taskcat_genpass_8A ] PasswordConfirm : $ [ taskcat_getval_Password ]","title":"From: (defined in taskcat.yaml')"},{"location":"index.html#to-at-runtime-passed-to-cloudformation-api","text":"InstanceType: t2.small AvailablityZones: us-east-1a: us-east1b RandomString: yysuawpwubvotiqgwjcu RandomNumbers: 56188163597280820763 GenerateUUID: 1c2e3483-2c99-45bb-801d-8af68a3b907b Password: tI8zN3iX8 PasswordConfirm: tI8zN3iX8","title":"To: (At runtime passed to cloudformation API)"},{"location":"index.html#gen-passwords","text":"More info on Passwords Generation To generate a random 8 character alpha-numeric password for testing use $[taskcat_genpass_8] as the value in the json input file * The number (8) in the injection string tells taskcat you want a password that character long. * Changing the 8 to 12 would result in a 12 character string (Optionally - you can specify the type of password by adding A or S) A alpha-numeric passwords S passwords with special characters Example: $[taskcat_genpass_8A] Generates: tI8zN3iX8 Example: $[taskcat_genpass_8S] Generates: mA5@cB5!","title":"Gen Passwords"},{"location":"index.html#retrieve-previously-generated-value-based-on-parameter-name","text":"UseCase: Need to confirm a dynamically generated password Example MyAppPassword $[taskcat_genpass_8A] Generates: pI8zN4iX8 Example ConfirmMyAppPassword: $[taskcat_getval_MyAppPassword] Generates: pI8zN4iX8","title":"(Retrieve previously generated value based on parameter name)"},{"location":"index.html#auto-input-availablityzones","text":"More info on passsing in AvailablityZones based on test region Value that matches the following pattern will be replaced Parameters must end with ] genaz in invoked when taskcat_genaz_X is found A number of AZ's will be selected from the region the stack is attempting to launch Example: $[taskcat_genaz_2] Generates: us-east-1a, us-east-2b (if the region is us-east-1)","title":"Auto input AvailablityZones"},{"location":"index.html#auto-generated-s3-bucket","text":"Example: $[taskcat_autobucket] Generates: evaluates to auto generated bucket name (taskcat-tag-sample-taskcat-project-5fba6597)","title":"Auto generated s3 bucket"},{"location":"index.html#auto-generate-uuid-string","text":"Example: $[taskcat_genuuid] Generates: 1c2e3483-2c99-45bb-801d-8af68a3b907b","title":"Auto generate UUID String"},{"location":"index.html#a-generate-random-values","text":"String: Example: $[taskcat_random-string] Generates: yysuawpwubvotiqgwjcu Numbers: Example: $[taskcat_random-numbers] Generates: 56188163597280820763","title":"A generate Random Values"},{"location":"index.html#github","text":"","title":"GitHub"},{"location":"index.html#pypi","text":"","title":"PyPi"},{"location":"CODE_OF_CONDUCT.html","text":"Code of Conduct 1. Purpose A primary goal of TaskCat is to be inclusive to the largest number of contributors, with the most varied and diverse backgrounds possible. As such, we are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, ability, ethnicity, socioeconomic status, and religion (or lack thereof). This code of conduct outlines our expectations for all those who participate in our community, as well as the consequences for unacceptable behavior. We invite all those who participate in TaskCat to help us create safe and positive experiences for everyone. 2. Open Source Citizenship A supplemental goal of this Code of Conduct is to increase open source citizenship by encouraging participants to recognize and strengthen the relationships between our actions and their effects on our community. Communities mirror the societies in which they exist and positive action is essential to counteract the many forms of inequality and abuses of power that exist in society. If you see someone who is making an extra effort to ensure our community is welcoming, friendly, and encourages all participants to contribute to the fullest extent, we want to know. 3. Expected Behavior The following behaviors are expected and requested of all community members: Participate in an authentic and active way. In doing so, you contribute to the health and longevity of this community. Exercise consideration and respect in your speech and actions. Attempt collaboration before conflict. Refrain from demeaning, discriminatory, or harassing behavior and speech. Be mindful of your surroundings and of your fellow participants. Alert community leaders if you notice a dangerous situation, someone in distress, or violations of this Code of Conduct, even if they seem inconsequential. Remember that community event venues may be shared with members of the public; please be respectful to all patrons of these locations. 4. Unacceptable Behavior The following behaviors are considered harassment and are unacceptable within our community: Violence, threats of violence or violent language directed against another person. Sexist, racist, homophobic, transphobic, ableist or otherwise discriminatory jokes and language. Posting or displaying sexually explicit or violent material. Posting or threatening to post other people\u2019s personally identifying information (\"doxing\"). Personal insults, particularly those related to gender, sexual orientation, race, religion, or disability. Inappropriate photography or recording. Inappropriate physical contact. You should have someone\u2019s consent before touching them. Unwelcome sexual attention. This includes, sexualized comments or jokes; inappropriate touching, groping, and unwelcomed sexual advances. Deliberate intimidation, stalking or following (online or in person). Advocating for, or encouraging, any of the above behavior. Sustained disruption of community events, including talks and presentations. 5. Consequences of Unacceptable Behavior Unacceptable behavior from any community member, including sponsors and those with decision-making authority, will not be tolerated. Anyone asked to stop unacceptable behavior is expected to comply immediately. If a community member engages in unacceptable behavior, the community organizers may take any action they deem appropriate, up to and including a temporary ban or permanent expulsion from the community without warning (and without refund in the case of a paid event). 6. Reporting Guidelines If you are subject to or witness unacceptable behavior, or have any other concerns, please notify a community organizer as soon as possible. quickstart@amazon.com. Link to reporting guidelines: codeofconduct@amazon.com Additionally, community organizers are available to help community members engage with local law enforcement or to otherwise help those experiencing unacceptable behavior feel safe. In the context of in-person events, organizers will also provide escorts as desired by the person experiencing distress. 7. Addressing Grievances If you feel you have been falsely or unfairly accused of violating this Code of Conduct, you should notify AWS Quickstart with a concise description of your grievance. Your grievance will be handled in accordance with our existing governing policies. Policy 8. Scope We expect all community participants (contributors, paid or otherwise; sponsors; and other guests) to abide by this Code of Conduct in all community venues\u2013online and in-person\u2013as well as in all one-on-one communications pertaining to community business. This code of conduct and its related procedures also applies to unacceptable behavior occurring outside the scope of community activities when such behavior has the potential to adversely affect the safety and well-being of community members. 9. Contact info quickstart@amazon.com 10. License and attribution This Code of Conduct is distributed under a Creative Commons Attribution-ShareAlike license . Portions of text derived from the Django Code of Conduct and the Geek Feminism Anti-Harassment Policy . Retrieved on November 22, 2016 from http://citizencodeofconduct.org/","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT.html#code-of-conduct","text":"","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT.html#1-purpose","text":"A primary goal of TaskCat is to be inclusive to the largest number of contributors, with the most varied and diverse backgrounds possible. As such, we are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, ability, ethnicity, socioeconomic status, and religion (or lack thereof). This code of conduct outlines our expectations for all those who participate in our community, as well as the consequences for unacceptable behavior. We invite all those who participate in TaskCat to help us create safe and positive experiences for everyone.","title":"1. Purpose"},{"location":"CODE_OF_CONDUCT.html#2-open-source-citizenship","text":"A supplemental goal of this Code of Conduct is to increase open source citizenship by encouraging participants to recognize and strengthen the relationships between our actions and their effects on our community. Communities mirror the societies in which they exist and positive action is essential to counteract the many forms of inequality and abuses of power that exist in society. If you see someone who is making an extra effort to ensure our community is welcoming, friendly, and encourages all participants to contribute to the fullest extent, we want to know.","title":"2. Open Source Citizenship"},{"location":"CODE_OF_CONDUCT.html#3-expected-behavior","text":"The following behaviors are expected and requested of all community members: Participate in an authentic and active way. In doing so, you contribute to the health and longevity of this community. Exercise consideration and respect in your speech and actions. Attempt collaboration before conflict. Refrain from demeaning, discriminatory, or harassing behavior and speech. Be mindful of your surroundings and of your fellow participants. Alert community leaders if you notice a dangerous situation, someone in distress, or violations of this Code of Conduct, even if they seem inconsequential. Remember that community event venues may be shared with members of the public; please be respectful to all patrons of these locations.","title":"3. Expected Behavior"},{"location":"CODE_OF_CONDUCT.html#4-unacceptable-behavior","text":"The following behaviors are considered harassment and are unacceptable within our community: Violence, threats of violence or violent language directed against another person. Sexist, racist, homophobic, transphobic, ableist or otherwise discriminatory jokes and language. Posting or displaying sexually explicit or violent material. Posting or threatening to post other people\u2019s personally identifying information (\"doxing\"). Personal insults, particularly those related to gender, sexual orientation, race, religion, or disability. Inappropriate photography or recording. Inappropriate physical contact. You should have someone\u2019s consent before touching them. Unwelcome sexual attention. This includes, sexualized comments or jokes; inappropriate touching, groping, and unwelcomed sexual advances. Deliberate intimidation, stalking or following (online or in person). Advocating for, or encouraging, any of the above behavior. Sustained disruption of community events, including talks and presentations.","title":"4. Unacceptable Behavior"},{"location":"CODE_OF_CONDUCT.html#5-consequences-of-unacceptable-behavior","text":"Unacceptable behavior from any community member, including sponsors and those with decision-making authority, will not be tolerated. Anyone asked to stop unacceptable behavior is expected to comply immediately. If a community member engages in unacceptable behavior, the community organizers may take any action they deem appropriate, up to and including a temporary ban or permanent expulsion from the community without warning (and without refund in the case of a paid event).","title":"5. Consequences of Unacceptable Behavior"},{"location":"CODE_OF_CONDUCT.html#6-reporting-guidelines","text":"If you are subject to or witness unacceptable behavior, or have any other concerns, please notify a community organizer as soon as possible. quickstart@amazon.com. Link to reporting guidelines: codeofconduct@amazon.com Additionally, community organizers are available to help community members engage with local law enforcement or to otherwise help those experiencing unacceptable behavior feel safe. In the context of in-person events, organizers will also provide escorts as desired by the person experiencing distress.","title":"6. Reporting Guidelines"},{"location":"CODE_OF_CONDUCT.html#7-addressing-grievances","text":"If you feel you have been falsely or unfairly accused of violating this Code of Conduct, you should notify AWS Quickstart with a concise description of your grievance. Your grievance will be handled in accordance with our existing governing policies. Policy","title":"7. Addressing Grievances"},{"location":"CODE_OF_CONDUCT.html#8-scope","text":"We expect all community participants (contributors, paid or otherwise; sponsors; and other guests) to abide by this Code of Conduct in all community venues\u2013online and in-person\u2013as well as in all one-on-one communications pertaining to community business. This code of conduct and its related procedures also applies to unacceptable behavior occurring outside the scope of community activities when such behavior has the potential to adversely affect the safety and well-being of community members.","title":"8. Scope"},{"location":"CODE_OF_CONDUCT.html#9-contact-info","text":"quickstart@amazon.com","title":"9. Contact info"},{"location":"CODE_OF_CONDUCT.html#10-license-and-attribution","text":"This Code of Conduct is distributed under a Creative Commons Attribution-ShareAlike license . Portions of text derived from the Django Code of Conduct and the Geek Feminism Anti-Harassment Policy . Retrieved on November 22, 2016 from http://citizencodeofconduct.org/","title":"10. License and attribution"},{"location":"CONTRIBUTING.html","text":"Contributing Guidelines Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Documentation Links: Module Documentation User Guide Reporting Bugs/Feature Requests We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment Contributing via Pull Requests (Pull request template provided) Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: All changes are staged into the develop branch (Send PR to the develop branch) You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request . Licensing We may ask you to affirm the Apache 2.0 agreement for larger changes.","title":"Contributing Guidelines"},{"location":"CONTRIBUTING.html#contributing-guidelines","text":"Thank you for your interest in contributing to our project. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community. Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution. Documentation Links: Module Documentation User Guide","title":"Contributing Guidelines"},{"location":"CONTRIBUTING.html#reporting-bugsfeature-requests","text":"We welcome you to use the GitHub issue tracker to report bugs or suggest features. When filing an issue, please check existing open , or recently closed , issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful: A reproducible test case or series of steps The version of our code being used Any modifications you've made relevant to the bug Anything unusual about your environment or deployment","title":"Reporting Bugs/Feature Requests"},{"location":"CONTRIBUTING.html#contributing-via-pull-requests-pull-request-template-provided","text":"Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that: All changes are staged into the develop branch (Send PR to the develop branch) You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already. You open an issue to discuss any significant work - we would hate for your time to be wasted. To send us a pull request, please: Fork the repository. Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change. Ensure local tests pass. Commit to your fork using clear commit messages. Send us a pull request, answering any default questions in the pull request interface. Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation. GitHub provides additional document on forking a repository and creating a pull request .","title":"Contributing via Pull Requests (Pull request template provided)"},{"location":"CONTRIBUTING.html#licensing","text":"We may ask you to affirm the Apache 2.0 agreement for larger changes.","title":"Licensing"},{"location":"FAQ.html","text":"TaskCat FAQ FAQ CommonErrors Error: botocore . exceptions . ClientError : An error occurred ( IllegalLocationConstraintException ) when calling the CreateBucket operation : The unspecified location constraint is incompatible for the region specific endpoint this request was sent to . Solution: Set your default region to us-east-1 For boto profile set the default to us-east-1 [profile default] output = json region = us-east-1 Critial failure with version all version below 2018.416.143234 Error: Traceback ( most recent call last ): File \"/var/lib/jenkins/.local/bin/taskcat\" , line 58 , in < module > main () File \"/var/lib/jenkins/.local/bin/taskcat\" , line 22 , in main tcat_instance . welcome ( 'taskcat' ) File \"/var/lib/jenkins/.local/lib/python3.6/site-packages/taskcat/stacker.py\" , line 2192 , in welcome self . checkforupdate () File \"/var/lib/jenkins/.local/lib/python3.6/site-packages/taskcat/stacker.py\" , line 2173 , in checkforupdate if version in current_version : TypeError : argument of type 'NoneType' is not iterable Due to infrastructure changes in https://pypi.org version check will fail for older versions :-( please update to latest version Solution: (Get latest version) To upgrade pip version [ pip install --upgrade taskcat] To upgrade docker version [ docker pull taskcat/taskcat ]","title":"FAQ"},{"location":"FAQ.html#taskcat-faq","text":"","title":"TaskCat FAQ"},{"location":"FAQ.html#faq","text":"","title":"FAQ"},{"location":"FAQ.html#commonerrors","text":"Error: botocore . exceptions . ClientError : An error occurred ( IllegalLocationConstraintException ) when calling the CreateBucket operation : The unspecified location constraint is incompatible for the region specific endpoint this request was sent to . Solution: Set your default region to us-east-1 For boto profile set the default to us-east-1 [profile default] output = json region = us-east-1","title":"CommonErrors"},{"location":"FAQ.html#critial-failure-with-version-all-version-below-2018416143234","text":"Error: Traceback ( most recent call last ): File \"/var/lib/jenkins/.local/bin/taskcat\" , line 58 , in < module > main () File \"/var/lib/jenkins/.local/bin/taskcat\" , line 22 , in main tcat_instance . welcome ( 'taskcat' ) File \"/var/lib/jenkins/.local/lib/python3.6/site-packages/taskcat/stacker.py\" , line 2192 , in welcome self . checkforupdate () File \"/var/lib/jenkins/.local/lib/python3.6/site-packages/taskcat/stacker.py\" , line 2173 , in checkforupdate if version in current_version : TypeError : argument of type 'NoneType' is not iterable Due to infrastructure changes in https://pypi.org version check will fail for older versions :-( please update to latest version Solution: (Get latest version) To upgrade pip version [ pip install --upgrade taskcat] To upgrade docker version [ docker pull taskcat/taskcat ]","title":"Critial failure with version all version below 2018.416.143234"},{"location":"PULL_REQUEST_TEMPLATE.html","text":"Overview Brief description of what this PR does, and why it is needed (use case)? Testing/Steps taken to ensure quality How did you validate the changes in this PR? Notes Optional. Caveats, Alternatives, Other relevant information. Testing Instructions How to test this PR Start after checking out this branch (bulleted) * Include test case, and expected output","title":"PULL REQUEST TEMPLATE"},{"location":"PULL_REQUEST_TEMPLATE.html#overview","text":"Brief description of what this PR does, and why it is needed (use case)?","title":"Overview"},{"location":"PULL_REQUEST_TEMPLATE.html#testingsteps-taken-to-ensure-quality","text":"How did you validate the changes in this PR?","title":"Testing/Steps taken to ensure quality"},{"location":"PULL_REQUEST_TEMPLATE.html#notes","text":"Optional. Caveats, Alternatives, Other relevant information.","title":"Notes"},{"location":"PULL_REQUEST_TEMPLATE.html#testing-instructions","text":"How to test this PR Start after checking out this branch (bulleted) * Include test case, and expected output","title":"Testing Instructions"},{"location":"README.AMIUPDATER.html","text":"AMIUpdater README General Usage. amiupdater <flags> </path/to/template_directory|template_file> For a current list of options, see.. amiupdater -h Leveraging the Upstream Config File Upstream Mappings By default, AMIUpdater uses a config file bundled with taskcat . This config file is populated with common AMI Mappings, such as Amazon Linux AMI and Ubuntu Server 18.04 . To see all of the mappings available, check out the config file To utilize these upstream mappings, simply leverage them in your templates. Note: The AMI IDs are here for example purposes. When first configuring the Mapping, you can filll them with arbitrary data. JSON { (...) \"Mappings\" : { \"AWSAMIRegionMap\" : { \"ap-northeast-1\" : { \"AMZNLINUXHVM\" : \"ami-00a5245b4816c38e6\" , \"CENTOS7HVM\" : \"ami-8e8847f1\" , \"US1404HVM\" : \"ami-0be9269b44d4b26c1\" , \"US1604HVM\" : \"ami-0d5e82481c5fd4ad5\" , \"SLES15HVM\" : \"ami-09161bc9964f46a98\" }, \"ap-northeast-2\" : { \"AMZNLINUXHVM\" : \"ami-00dc207f8ba6dc919\" , \"CENTOS7HVM\" : \"ami-bf9c36d1\" , \"US1404HVM\" : \"ami-017332df4b882edd2\" , \"US1604HVM\" : \"ami-0507b772e2c9b8c15\" , \"SLES15HVM\" : \"ami-04ecb44b7d8e8d354\" }, \"ap-south-1\" : { \"AMZNLINUXHVM\" : \"ami-0ad42f4f66f6c1cc9\" , \"CENTOS7HVM\" : \"ami-1780a878\" , \"US1404HVM\" : \"ami-09dcf5653a185f5df\" , \"US1604HVM\" : \"ami-0c8810f694cbe10ba\" , \"SLES15HVM\" : \"ami-025d8258d76079367\" } (...) } } } } YAML Mappings : AWSAMIRegionMap : ap-northeast-1 : AMZNLINUXHVM : ami-00a5245b4816c38e6, CENTOS7HVM : ami-8e8847f1, US1404HVM : ami-0be9269b44d4b26c1, US1604HVM : ami-0d5e82481c5fd4ad5, SLES15HVM : ami-09161bc9964f46a98 ap-northeast-2 : AMZNLINUXHVM : ami-00dc207f8ba6dc919, CENTOS7HVM : ami-bf9c36d1, US1404HVM : ami-017332df4b882edd2, US1604HVM : ami-0507b772e2c9b8c15, SLES15HVM : ami-04ecb44b7d8e8d354 ap-south-1 : AMZNLINUXHVM : ami-0ad42f4f66f6c1cc9, CENTOS7HVM : ami-1780a878, US1404HVM : ami-09dcf5653a185f5df, US1604HVM : ami-0c8810f694cbe10ba, SLES15HVM : ami-025d8258d76079367 Defining your own AMI Mappings Custom Config File Functionally the same as the upstream config file, a local config file can be created and used in deployment pipelines. For a full list of filters, available, please see the AWS EC2 API Documentation . # Owner-id must be in quotes # Whereas, all other filters do not need quotes, # because they are not in a number format global : AMIs : CUSTOM_MAPPING_1 : name : my_super_awesome_name-* owner-id : 1234567890 CUSTOM_MAPPING_2 : name : my_super_other_awesome_name ???? * owner-id : 1234567890 architecture : arm64 Template Inline Config JSON \"Metadata\" : { \"AWSAMIRegionMap\" :{ \"Filters\" :{ \"<MAPPING_NAME>\" :{ \"name\" : \"my awesome AMI NAME\" , \"owner-id\" : \"01234567890\" } } } YAML Metadata : AWSAMIRegionMap : Filters : <MAPPING_NAME> : name : my awesome AMI NAME owner-id : 01234567890","title":"*AMIUpdater README*"},{"location":"README.AMIUPDATER.html#amiupdater-readme","text":"","title":"AMIUpdater README"},{"location":"README.AMIUPDATER.html#general-usage","text":"amiupdater <flags> </path/to/template_directory|template_file> For a current list of options, see.. amiupdater -h","title":"General Usage."},{"location":"README.AMIUPDATER.html#leveraging-the-upstream-config-file","text":"","title":"Leveraging the Upstream Config File"},{"location":"README.AMIUPDATER.html#upstream-mappings","text":"By default, AMIUpdater uses a config file bundled with taskcat . This config file is populated with common AMI Mappings, such as Amazon Linux AMI and Ubuntu Server 18.04 . To see all of the mappings available, check out the config file To utilize these upstream mappings, simply leverage them in your templates. Note: The AMI IDs are here for example purposes. When first configuring the Mapping, you can filll them with arbitrary data. JSON { (...) \"Mappings\" : { \"AWSAMIRegionMap\" : { \"ap-northeast-1\" : { \"AMZNLINUXHVM\" : \"ami-00a5245b4816c38e6\" , \"CENTOS7HVM\" : \"ami-8e8847f1\" , \"US1404HVM\" : \"ami-0be9269b44d4b26c1\" , \"US1604HVM\" : \"ami-0d5e82481c5fd4ad5\" , \"SLES15HVM\" : \"ami-09161bc9964f46a98\" }, \"ap-northeast-2\" : { \"AMZNLINUXHVM\" : \"ami-00dc207f8ba6dc919\" , \"CENTOS7HVM\" : \"ami-bf9c36d1\" , \"US1404HVM\" : \"ami-017332df4b882edd2\" , \"US1604HVM\" : \"ami-0507b772e2c9b8c15\" , \"SLES15HVM\" : \"ami-04ecb44b7d8e8d354\" }, \"ap-south-1\" : { \"AMZNLINUXHVM\" : \"ami-0ad42f4f66f6c1cc9\" , \"CENTOS7HVM\" : \"ami-1780a878\" , \"US1404HVM\" : \"ami-09dcf5653a185f5df\" , \"US1604HVM\" : \"ami-0c8810f694cbe10ba\" , \"SLES15HVM\" : \"ami-025d8258d76079367\" } (...) } } } } YAML Mappings : AWSAMIRegionMap : ap-northeast-1 : AMZNLINUXHVM : ami-00a5245b4816c38e6, CENTOS7HVM : ami-8e8847f1, US1404HVM : ami-0be9269b44d4b26c1, US1604HVM : ami-0d5e82481c5fd4ad5, SLES15HVM : ami-09161bc9964f46a98 ap-northeast-2 : AMZNLINUXHVM : ami-00dc207f8ba6dc919, CENTOS7HVM : ami-bf9c36d1, US1404HVM : ami-017332df4b882edd2, US1604HVM : ami-0507b772e2c9b8c15, SLES15HVM : ami-04ecb44b7d8e8d354 ap-south-1 : AMZNLINUXHVM : ami-0ad42f4f66f6c1cc9, CENTOS7HVM : ami-1780a878, US1404HVM : ami-09dcf5653a185f5df, US1604HVM : ami-0c8810f694cbe10ba, SLES15HVM : ami-025d8258d76079367","title":"Upstream Mappings"},{"location":"README.AMIUPDATER.html#defining-your-own-ami-mappings","text":"","title":"Defining your own AMI Mappings"},{"location":"README.AMIUPDATER.html#custom-config-file","text":"Functionally the same as the upstream config file, a local config file can be created and used in deployment pipelines. For a full list of filters, available, please see the AWS EC2 API Documentation . # Owner-id must be in quotes # Whereas, all other filters do not need quotes, # because they are not in a number format global : AMIs : CUSTOM_MAPPING_1 : name : my_super_awesome_name-* owner-id : 1234567890 CUSTOM_MAPPING_2 : name : my_super_other_awesome_name ???? * owner-id : 1234567890 architecture : arm64","title":"Custom Config File"},{"location":"README.AMIUPDATER.html#template-inline-config","text":"JSON \"Metadata\" : { \"AWSAMIRegionMap\" :{ \"Filters\" :{ \"<MAPPING_NAME>\" :{ \"name\" : \"my awesome AMI NAME\" , \"owner-id\" : \"01234567890\" } } } YAML Metadata : AWSAMIRegionMap : Filters : <MAPPING_NAME> : name : my awesome AMI NAME owner-id : 01234567890","title":"Template Inline Config"},{"location":"docs/schema/taskcat_schema.html","text":"general type: object General configuration settings. auth type: object AWS authentication section <AUTH_NAME> type: object parameters type: object Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence <PARAMETER_NAME> type: object posthooks type: array hooks to execute after executing tests prehooks type: array hooks to execute prior to executing tests regions type: array List of AWS regions s3_bucket type: string Name of S3 bucket to upload project to, if left out a bucket will be auto-generated s3_regional_buckets type: boolean Enable regional auto-buckets. tags type: object Tags to apply to CloudFormation template <TAG_NAME> type: object project type: object Project specific configuration section auth type: object AWS authentication section <AUTH_NAME> type: object az_blacklist type: array List of Availablilty Zones ID's to exclude when generating availability zones build_submodules type: boolean Build Lambda zips recursively for submodules, set to false to disable lambda_source_path type: string Path relative to the project root containing Lambda zip files, default is 'lambda_functions/source' lambda_zip_path type: string Path relative to the project root to place Lambda zip files, default is 'lambda_functions/zips' name type: string Project name, used as s3 key prefix when uploading objects owner type: string email address for project owner (not used at present) package_lambda type: boolean Package Lambda functions into zips before uploading to s3, set to false to disable parameters type: object Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence <PARAMETER_NAME> type: object posthooks type: array hooks to execute after executing tests prehooks type: array hooks to execute prior to executing tests regions type: array List of AWS regions role_name type: string Role name to use when launching CFN Stacks. s3_bucket type: string Name of S3 bucket to upload project to, if left out a bucket will be auto-generated s3_enable_sig_v2 type: boolean Enable (deprecated) sigv2 access to auto-generated buckets s3_object_acl type: string ACL for uploaded s3 objects, defaults to 'private' s3_regional_buckets type: boolean Enable regional auto-buckets. shorten_stack_name type: boolean Shorten stack names generated for tests, set to true to enable tags type: object Tags to apply to CloudFormation template <TAG_NAME> type: object template type: string path to template file relative to the project config file path tests type: object auth type: object AWS authentication section <AUTH_NAME> type: object az_blacklist type: array List of Availablilty Zones ID's to exclude when generating availability zones parameters type: object Parameter key-values to pass to CloudFormation, parameters provided in global config take precedence <PARAMETER_NAME> type: object posthooks type: array hooks to execute after executing tests prehooks type: array hooks to execute prior to executing tests regions type: array List of AWS regions role_name type: string Role name to use when launching CFN Stacks. s3_bucket type: string Name of S3 bucket to upload project to, if left out a bucket will be auto-generated s3_regional_buckets type: boolean Enable regional auto-buckets. stack_name type: string Cloudformation Stack Name stack_name_prefix type: string Prefix to apply to generated CFN Stack Name stack_name_suffix type: string Suffix to apply to generated CFN Stack Name tags type: object Tags to apply to CloudFormation template <TAG_NAME> type: object template type: string path to template file relative to the project config file path","title":"Schema"},{"location":"reference/taskcat_plugin_testhook.html","text":"Module taskcat_plugin_testhook None None View Source from typing import Mapping , Optional from taskcat._config import Config from taskcat._dataclasses import TestObj from taskcat.exceptions import TaskCatException from taskcat.testing._hooks import BaseTaskcatHook class Hook ( BaseTaskcatHook ): def __init__ ( self , hook_config : dict , config : Config , tests : Mapping [ str , TestObj ], parameters : dict , outputs : Optional [ dict ], ): super () . __init__ ( hook_config , config , tests , parameters , outputs ) if hook_config . get ( \"generate_failure\" ): raise TaskCatException ( \"generated failure from hook\" ) Classes Hook class Hook ( hook_config : dict , config : taskcat . _config . Config , tests : Mapping [ str , taskcat . _dataclasses . TestObj ], parameters : dict , outputs : Union [ dict , NoneType ] ) View Source class Hook ( BaseTaskcatHook ) : def __init__ ( self , hook_config : dict , config : Config , tests : Mapping [ str, TestObj ] , parameters : dict , outputs : Optional [ dict ] , ) : super (). __init__ ( hook_config , config , tests , parameters , outputs ) if hook_config . get ( \"generate_failure\" ) : raise TaskCatException ( \"generated failure from hook\" ) Ancestors (in MRO) taskcat.testing._hooks.BaseTaskcatHook","title":"Taskcat Plugin Testhook"},{"location":"reference/taskcat_plugin_testhook.html#module-taskcat_plugin_testhook","text":"None None View Source from typing import Mapping , Optional from taskcat._config import Config from taskcat._dataclasses import TestObj from taskcat.exceptions import TaskCatException from taskcat.testing._hooks import BaseTaskcatHook class Hook ( BaseTaskcatHook ): def __init__ ( self , hook_config : dict , config : Config , tests : Mapping [ str , TestObj ], parameters : dict , outputs : Optional [ dict ], ): super () . __init__ ( hook_config , config , tests , parameters , outputs ) if hook_config . get ( \"generate_failure\" ): raise TaskCatException ( \"generated failure from hook\" )","title":"Module taskcat_plugin_testhook"},{"location":"reference/taskcat_plugin_testhook.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat_plugin_testhook.html#hook","text":"class Hook ( hook_config : dict , config : taskcat . _config . Config , tests : Mapping [ str , taskcat . _dataclasses . TestObj ], parameters : dict , outputs : Union [ dict , NoneType ] ) View Source class Hook ( BaseTaskcatHook ) : def __init__ ( self , hook_config : dict , config : Config , tests : Mapping [ str, TestObj ] , parameters : dict , outputs : Optional [ dict ] , ) : super (). __init__ ( hook_config , config , tests , parameters , outputs ) if hook_config . get ( \"generate_failure\" ) : raise TaskCatException ( \"generated failure from hook\" )","title":"Hook"},{"location":"reference/taskcat_plugin_testhook.html#ancestors-in-mro","text":"taskcat.testing._hooks.BaseTaskcatHook","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/index.html","text":"Module taskcat taskcat python module None View Source \"\"\" taskcat python module \"\"\" from ._cfn.stack import Stack # noqa: F401 from ._cfn.template import Template # noqa: F401 from ._cli import main # noqa: F401 from ._config import Config # noqa: F401 __all__ = [ \"Stack\" , \"Template\" , \"Config\" , \"main\" ] Sub-modules taskcat.exceptions taskcat.regions_to_partitions taskcat.testing Functions main def main ( cli_core_class =< class ' taskcat . _cli_core . CliCore '>, exit_func =< function exit_with_code at 0x112d519d0 > ) View Source def main ( cli_core_class = CliCore , exit_func = exit_with_code ): signal . signal ( signal . SIGINT , _sigint_handler ) log_level = _setup_logging ( sys . argv ) args = sys . argv [ 1 :] if not args : args . append ( \"-h\" ) try : _welcome () version = get_installed_version () cli = cli_core_class ( NAME , _cli_modules , DESCRIPTION , version , GLOBAL_ARGS . ARGS ) cli . parse ( args ) _default_profile = cli . parsed_args . __dict__ . get ( \"_profile\" ) if _default_profile : GLOBAL_ARGS . profile = _default_profile cli . run () except TaskCatException as e : LOG . error ( str ( e ), exc_info = _print_tracebacks ( log_level )) exit_func ( 1 ) except Exception as e : # pylint: disable=broad-except LOG . error ( \" %s %s \" , e . __class__ . __name__ , str ( e ), exc_info = _print_tracebacks ( log_level ) ) exit_func ( 1 ) Classes Config class Config ( sources : list , uid : uuid . UUID , project_root : pathlib . Path ) View Source class Config : def __init__ ( self , sources : list , uid : uuid . UUID , project_root : Path ): self . config = BaseConfig . from_dict ( DEFAULTS ) self . config . set_source ( \"TASKCAT_DEFAULT\" ) self . project_root = project_root self . uid = uid for source in sources : config_dict : dict = source [ \"config\" ] source_name : str = source [ \"source\" ] source_config = BaseConfig . from_dict ( config_dict ) source_config . set_source ( source_name ) self . config = BaseConfig . merge ( self . config , source_config ) @ classmethod # pylint: disable=too-many-locals def create ( cls , template_file : Optional [ Path ] = None , args : Optional [ dict ] = None , global_config_path : Path = GENERAL , project_config_path : Path = PROJECT , overrides_path : Path = OVERRIDES , env_vars : Optional [ dict ] = None , project_root : Path = PROJECT_ROOT , uid : uuid . UUID = None , ) -> \"Config\" : uid = uid if uid else uuid . uuid4 () project_source = cls . _get_project_source ( cls , project_config_path , project_root , template_file ) # general legacy_overrides ( Path ( \"~/.aws/taskcat_global_override.json\" ) . expanduser () . resolve (), global_config_path , \"global\" , ) sources = [ { \"source\" : str ( global_config_path ), \"config\" : cls . _dict_from_file ( global_config_path ), } ] # project config file if project_source : sources . append ( project_source ) # template file if isinstance ( template_file , Path ): sources . append ( { \"source\" : str ( template_file ), \"config\" : cls . _dict_from_template ( template_file ), } ) # override file legacy_overrides ( project_root / \"ci/taskcat_project_override.json\" , overrides_path , \"project\" ) if overrides_path . is_file (): overrides = BaseConfig () . to_dict () with open ( str ( overrides_path ), \"r\" ) as file_handle : override_params = yaml . safe_load ( file_handle ) overrides [ \"project\" ][ \"parameters\" ] = override_params sources . append ({ \"source\" : str ( overrides_path ), \"config\" : overrides }) # environment variables sources . append ( { \"source\" : \"EnvoronmentVariable\" , \"config\" : cls . _dict_from_env_vars ( env_vars ), } ) # cli arguments if args : sources . append ({ \"source\" : \"CliArgument\" , \"config\" : args }) return cls ( sources = sources , uid = uid , project_root = project_root ) # pylint: disable=protected-access,inconsistent-return-statements @ staticmethod def _get_project_source ( base_cls , project_config_path , project_root , template_file ): try : return { \"source\" : str ( project_config_path ), \"config\" : base_cls . _dict_from_file ( project_config_path , fail_ok = False ), } except FileNotFoundError as e : error = e try : legacy_conf = parse_legacy_config ( project_root ) return { \"source\" : str ( project_root / \"ci/taskcat.yml\" ), \"config\" : legacy_conf . to_dict (), } except Exception as e : # pylint: disable=broad-except LOG . debug ( str ( e ), exc_info = True ) if not template_file : # pylint: disable=raise-missing-from raise error @ staticmethod def _dict_from_file ( file_path : Path , fail_ok = True ) -> dict : config_dict = BaseConfig () . to_dict () if not file_path . is_file () and fail_ok : return config_dict try : with open ( str ( file_path ), \"r\" ) as file_handle : config_dict = yaml . safe_load ( file_handle ) return config_dict except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"failed to load config from {file_path}\" ) LOG . debug ( str ( e ), exc_info = True ) if not fail_ok : raise e return config_dict @ staticmethod def _dict_from_template ( file_path : Path ) -> dict : relative_path = str ( file_path . relative_to ( PROJECT_ROOT )) config_dict = ( BaseConfig () . from_dict ( { \"project\" : { \"template\" : relative_path }, \"tests\" : { \"default\" : {}}} ) . to_dict () ) if not file_path . is_file (): raise TaskCatException ( f \"invalid template path {file_path}\" ) try : template = Template ( str ( file_path ), template_cache = tcat_template_cache ) . template except Exception as e : LOG . warning ( f \"failed to load template from {file_path}\" ) LOG . debug ( str ( e ), exc_info = True ) raise e if not template . get ( \"Metadata\" ): return config_dict if not template [ \"Metadata\" ] . get ( \"taskcat\" ): return config_dict template_config_dict = template [ \"Metadata\" ][ \"taskcat\" ] if not template_config_dict . get ( \"project\" ): template_config_dict [ \"project\" ] = {} template_config_dict [ \"project\" ][ \"template\" ] = relative_path if not template_config_dict . get ( \"tests\" ): template_config_dict [ \"tests\" ] = { \"default\" : {}} return template_config_dict # pylint: disable=protected-access @ staticmethod def _dict_from_env_vars ( env_vars : Optional [ Union [ os . _Environ , Dict [ str , str ]]] = None ): if env_vars is None : env_vars = os . environ config_dict : Dict [ str , Dict [ str , Union [ str , bool , int ]]] = {} for key , value in env_vars . items (): if key . startswith ( \"TASKCAT_\" ): key = key [ 8 :] . lower () sub_key = None key_section = None for section in [ \"general\" , \"project\" , \"tests\" ]: if key . startswith ( section ): sub_key = key [ len ( section ) + 1 :] key_section = section if isinstance ( sub_key , str ) and isinstance ( key_section , str ): if value . isnumeric (): value = int ( value ) elif value . lower () in [ \"true\" , \"false\" ]: value = value . lower () == \"true\" if not config_dict . get ( key_section ): config_dict [ key_section ] = {} config_dict [ key_section ][ sub_key ] = value return config_dict def get_regions ( self , boto3_cache : Boto3Cache = None ): if boto3_cache is None : boto3_cache = Boto3Cache () region_objects : Dict [ str , Dict [ str , RegionObj ]] = {} for test_name , test in self . config . tests . items (): region_objects [ test_name ] = {} for region in test . regions : # TODO: comon_utils/determine_profile_for_region profile = ( test . auth . get ( region , test . auth . get ( \"default\" , \"default\" )) if test . auth else \"default\" ) region_objects [ test_name ][ region ] = RegionObj ( name = region , account_id = boto3_cache . account_id ( profile ), partition = boto3_cache . partition ( profile ), profile = profile , _boto3_cache = boto3_cache , taskcat_id = self . uid , _role_name = test . role_name , ) return region_objects def get_buckets ( self , boto3_cache : Boto3Cache = None ): regions = self . get_regions ( boto3_cache ) bucket_objects : Dict [ str , S3BucketObj ] = {} bucket_mappings : Dict [ str , Dict [ str , S3BucketObj ]] = {} for test_name , test in self . config . tests . items (): bucket_mappings [ test_name ] = {} for region_name , region in regions [ test_name ] . items (): if test . s3_regional_buckets : bucket_obj = self . _create_regional_bucket_obj ( bucket_objects , region , test ) bucket_objects [ f \"{region.account_id}{region.name}\" ] = bucket_obj else : bucket_obj = self . _create_legacy_bucket_obj ( bucket_objects , region , test ) bucket_objects [ region . account_id ] = bucket_obj bucket_mappings [ test_name ][ region_name ] = bucket_obj return bucket_mappings def _create_legacy_bucket_obj ( self , bucket_objects , region , test ): new = False object_acl = ( self . config . project . s3_object_acl if self . config . project . s3_object_acl else \"private\" ) sigv4 = not self . config . project . s3_enable_sig_v2 if not test . s3_bucket and not bucket_objects . get ( region . account_id ): name = generate_bucket_name ( self . config . project . name ) auto_generated = True new = True elif bucket_objects . get ( region . account_id ): name = bucket_objects [ region . account_id ] . name auto_generated = bucket_objects [ region . account_id ] . auto_generated else : name = test . s3_bucket auto_generated = False bucket_region = self . _get_bucket_region_for_partition ( region . partition ) bucket_obj = S3BucketObj ( name = name , region = bucket_region , account_id = region . account_id , s3_client = region . session . client ( \"s3\" , region_name = bucket_region ), auto_generated = auto_generated , object_acl = object_acl , sigv4 = sigv4 , taskcat_id = self . uid , partition = region . partition , regional_buckets = test . s3_regional_buckets , ) if new : bucket_obj . create () return bucket_obj def _create_regional_bucket_obj ( self , bucket_objects , region , test ): _bucket_obj_key = f \"{region.account_id}{region.name}\" new = False object_acl = ( self . config . project . s3_object_acl if self . config . project . s3_object_acl else \"private\" ) sigv4 = not self . config . project . s3_enable_sig_v2 if not test . s3_bucket and not bucket_objects . get ( _bucket_obj_key ): name = generate_regional_bucket_name ( region ) auto_generated = True new = True elif bucket_objects . get ( _bucket_obj_key ): name = bucket_objects [ _bucket_obj_key ] . name auto_generated = bucket_objects [ _bucket_obj_key ] . auto_generated else : name = f \"{test.s3_bucket}-{region.name}\" auto_generated = False try : region . client ( \"s3\" ) . head_bucket ( Bucket = name ) except ClientError as e : if \"(404)\" in str ( e ): new = True else : raise bucket_obj = S3BucketObj ( name = name , region = region . name , account_id = region . account_id , s3_client = region . session . client ( \"s3\" , region_name = region . name ), auto_generated = auto_generated , object_acl = object_acl , sigv4 = sigv4 , taskcat_id = self . uid , partition = region . partition , regional_buckets = test . s3_regional_buckets , ) if new : bucket_obj . create () return bucket_obj @ staticmethod def _get_bucket_region_for_partition ( partition ): region = \"us-east-1\" if partition == \"aws-us-gov\" : region = \"us-gov-east-1\" elif partition == \"aws-cn\" : region = \"cn-north-1\" return region def get_rendered_parameters ( self , bucket_objects , region_objects , template_objects ): parameters = {} template_params = self . get_params_from_templates ( template_objects ) for test_name , test in self . config . tests . items (): parameters [ test_name ] = {} for region_name in test . regions : region_params = template_params [ test_name ] . copy () for param_key , param_value in test . parameters . items (): if param_key in region_params : region_params [ param_key ] = param_value region = region_objects [ test_name ][ region_name ] s3bucket = bucket_objects [ test_name ][ region_name ] parameters [ test_name ][ region_name ] = ParamGen ( region_params , s3bucket . name , region . name , region . client , self . config . project . name , test_name , test . az_blacklist , ) . results return parameters @ staticmethod def get_params_from_templates ( template_objects ): parameters = {} for test_name , template in template_objects . items (): parameters [ test_name ] = template . parameters () return parameters def get_templates ( self ): templates = {} for test_name , test in self . config . tests . items (): templates [ test_name ] = Template ( template_path = self . project_root / test . template , project_root = self . project_root , s3_key_prefix = f \"{self.config.project.name}/\" , template_cache = tcat_template_cache , ) return templates def get_tests ( self , templates , regions , buckets , parameters ): tests = {} for test_name , test in self . config . tests . items (): region_list = [] tag_list = [] if test . tags : for tag_key , tag_value in test . tags . items (): tag_list . append ( Tag ({ \"Key\" : tag_key , \"Value\" : tag_value })) for region_obj in regions [ test_name ] . values (): region_list . append ( TestRegion . from_region_obj ( region_obj , buckets [ test_name ][ region_obj . name ], parameters [ test_name ][ region_obj . name ], ) ) tests [ test_name ] = TestObj ( name = test_name , template_path = self . project_root / test . template , template = templates [ test_name ], project_root = self . project_root , regions = region_list , tags = tag_list , uid = self . uid , _project_name = self . config . project . name , _shorten_stack_name = self . config . project . shorten_stack_name , _stack_name = test . stack_name , _stack_name_prefix = test . stack_name_prefix , _stack_name_suffix = test . stack_name_suffix , ) return tests Static methods create def create ( template_file : Union [ pathlib . Path , NoneType ] = None , args : Union [ dict , NoneType ] = None , global_config_path : pathlib . Path = PosixPath ( '/Users/andglenn/development/.local/.taskcat.yml' ), project_config_path : pathlib . Path = PosixPath ( '/Users/andglenn/development/tools/taskcat/.taskcat.yml' ), overrides_path : pathlib . Path = PosixPath ( '/Users/andglenn/development/tools/taskcat/.taskcat_overrides.yml' ), env_vars : Union [ dict , NoneType ] = None , project_root : pathlib . Path = PosixPath ( '/Users/andglenn/development/tools/taskcat' ), uid : uuid . UUID = None ) -> 'Config' View Source @ classmethod # pylint: disable=too-many-locals def create ( cls , template_file : Optional [ Path ] = None , args : Optional [ dict ] = None , global_config_path : Path = GENERAL , project_config_path : Path = PROJECT , overrides_path : Path = OVERRIDES , env_vars : Optional [ dict ] = None , project_root : Path = PROJECT_ROOT , uid : uuid . UUID = None , ) -> \"Config\" : uid = uid if uid else uuid . uuid4 () project_source = cls . _get_project_source ( cls , project_config_path , project_root , template_file ) # general legacy_overrides ( Path ( \"~/.aws/taskcat_global_override.json\" ) . expanduser () . resolve (), global_config_path , \"global\" , ) sources = [ { \"source\" : str ( global_config_path ), \"config\" : cls . _dict_from_file ( global_config_path ), } ] # project config file if project_source : sources . append ( project_source ) # template file if isinstance ( template_file , Path ): sources . append ( { \"source\" : str ( template_file ), \"config\" : cls . _dict_from_template ( template_file ), } ) # override file legacy_overrides ( project_root / \"ci/taskcat_project_override.json\" , overrides_path , \"project\" ) if overrides_path . is_file (): overrides = BaseConfig () . to_dict () with open ( str ( overrides_path ), \"r\" ) as file_handle : override_params = yaml . safe_load ( file_handle ) overrides [ \"project\" ][ \"parameters\" ] = override_params sources . append ({ \"source\" : str ( overrides_path ), \"config\" : overrides }) # environment variables sources . append ( { \"source\" : \"EnvoronmentVariable\" , \"config\" : cls . _dict_from_env_vars ( env_vars ), } ) # cli arguments if args : sources . append ({ \"source\" : \"CliArgument\" , \"config\" : args }) return cls ( sources = sources , uid = uid , project_root = project_root ) get_params_from_templates def get_params_from_templates ( template_objects ) View Source @staticmethod def get_params_from_templates ( template_objects ) : parameters = {} for test_name , template in template_objects . items () : parameters [ test_name ] = template . parameters () return parameters Methods get_buckets def get_buckets ( self , boto3_cache : taskcat . _client_factory . Boto3Cache = None ) View Source def get_buckets ( self , boto3_cache : Boto3Cache = None ) : regions = self . get_regions ( boto3_cache ) bucket_objects : Dict [ str, S3BucketObj ] = {} bucket_mappings : Dict [ str, Dict[str, S3BucketObj ] ] = {} for test_name , test in self . config . tests . items () : bucket_mappings [ test_name ] = {} for region_name , region in regions [ test_name ] . items () : if test . s3_regional_buckets : bucket_obj = self . _create_regional_bucket_obj ( bucket_objects , region , test ) bucket_objects [ f\"{region.account_id}{region.name}\" ] = bucket_obj else : bucket_obj = self . _create_legacy_bucket_obj ( bucket_objects , region , test ) bucket_objects [ region.account_id ] = bucket_obj bucket_mappings [ test_name ][ region_name ] = bucket_obj return bucket_mappings get_regions def get_regions ( self , boto3_cache : taskcat . _client_factory . Boto3Cache = None ) View Source def get_regions ( self , boto3_cache : Boto3Cache = None ) : if boto3_cache is None : boto3_cache = Boto3Cache () region_objects : Dict [ str, Dict[str, RegionObj ] ] = {} for test_name , test in self . config . tests . items () : region_objects [ test_name ] = {} for region in test . regions : # TODO : comon_utils / determine_profile_for_region profile = ( test . auth . get ( region , test . auth . get ( \"default\" , \"default\" )) if test . auth else \"default\" ) region_objects [ test_name ][ region ] = RegionObj ( name = region , account_id = boto3_cache . account_id ( profile ), partition = boto3_cache . partition ( profile ), profile = profile , _boto3_cache = boto3_cache , taskcat_id = self . uid , _role_name = test . role_name , ) return region_objects get_rendered_parameters def get_rendered_parameters ( self , bucket_objects , region_objects , template_objects ) View Source def get_rendered_parameters ( self , bucket_objects , region_objects , template_objects ) : parameters = {} template_params = self . get_params_from_templates ( template_objects ) for test_name , test in self . config . tests . items () : parameters [ test_name ] = {} for region_name in test . regions : region_params = template_params [ test_name ] . copy () for param_key , param_value in test . parameters . items () : if param_key in region_params : region_params [ param_key ] = param_value region = region_objects [ test_name ][ region_name ] s3bucket = bucket_objects [ test_name ][ region_name ] parameters [ test_name ][ region_name ] = ParamGen ( region_params , s3bucket . name , region . name , region . client , self . config . project . name , test_name , test . az_blacklist , ). results return parameters get_templates def get_templates ( self ) View Source def get_templates ( self ) : templates = {} for test_name , test in self . config . tests . items () : templates [ test_name ] = Template ( template_path = self . project_root / test . template , project_root = self . project_root , s3_key_prefix = f \"{self.config.project.name}/\" , template_cache = tcat_template_cache , ) return templates get_tests def get_tests ( self , templates , regions , buckets , parameters ) View Source def get_tests ( self , templates , regions , buckets , parameters ) : tests = {} for test_name , test in self . config . tests . items () : region_list = [] tag_list = [] if test . tags : for tag_key , tag_value in test . tags . items () : tag_list . append ( Tag ( { \"Key\" : tag_key , \"Value\" : tag_value } )) for region_obj in regions [ test_name ] . values () : region_list . append ( TestRegion . from_region_obj ( region_obj , buckets [ test_name ][ region_obj.name ] , parameters [ test_name ][ region_obj.name ] , ) ) tests [ test_name ] = TestObj ( name = test_name , template_path = self . project_root / test . template , template = templates [ test_name ] , project_root = self . project_root , regions = region_list , tags = tag_list , uid = self . uid , _project_name = self . config . project . name , _shorten_stack_name = self . config . project . shorten_stack_name , _stack_name = test . stack_name , _stack_name_prefix = test . stack_name_prefix , _stack_name_suffix = test . stack_name_suffix , ) return tests Stack class Stack ( region : taskcat . _dataclasses . TestRegion , stack_id : str , template : taskcat . _cfn . template . Template , test_name , uuid : uuid . UUID = None ) View Source class Stack : # pylint: disable=too-many-instance-attributes REMOTE_TEMPLATE_PATH = Path ( \".taskcat/.remote_templates\" ) def __init__ ( self , region : TestRegion , stack_id : str , template : Template , test_name , uuid : UUID = None , ): uuid = uuid if uuid else uuid4 () self . test_name : str = test_name self . uuid : UUID = uuid self . id : str = stack_id self . template : Template = template self . name : str = self . _get_name () self . region : TestRegion = region self . region_name = region . name self . client : boto3 . client = region . client ( \"cloudformation\" ) self . completion_time : timedelta = timedelta ( 0 ) self . role_arn = region . role_arn # properties from additional cfn api calls self . _events : Events = Events () self . _resources : Resources = Resources () self . _children : Stacks = Stacks () # properties from describe_stacks response self . change_set_id : str = \"\" self . parameters : List [ Parameter ] = [] self . creation_time : datetime = datetime . fromtimestamp ( 0 ) self . deletion_time : datetime = datetime . fromtimestamp ( 0 ) self . _status : str = \"\" self . status_reason : str = \"\" self . disable_rollback : bool = False self . timeout_in_minutes : int = 0 self . capabilities : List [ str ] = [] self . outputs : List [ Output ] = [] self . tags : List [ Tag ] = [] self . parent_id : str = \"\" self . root_id : str = \"\" self . _launch_succeeded : bool = False self . _auto_refresh_interval : timedelta = timedelta ( seconds = 60 ) self . _last_event_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_resource_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_child_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () def __str__ ( self ): return self . id def __repr__ ( self ): return \"<Stack object {} at {}>\" . format ( self . name , hex ( id ( self ))) def _get_region ( self ) -> str : return self . id . split ( \":\" )[ 3 ] def _get_name ( self ) -> str : return self . id . split ( \":\" )[ 5 ] . split ( \"/\" )[ 1 ] def _auto_refresh ( self , last_refresh ): if datetime . now () - last_refresh > self . _auto_refresh_interval : return True return False @ property def status ( self ): if self . _status in StackStatus . COMPLETE : if not self . launch_succeeded : self . _status = \"OUT_OF_ORDER_EVENT\" self . status_reason = ( \"COMPLETE event not detected. \" + \"Potential out-of-band action against the stack.\" ) return self . _status @ status . setter def status ( self , status ): _complete = StackStatus . COMPLETE . copy () del _complete [ _complete . index ( \"DELETE_COMPLETE\" )] self . _status = status if status in StackStatus . FAILED : self . _launch_succeeded = False return if status in _complete : self . _launch_succeeded = True return return @ property def launch_succeeded ( self ): return self . _launch_succeeded @ classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t . dump () for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options )[ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack @ staticmethod def _cfn_format_parameters ( parameters ): return [{ \"ParameterKey\" : k , \"ParameterValue\" : v } for k , v in parameters . items ()] @ classmethod def _import_child ( # pylint: disable=too-many-locals cls , stack_properties : dict , parent_stack : \"Stack\" ) -> Optional [ \"Stack\" ]: try : url = \"\" for event in parent_stack . events (): if ( event . physical_id == stack_properties [ \"StackId\" ] and event . properties ): url = event . properties [ \"TemplateURL\" ] if url . startswith ( parent_stack . template . url_prefix ()): # Template is part of the project, discovering path relative_path = url . replace ( parent_stack . template . url_prefix (), \"\" ) . lstrip ( \"/\" ) absolute_path = parent_stack . template . project_root / relative_path if not absolute_path . is_file (): # try with the base folder stripped off relative_path2 = Path ( relative_path ) relative_path2 = relative_path2 . relative_to ( * relative_path2 . parts [: 1 ] ) absolute_path = parent_stack . template . project_root / relative_path2 if not absolute_path . is_file (): LOG . warning ( f \"Failed to find template for child stack \" f \"{stack_properties['StackId']}. tried \" f \"{parent_stack.template.project_root / relative_path}\" f \" and {absolute_path}\" ) return None else : # Assuming template is remote to project and downloading it cfn_client = parent_stack . client tempate_body = cfn_client . get_template ( StackName = stack_properties [ \"StackId\" ] )[ \"TemplateBody\" ] path = parent_stack . template . project_root / Stack . REMOTE_TEMPLATE_PATH os . makedirs ( path , exist_ok = True ) fname = ( \"\" . join ( random . choice ( string . ascii_lowercase ) # nosec for _ in range ( 16 ) ) + \".template\" ) absolute_path = path / fname if not isinstance ( tempate_body , str ): tempate_body = ordered_dump ( tempate_body , dumper = yaml . SafeDumper ) if not absolute_path . exists (): with open ( absolute_path , \"w\" ) as fh : fh . write ( tempate_body ) template = Template ( template_path = str ( absolute_path ), project_root = parent_stack . template . project_root , url = url , template_cache = tcat_template_cache , ) stack = cls ( parent_stack . region , stack_properties [ \"StackId\" ], template , parent_stack . name , parent_stack . uuid , ) stack . set_stack_properties ( stack_properties ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to import child stack: {str(e)}\" ) LOG . debug ( \"traceback:\" , exc_info = True ) return None return stack @ classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ], template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO: get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id )[ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple [ str , Callable ]] = [ ( \"Parameters\" , Parameter ), ( \"Outputs\" , Output ), ( \"Tags\" , Tag ), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , []): item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items (): if key in [ p [ 0 ] for p in iterable_props ]: # noqa: C412 continue key = pascal_to_snake ( key ) . replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () @ staticmethod def _merge_props ( existing_props , new ): added = False for existing_id , prop in enumerate ( existing_props ): if prop . key == new . key : existing_props [ existing_id ] = new added = True if not added : existing_props . append ( new ) def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ): self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events @ staticmethod def _is_generic ( event : Event ) -> bool : generic = False for regex in GENERIC_ERROR_PATTERNS : if re . search ( regex , event . status_reason ): generic = True return generic def _fetch_stack_events ( self ) -> None : self . _last_event_refresh = datetime . now () events = Events () for page in self . client . get_paginator ( \"describe_stack_events\" ) . paginate ( StackName = self . id ): for event in page [ \"StackEvents\" ]: events . append ( Event ( event )) self . _events = events def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ): self . _fetch_stack_resources () return self . _resources def _fetch_stack_resources ( self ) -> None : self . _last_resource_refresh = datetime . now () resources = Resources () for page in self . client . get_paginator ( \"list_stack_resources\" ) . paginate ( StackName = self . id ): for resource in page [ \"StackResourceSummaries\" ]: resources . append ( Resource ( self . id , resource , self . test_name , self . uuid )) self . _resources = resources @ staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" ) def update ( self , * args , ** kwargs ): raise NotImplementedError ( \"Stack updates not implemented\" ) def _fetch_children ( self ) -> None : self . _last_child_refresh = datetime . now () for page in self . client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack in page [ \"Stacks\" ]: if self . _children . filter ( id = stack [ \"StackId\" ]): continue if \"ParentId\" in stack . keys (): if self . id == stack [ \"ParentId\" ]: stack_obj = Stack . _import_child ( stack , self ) if stack_obj : self . _children . append ( stack_obj ) def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ): self . _fetch_children () return self . _children def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ): descendants += stack . children () for child in stack . children (): descendants = recurse ( child , descendants ) return descendants return recurse ( self ) def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ([ self ]) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ) . filter ({ \"status\" : status }) return errors Class variables REMOTE_TEMPLATE_PATH Static methods create def create ( region : taskcat . _dataclasses . TestRegion , stack_name : str , template : taskcat . _cfn . template . Template , tags : List [ taskcat . _dataclasses . Tag ] = None , disable_rollback : bool = True , test_name : str = '' , uuid : uuid . UUID = None ) -> 'Stack' View Source @classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t.dump() for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options ) [ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack delete def delete ( client , stack_id ) -> None View Source @staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" ) import_existing def import_existing ( stack_properties : dict , template : taskcat . _cfn . template . Template , region : taskcat . _dataclasses . TestRegion , test_name : str , uid : uuid . UUID ) -> 'Stack' View Source @classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ] , template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack Instance variables launch_succeeded status Methods children def children ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ) : self . _fetch_children () return self . _children descendants def descendants ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ) : descendants += stack . children () for child in stack . children () : descendants = recurse ( child , descendants ) return descendants return recurse ( self ) error_events def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> taskcat . _cfn . stack . Events View Source def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ( [ self ] ) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ). filter ( { \"status\" : status } ) return errors events def events ( self , refresh : bool = False , include_generic : bool = True ) -> taskcat . _cfn . stack . Events View Source def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ) : self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events refresh def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False ) -> None View Source def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () resources def resources ( self , refresh : bool = False ) -> taskcat . _cfn . stack . Resources View Source def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ) : self . _fetch_stack_resources () return self . _resources set_stack_properties def set_stack_properties ( self , stack_properties : Union [ dict , NoneType ] = None ) -> None View Source def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO : get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id ) [ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple[str, Callable ] ] = [ (\"Parameters\", Parameter), (\"Outputs\", Output), (\"Tags\", Tag), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , [] ) : item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items () : if key in [ p[0 ] for p in iterable_props ]: # noqa : C412 continue key = pascal_to_snake ( key ). replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () update def update ( self , * args , ** kwargs ) View Source def update(self, *args, **kwargs): raise NotImplementedError(\"Stack updates not implemented\") Template class Template ( template_path : Union [ str , pathlib . Path ], project_root : Union [ str , pathlib . Path ] = '' , url : str = '' , s3_key_prefix : str = '' , template_cache : taskcat . _cfn . template . TemplateCache = < taskcat . _cfn . template . TemplateCache object at 0x10ee7c490 > ) View Source class Template : def __ init__ ( self , template_path: Union [ str , Path ], project_root: Union [ str , Path ] = \"\" , url : str = \"\" , s3_key_prefix: str = \"\" , template_cache: TemplateCache = tcat_template_cache , ) : self . template_cache = template_cache self . template_path: Path = Path ( template_path ). expanduser (). resolve () self . template = self . template_cache . get ( str ( self . template_path )) with open ( template_path , \"r\" ) as file_handle: self . raw_template = file_handle . read () project_root = ( project_root if project_root else self . template_path . parent . parent ) self . project_root = Path ( project_root ). expanduser (). resolve () self . url = url self . _ s3_key_prefix = s3_key_prefix self . children : List [ Template ] = [] self . _ find_children () def __ str__ ( self ) : return str ( self . template ) def __ repr__ ( self ) : return f \"<Template {self.template_path} at {hex(id(self))}>\" @property def s3_key ( self ) : suffix = str ( self . template_path . relative_to ( self . project_root ). as_posix ()) return self . _ s3_key_prefix + suffix @property def s3_key_prefix ( self ) : return self . _ s3_key_prefix @property def linesplit ( self ) : return self . raw_template . split ( \"\\n\" ) def write ( self ) : \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle: file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _ find_children () def _ template_url_to_path ( self , template_url , template_mappings = None , ) : try : helper = StackURLHelper ( template_mappings = template_mappings , template_parameters = self . template . get ( \"Parameters\" ), ) urls = helper . template_url_to_path ( current_template_path = self . template_path , template_url = template_url ) if len ( urls ) > 0 : return urls [ 0 ] except Exception as e : # pylint : disable = broad - except LOG . debug ( \"Traceback:\" , exc_info = True ) LOG . error ( \"TemplateURL parsing error: %s \" % str(e)) LOG . warning ( \"Failed to discover path for %s, path %s does not exist\" , template_url , None , ) return \"\" def _ get_relative_url ( self , path : str ) -> str : suffix = str ( path ). replace ( str ( self . project_root ), \"\" ) url = self . url_prefix () + suffix return url def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \")[0:-suffix_length]) return url_prefix def _find_children(self) -> None: # noqa: C901 children = set() if \" Resources \" not in self.template: raise TaskCatException( f\" did not receive a valid template : { self . template_path } does not \" f\" have a Resources section \" ) for resource in self.template[\" Resources \"].keys(): resource = self.template[\" Resources \"][resource] if resource[\" Type \"] == \" AWS :: CloudFormation :: Stack \": child_name = self._template_url_to_path( template_url=resource[\" Properties \"][\" TemplateURL \"], ) # print(child_name) if child_name: # for child_url in child_name: children.add(child_name) for child in children: child_template_instance = None for descendent in self.descendents: if str(descendent.template_path) == str(child): child_template_instance = descendent if not child_template_instance: try: child_template_instance = Template( child, self.project_root, self._get_relative_url(child), self._s3_key_prefix, tcat_template_cache, ) except Exception: # pylint: disable=broad-except LOG.debug(\" Traceback : \", exc_info=True) LOG.error(f\" Failed to add child template { child } \") if isinstance(child_template_instance, Template): self.children.append(child_template_instance) @property def descendents(self) -> List[\" Template \"]: desc_map = {} def recurse(template): for child in template.children: desc_map[str(child.template_path)] = child recurse(child) recurse(self) return list(desc_map.values()) def parameters( self, ) -> Dict[str, Union[None, str, int, bool, List[Union[int, str]]]]: parameters = {} for param_key, param in self.template.get(\" Parameters \", {}).items(): parameters[param_key] = param.get(\" Default \" ) return parameters Instance variables descendents linesplit s3_key s3_key_prefix Methods parameters def parameters ( self ) -> Dict [ str , Union [ NoneType , str , int , bool , List [ Union [ int , str ]]]] View Source def parameters ( self , ) -> Dict [ str, Union[None, str, int, bool, List[Union[int, str ] ]]]: parameters = {} for param_key , param in self . template . get ( \"Parameters\" , {} ). items () : parameters [ param_key ] = param . get ( \"Default\" ) return parameters url_prefix def url_prefix ( self ) -> str View Source def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \" )[ 0 :- suffix_length ]) return url_prefix write def write ( self ) writes raw_template back to file, and reloads decoded template, useful if the template has been modified View Source def write ( self ): \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle : file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _find_children ()","title":"Index"},{"location":"reference/taskcat/index.html#module-taskcat","text":"taskcat python module None View Source \"\"\" taskcat python module \"\"\" from ._cfn.stack import Stack # noqa: F401 from ._cfn.template import Template # noqa: F401 from ._cli import main # noqa: F401 from ._config import Config # noqa: F401 __all__ = [ \"Stack\" , \"Template\" , \"Config\" , \"main\" ]","title":"Module taskcat"},{"location":"reference/taskcat/index.html#sub-modules","text":"taskcat.exceptions taskcat.regions_to_partitions taskcat.testing","title":"Sub-modules"},{"location":"reference/taskcat/index.html#functions","text":"","title":"Functions"},{"location":"reference/taskcat/index.html#main","text":"def main ( cli_core_class =< class ' taskcat . _cli_core . CliCore '>, exit_func =< function exit_with_code at 0x112d519d0 > ) View Source def main ( cli_core_class = CliCore , exit_func = exit_with_code ): signal . signal ( signal . SIGINT , _sigint_handler ) log_level = _setup_logging ( sys . argv ) args = sys . argv [ 1 :] if not args : args . append ( \"-h\" ) try : _welcome () version = get_installed_version () cli = cli_core_class ( NAME , _cli_modules , DESCRIPTION , version , GLOBAL_ARGS . ARGS ) cli . parse ( args ) _default_profile = cli . parsed_args . __dict__ . get ( \"_profile\" ) if _default_profile : GLOBAL_ARGS . profile = _default_profile cli . run () except TaskCatException as e : LOG . error ( str ( e ), exc_info = _print_tracebacks ( log_level )) exit_func ( 1 ) except Exception as e : # pylint: disable=broad-except LOG . error ( \" %s %s \" , e . __class__ . __name__ , str ( e ), exc_info = _print_tracebacks ( log_level ) ) exit_func ( 1 )","title":"main"},{"location":"reference/taskcat/index.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/index.html#config","text":"class Config ( sources : list , uid : uuid . UUID , project_root : pathlib . Path ) View Source class Config : def __init__ ( self , sources : list , uid : uuid . UUID , project_root : Path ): self . config = BaseConfig . from_dict ( DEFAULTS ) self . config . set_source ( \"TASKCAT_DEFAULT\" ) self . project_root = project_root self . uid = uid for source in sources : config_dict : dict = source [ \"config\" ] source_name : str = source [ \"source\" ] source_config = BaseConfig . from_dict ( config_dict ) source_config . set_source ( source_name ) self . config = BaseConfig . merge ( self . config , source_config ) @ classmethod # pylint: disable=too-many-locals def create ( cls , template_file : Optional [ Path ] = None , args : Optional [ dict ] = None , global_config_path : Path = GENERAL , project_config_path : Path = PROJECT , overrides_path : Path = OVERRIDES , env_vars : Optional [ dict ] = None , project_root : Path = PROJECT_ROOT , uid : uuid . UUID = None , ) -> \"Config\" : uid = uid if uid else uuid . uuid4 () project_source = cls . _get_project_source ( cls , project_config_path , project_root , template_file ) # general legacy_overrides ( Path ( \"~/.aws/taskcat_global_override.json\" ) . expanduser () . resolve (), global_config_path , \"global\" , ) sources = [ { \"source\" : str ( global_config_path ), \"config\" : cls . _dict_from_file ( global_config_path ), } ] # project config file if project_source : sources . append ( project_source ) # template file if isinstance ( template_file , Path ): sources . append ( { \"source\" : str ( template_file ), \"config\" : cls . _dict_from_template ( template_file ), } ) # override file legacy_overrides ( project_root / \"ci/taskcat_project_override.json\" , overrides_path , \"project\" ) if overrides_path . is_file (): overrides = BaseConfig () . to_dict () with open ( str ( overrides_path ), \"r\" ) as file_handle : override_params = yaml . safe_load ( file_handle ) overrides [ \"project\" ][ \"parameters\" ] = override_params sources . append ({ \"source\" : str ( overrides_path ), \"config\" : overrides }) # environment variables sources . append ( { \"source\" : \"EnvoronmentVariable\" , \"config\" : cls . _dict_from_env_vars ( env_vars ), } ) # cli arguments if args : sources . append ({ \"source\" : \"CliArgument\" , \"config\" : args }) return cls ( sources = sources , uid = uid , project_root = project_root ) # pylint: disable=protected-access,inconsistent-return-statements @ staticmethod def _get_project_source ( base_cls , project_config_path , project_root , template_file ): try : return { \"source\" : str ( project_config_path ), \"config\" : base_cls . _dict_from_file ( project_config_path , fail_ok = False ), } except FileNotFoundError as e : error = e try : legacy_conf = parse_legacy_config ( project_root ) return { \"source\" : str ( project_root / \"ci/taskcat.yml\" ), \"config\" : legacy_conf . to_dict (), } except Exception as e : # pylint: disable=broad-except LOG . debug ( str ( e ), exc_info = True ) if not template_file : # pylint: disable=raise-missing-from raise error @ staticmethod def _dict_from_file ( file_path : Path , fail_ok = True ) -> dict : config_dict = BaseConfig () . to_dict () if not file_path . is_file () and fail_ok : return config_dict try : with open ( str ( file_path ), \"r\" ) as file_handle : config_dict = yaml . safe_load ( file_handle ) return config_dict except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"failed to load config from {file_path}\" ) LOG . debug ( str ( e ), exc_info = True ) if not fail_ok : raise e return config_dict @ staticmethod def _dict_from_template ( file_path : Path ) -> dict : relative_path = str ( file_path . relative_to ( PROJECT_ROOT )) config_dict = ( BaseConfig () . from_dict ( { \"project\" : { \"template\" : relative_path }, \"tests\" : { \"default\" : {}}} ) . to_dict () ) if not file_path . is_file (): raise TaskCatException ( f \"invalid template path {file_path}\" ) try : template = Template ( str ( file_path ), template_cache = tcat_template_cache ) . template except Exception as e : LOG . warning ( f \"failed to load template from {file_path}\" ) LOG . debug ( str ( e ), exc_info = True ) raise e if not template . get ( \"Metadata\" ): return config_dict if not template [ \"Metadata\" ] . get ( \"taskcat\" ): return config_dict template_config_dict = template [ \"Metadata\" ][ \"taskcat\" ] if not template_config_dict . get ( \"project\" ): template_config_dict [ \"project\" ] = {} template_config_dict [ \"project\" ][ \"template\" ] = relative_path if not template_config_dict . get ( \"tests\" ): template_config_dict [ \"tests\" ] = { \"default\" : {}} return template_config_dict # pylint: disable=protected-access @ staticmethod def _dict_from_env_vars ( env_vars : Optional [ Union [ os . _Environ , Dict [ str , str ]]] = None ): if env_vars is None : env_vars = os . environ config_dict : Dict [ str , Dict [ str , Union [ str , bool , int ]]] = {} for key , value in env_vars . items (): if key . startswith ( \"TASKCAT_\" ): key = key [ 8 :] . lower () sub_key = None key_section = None for section in [ \"general\" , \"project\" , \"tests\" ]: if key . startswith ( section ): sub_key = key [ len ( section ) + 1 :] key_section = section if isinstance ( sub_key , str ) and isinstance ( key_section , str ): if value . isnumeric (): value = int ( value ) elif value . lower () in [ \"true\" , \"false\" ]: value = value . lower () == \"true\" if not config_dict . get ( key_section ): config_dict [ key_section ] = {} config_dict [ key_section ][ sub_key ] = value return config_dict def get_regions ( self , boto3_cache : Boto3Cache = None ): if boto3_cache is None : boto3_cache = Boto3Cache () region_objects : Dict [ str , Dict [ str , RegionObj ]] = {} for test_name , test in self . config . tests . items (): region_objects [ test_name ] = {} for region in test . regions : # TODO: comon_utils/determine_profile_for_region profile = ( test . auth . get ( region , test . auth . get ( \"default\" , \"default\" )) if test . auth else \"default\" ) region_objects [ test_name ][ region ] = RegionObj ( name = region , account_id = boto3_cache . account_id ( profile ), partition = boto3_cache . partition ( profile ), profile = profile , _boto3_cache = boto3_cache , taskcat_id = self . uid , _role_name = test . role_name , ) return region_objects def get_buckets ( self , boto3_cache : Boto3Cache = None ): regions = self . get_regions ( boto3_cache ) bucket_objects : Dict [ str , S3BucketObj ] = {} bucket_mappings : Dict [ str , Dict [ str , S3BucketObj ]] = {} for test_name , test in self . config . tests . items (): bucket_mappings [ test_name ] = {} for region_name , region in regions [ test_name ] . items (): if test . s3_regional_buckets : bucket_obj = self . _create_regional_bucket_obj ( bucket_objects , region , test ) bucket_objects [ f \"{region.account_id}{region.name}\" ] = bucket_obj else : bucket_obj = self . _create_legacy_bucket_obj ( bucket_objects , region , test ) bucket_objects [ region . account_id ] = bucket_obj bucket_mappings [ test_name ][ region_name ] = bucket_obj return bucket_mappings def _create_legacy_bucket_obj ( self , bucket_objects , region , test ): new = False object_acl = ( self . config . project . s3_object_acl if self . config . project . s3_object_acl else \"private\" ) sigv4 = not self . config . project . s3_enable_sig_v2 if not test . s3_bucket and not bucket_objects . get ( region . account_id ): name = generate_bucket_name ( self . config . project . name ) auto_generated = True new = True elif bucket_objects . get ( region . account_id ): name = bucket_objects [ region . account_id ] . name auto_generated = bucket_objects [ region . account_id ] . auto_generated else : name = test . s3_bucket auto_generated = False bucket_region = self . _get_bucket_region_for_partition ( region . partition ) bucket_obj = S3BucketObj ( name = name , region = bucket_region , account_id = region . account_id , s3_client = region . session . client ( \"s3\" , region_name = bucket_region ), auto_generated = auto_generated , object_acl = object_acl , sigv4 = sigv4 , taskcat_id = self . uid , partition = region . partition , regional_buckets = test . s3_regional_buckets , ) if new : bucket_obj . create () return bucket_obj def _create_regional_bucket_obj ( self , bucket_objects , region , test ): _bucket_obj_key = f \"{region.account_id}{region.name}\" new = False object_acl = ( self . config . project . s3_object_acl if self . config . project . s3_object_acl else \"private\" ) sigv4 = not self . config . project . s3_enable_sig_v2 if not test . s3_bucket and not bucket_objects . get ( _bucket_obj_key ): name = generate_regional_bucket_name ( region ) auto_generated = True new = True elif bucket_objects . get ( _bucket_obj_key ): name = bucket_objects [ _bucket_obj_key ] . name auto_generated = bucket_objects [ _bucket_obj_key ] . auto_generated else : name = f \"{test.s3_bucket}-{region.name}\" auto_generated = False try : region . client ( \"s3\" ) . head_bucket ( Bucket = name ) except ClientError as e : if \"(404)\" in str ( e ): new = True else : raise bucket_obj = S3BucketObj ( name = name , region = region . name , account_id = region . account_id , s3_client = region . session . client ( \"s3\" , region_name = region . name ), auto_generated = auto_generated , object_acl = object_acl , sigv4 = sigv4 , taskcat_id = self . uid , partition = region . partition , regional_buckets = test . s3_regional_buckets , ) if new : bucket_obj . create () return bucket_obj @ staticmethod def _get_bucket_region_for_partition ( partition ): region = \"us-east-1\" if partition == \"aws-us-gov\" : region = \"us-gov-east-1\" elif partition == \"aws-cn\" : region = \"cn-north-1\" return region def get_rendered_parameters ( self , bucket_objects , region_objects , template_objects ): parameters = {} template_params = self . get_params_from_templates ( template_objects ) for test_name , test in self . config . tests . items (): parameters [ test_name ] = {} for region_name in test . regions : region_params = template_params [ test_name ] . copy () for param_key , param_value in test . parameters . items (): if param_key in region_params : region_params [ param_key ] = param_value region = region_objects [ test_name ][ region_name ] s3bucket = bucket_objects [ test_name ][ region_name ] parameters [ test_name ][ region_name ] = ParamGen ( region_params , s3bucket . name , region . name , region . client , self . config . project . name , test_name , test . az_blacklist , ) . results return parameters @ staticmethod def get_params_from_templates ( template_objects ): parameters = {} for test_name , template in template_objects . items (): parameters [ test_name ] = template . parameters () return parameters def get_templates ( self ): templates = {} for test_name , test in self . config . tests . items (): templates [ test_name ] = Template ( template_path = self . project_root / test . template , project_root = self . project_root , s3_key_prefix = f \"{self.config.project.name}/\" , template_cache = tcat_template_cache , ) return templates def get_tests ( self , templates , regions , buckets , parameters ): tests = {} for test_name , test in self . config . tests . items (): region_list = [] tag_list = [] if test . tags : for tag_key , tag_value in test . tags . items (): tag_list . append ( Tag ({ \"Key\" : tag_key , \"Value\" : tag_value })) for region_obj in regions [ test_name ] . values (): region_list . append ( TestRegion . from_region_obj ( region_obj , buckets [ test_name ][ region_obj . name ], parameters [ test_name ][ region_obj . name ], ) ) tests [ test_name ] = TestObj ( name = test_name , template_path = self . project_root / test . template , template = templates [ test_name ], project_root = self . project_root , regions = region_list , tags = tag_list , uid = self . uid , _project_name = self . config . project . name , _shorten_stack_name = self . config . project . shorten_stack_name , _stack_name = test . stack_name , _stack_name_prefix = test . stack_name_prefix , _stack_name_suffix = test . stack_name_suffix , ) return tests","title":"Config"},{"location":"reference/taskcat/index.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/index.html#create","text":"def create ( template_file : Union [ pathlib . Path , NoneType ] = None , args : Union [ dict , NoneType ] = None , global_config_path : pathlib . Path = PosixPath ( '/Users/andglenn/development/.local/.taskcat.yml' ), project_config_path : pathlib . Path = PosixPath ( '/Users/andglenn/development/tools/taskcat/.taskcat.yml' ), overrides_path : pathlib . Path = PosixPath ( '/Users/andglenn/development/tools/taskcat/.taskcat_overrides.yml' ), env_vars : Union [ dict , NoneType ] = None , project_root : pathlib . Path = PosixPath ( '/Users/andglenn/development/tools/taskcat' ), uid : uuid . UUID = None ) -> 'Config' View Source @ classmethod # pylint: disable=too-many-locals def create ( cls , template_file : Optional [ Path ] = None , args : Optional [ dict ] = None , global_config_path : Path = GENERAL , project_config_path : Path = PROJECT , overrides_path : Path = OVERRIDES , env_vars : Optional [ dict ] = None , project_root : Path = PROJECT_ROOT , uid : uuid . UUID = None , ) -> \"Config\" : uid = uid if uid else uuid . uuid4 () project_source = cls . _get_project_source ( cls , project_config_path , project_root , template_file ) # general legacy_overrides ( Path ( \"~/.aws/taskcat_global_override.json\" ) . expanduser () . resolve (), global_config_path , \"global\" , ) sources = [ { \"source\" : str ( global_config_path ), \"config\" : cls . _dict_from_file ( global_config_path ), } ] # project config file if project_source : sources . append ( project_source ) # template file if isinstance ( template_file , Path ): sources . append ( { \"source\" : str ( template_file ), \"config\" : cls . _dict_from_template ( template_file ), } ) # override file legacy_overrides ( project_root / \"ci/taskcat_project_override.json\" , overrides_path , \"project\" ) if overrides_path . is_file (): overrides = BaseConfig () . to_dict () with open ( str ( overrides_path ), \"r\" ) as file_handle : override_params = yaml . safe_load ( file_handle ) overrides [ \"project\" ][ \"parameters\" ] = override_params sources . append ({ \"source\" : str ( overrides_path ), \"config\" : overrides }) # environment variables sources . append ( { \"source\" : \"EnvoronmentVariable\" , \"config\" : cls . _dict_from_env_vars ( env_vars ), } ) # cli arguments if args : sources . append ({ \"source\" : \"CliArgument\" , \"config\" : args }) return cls ( sources = sources , uid = uid , project_root = project_root )","title":"create"},{"location":"reference/taskcat/index.html#get_params_from_templates","text":"def get_params_from_templates ( template_objects ) View Source @staticmethod def get_params_from_templates ( template_objects ) : parameters = {} for test_name , template in template_objects . items () : parameters [ test_name ] = template . parameters () return parameters","title":"get_params_from_templates"},{"location":"reference/taskcat/index.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/index.html#get_buckets","text":"def get_buckets ( self , boto3_cache : taskcat . _client_factory . Boto3Cache = None ) View Source def get_buckets ( self , boto3_cache : Boto3Cache = None ) : regions = self . get_regions ( boto3_cache ) bucket_objects : Dict [ str, S3BucketObj ] = {} bucket_mappings : Dict [ str, Dict[str, S3BucketObj ] ] = {} for test_name , test in self . config . tests . items () : bucket_mappings [ test_name ] = {} for region_name , region in regions [ test_name ] . items () : if test . s3_regional_buckets : bucket_obj = self . _create_regional_bucket_obj ( bucket_objects , region , test ) bucket_objects [ f\"{region.account_id}{region.name}\" ] = bucket_obj else : bucket_obj = self . _create_legacy_bucket_obj ( bucket_objects , region , test ) bucket_objects [ region.account_id ] = bucket_obj bucket_mappings [ test_name ][ region_name ] = bucket_obj return bucket_mappings","title":"get_buckets"},{"location":"reference/taskcat/index.html#get_regions","text":"def get_regions ( self , boto3_cache : taskcat . _client_factory . Boto3Cache = None ) View Source def get_regions ( self , boto3_cache : Boto3Cache = None ) : if boto3_cache is None : boto3_cache = Boto3Cache () region_objects : Dict [ str, Dict[str, RegionObj ] ] = {} for test_name , test in self . config . tests . items () : region_objects [ test_name ] = {} for region in test . regions : # TODO : comon_utils / determine_profile_for_region profile = ( test . auth . get ( region , test . auth . get ( \"default\" , \"default\" )) if test . auth else \"default\" ) region_objects [ test_name ][ region ] = RegionObj ( name = region , account_id = boto3_cache . account_id ( profile ), partition = boto3_cache . partition ( profile ), profile = profile , _boto3_cache = boto3_cache , taskcat_id = self . uid , _role_name = test . role_name , ) return region_objects","title":"get_regions"},{"location":"reference/taskcat/index.html#get_rendered_parameters","text":"def get_rendered_parameters ( self , bucket_objects , region_objects , template_objects ) View Source def get_rendered_parameters ( self , bucket_objects , region_objects , template_objects ) : parameters = {} template_params = self . get_params_from_templates ( template_objects ) for test_name , test in self . config . tests . items () : parameters [ test_name ] = {} for region_name in test . regions : region_params = template_params [ test_name ] . copy () for param_key , param_value in test . parameters . items () : if param_key in region_params : region_params [ param_key ] = param_value region = region_objects [ test_name ][ region_name ] s3bucket = bucket_objects [ test_name ][ region_name ] parameters [ test_name ][ region_name ] = ParamGen ( region_params , s3bucket . name , region . name , region . client , self . config . project . name , test_name , test . az_blacklist , ). results return parameters","title":"get_rendered_parameters"},{"location":"reference/taskcat/index.html#get_templates","text":"def get_templates ( self ) View Source def get_templates ( self ) : templates = {} for test_name , test in self . config . tests . items () : templates [ test_name ] = Template ( template_path = self . project_root / test . template , project_root = self . project_root , s3_key_prefix = f \"{self.config.project.name}/\" , template_cache = tcat_template_cache , ) return templates","title":"get_templates"},{"location":"reference/taskcat/index.html#get_tests","text":"def get_tests ( self , templates , regions , buckets , parameters ) View Source def get_tests ( self , templates , regions , buckets , parameters ) : tests = {} for test_name , test in self . config . tests . items () : region_list = [] tag_list = [] if test . tags : for tag_key , tag_value in test . tags . items () : tag_list . append ( Tag ( { \"Key\" : tag_key , \"Value\" : tag_value } )) for region_obj in regions [ test_name ] . values () : region_list . append ( TestRegion . from_region_obj ( region_obj , buckets [ test_name ][ region_obj.name ] , parameters [ test_name ][ region_obj.name ] , ) ) tests [ test_name ] = TestObj ( name = test_name , template_path = self . project_root / test . template , template = templates [ test_name ] , project_root = self . project_root , regions = region_list , tags = tag_list , uid = self . uid , _project_name = self . config . project . name , _shorten_stack_name = self . config . project . shorten_stack_name , _stack_name = test . stack_name , _stack_name_prefix = test . stack_name_prefix , _stack_name_suffix = test . stack_name_suffix , ) return tests","title":"get_tests"},{"location":"reference/taskcat/index.html#stack","text":"class Stack ( region : taskcat . _dataclasses . TestRegion , stack_id : str , template : taskcat . _cfn . template . Template , test_name , uuid : uuid . UUID = None ) View Source class Stack : # pylint: disable=too-many-instance-attributes REMOTE_TEMPLATE_PATH = Path ( \".taskcat/.remote_templates\" ) def __init__ ( self , region : TestRegion , stack_id : str , template : Template , test_name , uuid : UUID = None , ): uuid = uuid if uuid else uuid4 () self . test_name : str = test_name self . uuid : UUID = uuid self . id : str = stack_id self . template : Template = template self . name : str = self . _get_name () self . region : TestRegion = region self . region_name = region . name self . client : boto3 . client = region . client ( \"cloudformation\" ) self . completion_time : timedelta = timedelta ( 0 ) self . role_arn = region . role_arn # properties from additional cfn api calls self . _events : Events = Events () self . _resources : Resources = Resources () self . _children : Stacks = Stacks () # properties from describe_stacks response self . change_set_id : str = \"\" self . parameters : List [ Parameter ] = [] self . creation_time : datetime = datetime . fromtimestamp ( 0 ) self . deletion_time : datetime = datetime . fromtimestamp ( 0 ) self . _status : str = \"\" self . status_reason : str = \"\" self . disable_rollback : bool = False self . timeout_in_minutes : int = 0 self . capabilities : List [ str ] = [] self . outputs : List [ Output ] = [] self . tags : List [ Tag ] = [] self . parent_id : str = \"\" self . root_id : str = \"\" self . _launch_succeeded : bool = False self . _auto_refresh_interval : timedelta = timedelta ( seconds = 60 ) self . _last_event_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_resource_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_child_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () def __str__ ( self ): return self . id def __repr__ ( self ): return \"<Stack object {} at {}>\" . format ( self . name , hex ( id ( self ))) def _get_region ( self ) -> str : return self . id . split ( \":\" )[ 3 ] def _get_name ( self ) -> str : return self . id . split ( \":\" )[ 5 ] . split ( \"/\" )[ 1 ] def _auto_refresh ( self , last_refresh ): if datetime . now () - last_refresh > self . _auto_refresh_interval : return True return False @ property def status ( self ): if self . _status in StackStatus . COMPLETE : if not self . launch_succeeded : self . _status = \"OUT_OF_ORDER_EVENT\" self . status_reason = ( \"COMPLETE event not detected. \" + \"Potential out-of-band action against the stack.\" ) return self . _status @ status . setter def status ( self , status ): _complete = StackStatus . COMPLETE . copy () del _complete [ _complete . index ( \"DELETE_COMPLETE\" )] self . _status = status if status in StackStatus . FAILED : self . _launch_succeeded = False return if status in _complete : self . _launch_succeeded = True return return @ property def launch_succeeded ( self ): return self . _launch_succeeded @ classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t . dump () for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options )[ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack @ staticmethod def _cfn_format_parameters ( parameters ): return [{ \"ParameterKey\" : k , \"ParameterValue\" : v } for k , v in parameters . items ()] @ classmethod def _import_child ( # pylint: disable=too-many-locals cls , stack_properties : dict , parent_stack : \"Stack\" ) -> Optional [ \"Stack\" ]: try : url = \"\" for event in parent_stack . events (): if ( event . physical_id == stack_properties [ \"StackId\" ] and event . properties ): url = event . properties [ \"TemplateURL\" ] if url . startswith ( parent_stack . template . url_prefix ()): # Template is part of the project, discovering path relative_path = url . replace ( parent_stack . template . url_prefix (), \"\" ) . lstrip ( \"/\" ) absolute_path = parent_stack . template . project_root / relative_path if not absolute_path . is_file (): # try with the base folder stripped off relative_path2 = Path ( relative_path ) relative_path2 = relative_path2 . relative_to ( * relative_path2 . parts [: 1 ] ) absolute_path = parent_stack . template . project_root / relative_path2 if not absolute_path . is_file (): LOG . warning ( f \"Failed to find template for child stack \" f \"{stack_properties['StackId']}. tried \" f \"{parent_stack.template.project_root / relative_path}\" f \" and {absolute_path}\" ) return None else : # Assuming template is remote to project and downloading it cfn_client = parent_stack . client tempate_body = cfn_client . get_template ( StackName = stack_properties [ \"StackId\" ] )[ \"TemplateBody\" ] path = parent_stack . template . project_root / Stack . REMOTE_TEMPLATE_PATH os . makedirs ( path , exist_ok = True ) fname = ( \"\" . join ( random . choice ( string . ascii_lowercase ) # nosec for _ in range ( 16 ) ) + \".template\" ) absolute_path = path / fname if not isinstance ( tempate_body , str ): tempate_body = ordered_dump ( tempate_body , dumper = yaml . SafeDumper ) if not absolute_path . exists (): with open ( absolute_path , \"w\" ) as fh : fh . write ( tempate_body ) template = Template ( template_path = str ( absolute_path ), project_root = parent_stack . template . project_root , url = url , template_cache = tcat_template_cache , ) stack = cls ( parent_stack . region , stack_properties [ \"StackId\" ], template , parent_stack . name , parent_stack . uuid , ) stack . set_stack_properties ( stack_properties ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to import child stack: {str(e)}\" ) LOG . debug ( \"traceback:\" , exc_info = True ) return None return stack @ classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ], template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO: get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id )[ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple [ str , Callable ]] = [ ( \"Parameters\" , Parameter ), ( \"Outputs\" , Output ), ( \"Tags\" , Tag ), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , []): item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items (): if key in [ p [ 0 ] for p in iterable_props ]: # noqa: C412 continue key = pascal_to_snake ( key ) . replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () @ staticmethod def _merge_props ( existing_props , new ): added = False for existing_id , prop in enumerate ( existing_props ): if prop . key == new . key : existing_props [ existing_id ] = new added = True if not added : existing_props . append ( new ) def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ): self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events @ staticmethod def _is_generic ( event : Event ) -> bool : generic = False for regex in GENERIC_ERROR_PATTERNS : if re . search ( regex , event . status_reason ): generic = True return generic def _fetch_stack_events ( self ) -> None : self . _last_event_refresh = datetime . now () events = Events () for page in self . client . get_paginator ( \"describe_stack_events\" ) . paginate ( StackName = self . id ): for event in page [ \"StackEvents\" ]: events . append ( Event ( event )) self . _events = events def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ): self . _fetch_stack_resources () return self . _resources def _fetch_stack_resources ( self ) -> None : self . _last_resource_refresh = datetime . now () resources = Resources () for page in self . client . get_paginator ( \"list_stack_resources\" ) . paginate ( StackName = self . id ): for resource in page [ \"StackResourceSummaries\" ]: resources . append ( Resource ( self . id , resource , self . test_name , self . uuid )) self . _resources = resources @ staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" ) def update ( self , * args , ** kwargs ): raise NotImplementedError ( \"Stack updates not implemented\" ) def _fetch_children ( self ) -> None : self . _last_child_refresh = datetime . now () for page in self . client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack in page [ \"Stacks\" ]: if self . _children . filter ( id = stack [ \"StackId\" ]): continue if \"ParentId\" in stack . keys (): if self . id == stack [ \"ParentId\" ]: stack_obj = Stack . _import_child ( stack , self ) if stack_obj : self . _children . append ( stack_obj ) def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ): self . _fetch_children () return self . _children def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ): descendants += stack . children () for child in stack . children (): descendants = recurse ( child , descendants ) return descendants return recurse ( self ) def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ([ self ]) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ) . filter ({ \"status\" : status }) return errors","title":"Stack"},{"location":"reference/taskcat/index.html#class-variables","text":"REMOTE_TEMPLATE_PATH","title":"Class variables"},{"location":"reference/taskcat/index.html#static-methods_1","text":"","title":"Static methods"},{"location":"reference/taskcat/index.html#create_1","text":"def create ( region : taskcat . _dataclasses . TestRegion , stack_name : str , template : taskcat . _cfn . template . Template , tags : List [ taskcat . _dataclasses . Tag ] = None , disable_rollback : bool = True , test_name : str = '' , uuid : uuid . UUID = None ) -> 'Stack' View Source @classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t.dump() for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options ) [ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack","title":"create"},{"location":"reference/taskcat/index.html#delete","text":"def delete ( client , stack_id ) -> None View Source @staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" )","title":"delete"},{"location":"reference/taskcat/index.html#import_existing","text":"def import_existing ( stack_properties : dict , template : taskcat . _cfn . template . Template , region : taskcat . _dataclasses . TestRegion , test_name : str , uid : uuid . UUID ) -> 'Stack' View Source @classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ] , template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack","title":"import_existing"},{"location":"reference/taskcat/index.html#instance-variables","text":"launch_succeeded status","title":"Instance variables"},{"location":"reference/taskcat/index.html#methods_1","text":"","title":"Methods"},{"location":"reference/taskcat/index.html#children","text":"def children ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ) : self . _fetch_children () return self . _children","title":"children"},{"location":"reference/taskcat/index.html#descendants","text":"def descendants ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ) : descendants += stack . children () for child in stack . children () : descendants = recurse ( child , descendants ) return descendants return recurse ( self )","title":"descendants"},{"location":"reference/taskcat/index.html#error_events","text":"def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> taskcat . _cfn . stack . Events View Source def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ( [ self ] ) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ). filter ( { \"status\" : status } ) return errors","title":"error_events"},{"location":"reference/taskcat/index.html#events","text":"def events ( self , refresh : bool = False , include_generic : bool = True ) -> taskcat . _cfn . stack . Events View Source def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ) : self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events","title":"events"},{"location":"reference/taskcat/index.html#refresh","text":"def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False ) -> None View Source def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now ()","title":"refresh"},{"location":"reference/taskcat/index.html#resources","text":"def resources ( self , refresh : bool = False ) -> taskcat . _cfn . stack . Resources View Source def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ) : self . _fetch_stack_resources () return self . _resources","title":"resources"},{"location":"reference/taskcat/index.html#set_stack_properties","text":"def set_stack_properties ( self , stack_properties : Union [ dict , NoneType ] = None ) -> None View Source def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO : get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id ) [ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple[str, Callable ] ] = [ (\"Parameters\", Parameter), (\"Outputs\", Output), (\"Tags\", Tag), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , [] ) : item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items () : if key in [ p[0 ] for p in iterable_props ]: # noqa : C412 continue key = pascal_to_snake ( key ). replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start ()","title":"set_stack_properties"},{"location":"reference/taskcat/index.html#update","text":"def update ( self , * args , ** kwargs ) View Source def update(self, *args, **kwargs): raise NotImplementedError(\"Stack updates not implemented\")","title":"update"},{"location":"reference/taskcat/index.html#template","text":"class Template ( template_path : Union [ str , pathlib . Path ], project_root : Union [ str , pathlib . Path ] = '' , url : str = '' , s3_key_prefix : str = '' , template_cache : taskcat . _cfn . template . TemplateCache = < taskcat . _cfn . template . TemplateCache object at 0x10ee7c490 > ) View Source class Template : def __ init__ ( self , template_path: Union [ str , Path ], project_root: Union [ str , Path ] = \"\" , url : str = \"\" , s3_key_prefix: str = \"\" , template_cache: TemplateCache = tcat_template_cache , ) : self . template_cache = template_cache self . template_path: Path = Path ( template_path ). expanduser (). resolve () self . template = self . template_cache . get ( str ( self . template_path )) with open ( template_path , \"r\" ) as file_handle: self . raw_template = file_handle . read () project_root = ( project_root if project_root else self . template_path . parent . parent ) self . project_root = Path ( project_root ). expanduser (). resolve () self . url = url self . _ s3_key_prefix = s3_key_prefix self . children : List [ Template ] = [] self . _ find_children () def __ str__ ( self ) : return str ( self . template ) def __ repr__ ( self ) : return f \"<Template {self.template_path} at {hex(id(self))}>\" @property def s3_key ( self ) : suffix = str ( self . template_path . relative_to ( self . project_root ). as_posix ()) return self . _ s3_key_prefix + suffix @property def s3_key_prefix ( self ) : return self . _ s3_key_prefix @property def linesplit ( self ) : return self . raw_template . split ( \"\\n\" ) def write ( self ) : \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle: file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _ find_children () def _ template_url_to_path ( self , template_url , template_mappings = None , ) : try : helper = StackURLHelper ( template_mappings = template_mappings , template_parameters = self . template . get ( \"Parameters\" ), ) urls = helper . template_url_to_path ( current_template_path = self . template_path , template_url = template_url ) if len ( urls ) > 0 : return urls [ 0 ] except Exception as e : # pylint : disable = broad - except LOG . debug ( \"Traceback:\" , exc_info = True ) LOG . error ( \"TemplateURL parsing error: %s \" % str(e)) LOG . warning ( \"Failed to discover path for %s, path %s does not exist\" , template_url , None , ) return \"\" def _ get_relative_url ( self , path : str ) -> str : suffix = str ( path ). replace ( str ( self . project_root ), \"\" ) url = self . url_prefix () + suffix return url def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \")[0:-suffix_length]) return url_prefix def _find_children(self) -> None: # noqa: C901 children = set() if \" Resources \" not in self.template: raise TaskCatException( f\" did not receive a valid template : { self . template_path } does not \" f\" have a Resources section \" ) for resource in self.template[\" Resources \"].keys(): resource = self.template[\" Resources \"][resource] if resource[\" Type \"] == \" AWS :: CloudFormation :: Stack \": child_name = self._template_url_to_path( template_url=resource[\" Properties \"][\" TemplateURL \"], ) # print(child_name) if child_name: # for child_url in child_name: children.add(child_name) for child in children: child_template_instance = None for descendent in self.descendents: if str(descendent.template_path) == str(child): child_template_instance = descendent if not child_template_instance: try: child_template_instance = Template( child, self.project_root, self._get_relative_url(child), self._s3_key_prefix, tcat_template_cache, ) except Exception: # pylint: disable=broad-except LOG.debug(\" Traceback : \", exc_info=True) LOG.error(f\" Failed to add child template { child } \") if isinstance(child_template_instance, Template): self.children.append(child_template_instance) @property def descendents(self) -> List[\" Template \"]: desc_map = {} def recurse(template): for child in template.children: desc_map[str(child.template_path)] = child recurse(child) recurse(self) return list(desc_map.values()) def parameters( self, ) -> Dict[str, Union[None, str, int, bool, List[Union[int, str]]]]: parameters = {} for param_key, param in self.template.get(\" Parameters \", {}).items(): parameters[param_key] = param.get(\" Default \" ) return parameters","title":"Template"},{"location":"reference/taskcat/index.html#instance-variables_1","text":"descendents linesplit s3_key s3_key_prefix","title":"Instance variables"},{"location":"reference/taskcat/index.html#methods_2","text":"","title":"Methods"},{"location":"reference/taskcat/index.html#parameters","text":"def parameters ( self ) -> Dict [ str , Union [ NoneType , str , int , bool , List [ Union [ int , str ]]]] View Source def parameters ( self , ) -> Dict [ str, Union[None, str, int, bool, List[Union[int, str ] ]]]: parameters = {} for param_key , param in self . template . get ( \"Parameters\" , {} ). items () : parameters [ param_key ] = param . get ( \"Default\" ) return parameters","title":"parameters"},{"location":"reference/taskcat/index.html#url_prefix","text":"def url_prefix ( self ) -> str View Source def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \" )[ 0 :- suffix_length ]) return url_prefix","title":"url_prefix"},{"location":"reference/taskcat/index.html#write","text":"def write ( self ) writes raw_template back to file, and reloads decoded template, useful if the template has been modified View Source def write ( self ): \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle : file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _find_children ()","title":"write"},{"location":"reference/taskcat/exceptions.html","text":"Module taskcat.exceptions None None View Source class TaskCatException ( Exception ): \"\"\"Raised when taskcat experiences a fatal error\"\"\" class InvalidActionError ( TaskCatException ): \"\"\"Exception raised for error when invalid action is supplied Attributes: expression -- input expression in which the error occurred \"\"\" def __init__ ( self , expression ): self . expression = expression super (). __init__ () Classes InvalidActionError class InvalidActionError ( expression ) Exception raised for error when invalid action is supplied Attributes: expression -- input expression in which the error occurred View Source class InvalidActionError ( TaskCatException ): \"\"\"Exception raised for error when invalid action is supplied Attributes: expression -- input expression in which the error occurred \"\"\" def __init__ ( self , expression ): self . expression = expression super (). __init__ () Ancestors (in MRO) taskcat.exceptions.TaskCatException builtins.Exception builtins.BaseException Class variables args Methods with_traceback def with_traceback ( ... ) Exception.with_traceback(tb) -- set self. traceback to tb and return self. TaskCatException class TaskCatException ( / , * args , ** kwargs ) View Source class TaskCatException ( Exception ): \"\"\"Raised when taskcat experiences a fatal error\"\"\" Ancestors (in MRO) builtins.Exception builtins.BaseException Descendants taskcat.exceptions.InvalidActionError taskcat._s3_stage.S3BucketCreatorException taskcat._amiupdater.AMIUpdaterFatalException taskcat._amiupdater.AMIUpdaterCommitNeededException Class variables args Methods with_traceback def with_traceback ( ... ) Exception.with_traceback(tb) -- set self. traceback to tb and return self.","title":"Exceptions"},{"location":"reference/taskcat/exceptions.html#module-taskcatexceptions","text":"None None View Source class TaskCatException ( Exception ): \"\"\"Raised when taskcat experiences a fatal error\"\"\" class InvalidActionError ( TaskCatException ): \"\"\"Exception raised for error when invalid action is supplied Attributes: expression -- input expression in which the error occurred \"\"\" def __init__ ( self , expression ): self . expression = expression super (). __init__ ()","title":"Module taskcat.exceptions"},{"location":"reference/taskcat/exceptions.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/exceptions.html#invalidactionerror","text":"class InvalidActionError ( expression ) Exception raised for error when invalid action is supplied Attributes: expression -- input expression in which the error occurred View Source class InvalidActionError ( TaskCatException ): \"\"\"Exception raised for error when invalid action is supplied Attributes: expression -- input expression in which the error occurred \"\"\" def __init__ ( self , expression ): self . expression = expression super (). __init__ ()","title":"InvalidActionError"},{"location":"reference/taskcat/exceptions.html#ancestors-in-mro","text":"taskcat.exceptions.TaskCatException builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/exceptions.html#class-variables","text":"args","title":"Class variables"},{"location":"reference/taskcat/exceptions.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/exceptions.html#with_traceback","text":"def with_traceback ( ... ) Exception.with_traceback(tb) -- set self. traceback to tb and return self.","title":"with_traceback"},{"location":"reference/taskcat/exceptions.html#taskcatexception","text":"class TaskCatException ( / , * args , ** kwargs ) View Source class TaskCatException ( Exception ): \"\"\"Raised when taskcat experiences a fatal error\"\"\"","title":"TaskCatException"},{"location":"reference/taskcat/exceptions.html#ancestors-in-mro_1","text":"builtins.Exception builtins.BaseException","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/exceptions.html#descendants","text":"taskcat.exceptions.InvalidActionError taskcat._s3_stage.S3BucketCreatorException taskcat._amiupdater.AMIUpdaterFatalException taskcat._amiupdater.AMIUpdaterCommitNeededException","title":"Descendants"},{"location":"reference/taskcat/exceptions.html#class-variables_1","text":"args","title":"Class variables"},{"location":"reference/taskcat/exceptions.html#methods_1","text":"","title":"Methods"},{"location":"reference/taskcat/exceptions.html#with_traceback_1","text":"def with_traceback ( ... ) Exception.with_traceback(tb) -- set self. traceback to tb and return self.","title":"with_traceback"},{"location":"reference/taskcat/regions_to_partitions.html","text":"Module taskcat.regions_to_partitions None None View Source REGIONS = { \"af-south-1\": \"aws\", \"ap-east-1\": \"aws\", \"ap-northeast-1\": \"aws\", \"ap-northeast-2\": \"aws\", \"ap-northeast-3\": \"aws\", \"ap-south-1\": \"aws\", \"ap-southeast-1\": \"aws\", \"ap-southeast-2\": \"aws\", \"ca-central-1\": \"aws\", \"eu-central-1\": \"aws\", \"eu-north-1\": \"aws\", \"eu-south-1\": \"aws\", \"eu-west-1\": \"aws\", \"eu-west-2\": \"aws\", \"eu-west-3\": \"aws\", \"me-south-1\": \"aws\", \"sa-east-1\": \"aws\", \"us-east-1\": \"aws\", \"us-east-2\": \"aws\", \"us-west-1\": \"aws\", \"us-west-2\": \"aws\", \"cn-north-1\": \"aws-cn\", \"cn-northwest-1\": \"aws-cn\", \"us-gov-east-1\": \"aws-us-gov\", \"us-gov-west-1\": \"aws-us-gov\", \"us-iso-east-1\": \"aws-iso\", \"us-isob-east-1\": \"aws-iso-b\" } PARTITIONS = { \"aws\": [ \"af-south-1\", \"ap-east-1\", \"ap-northeast-1\", \"ap-northeast-2\", \"ap-northeast-3\", \"ap-south-1\", \"ap-southeast-1\", \"ap-southeast-2\", \"ca-central-1\", \"eu-central-1\", \"eu-north-1\", \"eu-south-1\", \"eu-west-1\", \"eu-west-2\", \"eu-west-3\", \"me-south-1\", \"sa-east-1\", \"us-east-1\", \"us-east-2\", \"us-west-1\", \"us-west-2\" ], \"aws-cn\": [ \"cn-north-1\", \"cn-northwest-1\" ], \"aws-us-gov\": [ \"us-gov-east-1\", \"us-gov-west-1\" ], \"aws-iso\": [ \"us-iso-east-1\" ], \"aws-iso-b\": [ \"us-isob-east-1\" ] } Variables PARTITIONS REGIONS","title":"Regions To Partitions"},{"location":"reference/taskcat/regions_to_partitions.html#module-taskcatregions_to_partitions","text":"None None View Source REGIONS = { \"af-south-1\": \"aws\", \"ap-east-1\": \"aws\", \"ap-northeast-1\": \"aws\", \"ap-northeast-2\": \"aws\", \"ap-northeast-3\": \"aws\", \"ap-south-1\": \"aws\", \"ap-southeast-1\": \"aws\", \"ap-southeast-2\": \"aws\", \"ca-central-1\": \"aws\", \"eu-central-1\": \"aws\", \"eu-north-1\": \"aws\", \"eu-south-1\": \"aws\", \"eu-west-1\": \"aws\", \"eu-west-2\": \"aws\", \"eu-west-3\": \"aws\", \"me-south-1\": \"aws\", \"sa-east-1\": \"aws\", \"us-east-1\": \"aws\", \"us-east-2\": \"aws\", \"us-west-1\": \"aws\", \"us-west-2\": \"aws\", \"cn-north-1\": \"aws-cn\", \"cn-northwest-1\": \"aws-cn\", \"us-gov-east-1\": \"aws-us-gov\", \"us-gov-west-1\": \"aws-us-gov\", \"us-iso-east-1\": \"aws-iso\", \"us-isob-east-1\": \"aws-iso-b\" } PARTITIONS = { \"aws\": [ \"af-south-1\", \"ap-east-1\", \"ap-northeast-1\", \"ap-northeast-2\", \"ap-northeast-3\", \"ap-south-1\", \"ap-southeast-1\", \"ap-southeast-2\", \"ca-central-1\", \"eu-central-1\", \"eu-north-1\", \"eu-south-1\", \"eu-west-1\", \"eu-west-2\", \"eu-west-3\", \"me-south-1\", \"sa-east-1\", \"us-east-1\", \"us-east-2\", \"us-west-1\", \"us-west-2\" ], \"aws-cn\": [ \"cn-north-1\", \"cn-northwest-1\" ], \"aws-us-gov\": [ \"us-gov-east-1\", \"us-gov-west-1\" ], \"aws-iso\": [ \"us-iso-east-1\" ], \"aws-iso-b\": [ \"us-isob-east-1\" ] }","title":"Module taskcat.regions_to_partitions"},{"location":"reference/taskcat/regions_to_partitions.html#variables","text":"PARTITIONS REGIONS","title":"Variables"},{"location":"reference/taskcat/_cfn/index.html","text":"Module taskcat._cfn None None Sub-modules taskcat._cfn.stack taskcat._cfn.stack_url_helper taskcat._cfn.template taskcat._cfn.threaded","title":"Index"},{"location":"reference/taskcat/_cfn/index.html#module-taskcat_cfn","text":"None None","title":"Module taskcat._cfn"},{"location":"reference/taskcat/_cfn/index.html#sub-modules","text":"taskcat._cfn.stack taskcat._cfn.stack_url_helper taskcat._cfn.template taskcat._cfn.threaded","title":"Sub-modules"},{"location":"reference/taskcat/_cfn/stack.html","text":"Module taskcat._cfn.stack None None View Source import json import logging import os import random import re import string from datetime import datetime , timedelta from pathlib import Path from threading import Timer from typing import Callable , List , Optional , Tuple from uuid import UUID , uuid4 import boto3 import yaml from taskcat._cfn.template import Template , tcat_template_cache from taskcat._common_utils import ordered_dump , pascal_to_snake , s3_url_maker from taskcat._dataclasses import Tag , TestRegion LOG = logging . getLogger ( __name__ ) GENERIC_ERROR_PATTERNS = [ r \"(The following resource\\(s\\) failed to create: )\" , r \"(^Resource creation cancelled$)\" , ] def criteria_matches ( criteria : dict , instance ): # fail if criteria includes an invalid property for k in criteria : if not hasattr ( instance , k ): raise ValueError ( f \" { k } is not a valid property of { type ( instance ) } \" ) for k , v in criteria . items (): # matching is AND for multiple criteria, so as soon as one fails, # it's not a match if getattr ( instance , k ) != v : return False return True class StackStatus : COMPLETE = [ \"CREATE_COMPLETE\" , \"UPDATE_COMPLETE\" , \"DELETE_COMPLETE\" ] IN_PROGRESS = [ \"CREATE_IN_PROGRESS\" , \"DELETE_IN_PROGRESS\" , \"UPDATE_IN_PROGRESS\" , \"UPDATE_COMPLETE_CLEANUP_IN_PROGRESS\" , ] FAILED = [ \"DELETE_FAILED\" , \"CREATE_FAILED\" , \"ROLLBACK_IN_PROGRESS\" , \"ROLLBACK_FAILED\" , \"ROLLBACK_COMPLETE\" , \"UPDATE_ROLLBACK_IN_PROGRESS\" , \"UPDATE_ROLLBACK_FAILED\" , \"UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS\" , \"UPDATE_ROLLBACK_COMPLETE\" , \"OUT_OF_ORDER_EVENT\" , ] class Capabilities : IAM = \"CAPABILITY_IAM\" NAMED_IAM = \"CAPABILITY_NAMED_IAM\" AUTO_EXPAND = \"CAPABILITY_AUTO_EXPAND\" ALL = [ IAM , NAMED_IAM , AUTO_EXPAND ] class Event : def __init__ ( self , event_dict : dict ): self . event_id : str = event_dict [ \"EventId\" ] self . stack_name : str = event_dict [ \"StackName\" ] self . logical_id : str = event_dict [ \"LogicalResourceId\" ] self . type : str = event_dict [ \"ResourceType\" ] self . status : str = event_dict [ \"ResourceStatus\" ] self . physical_id : str = \"\" self . timestamp : datetime = datetime . fromtimestamp ( 0 ) self . status_reason : str = \"\" self . properties : dict = {} if \"PhysicalResourceId\" in event_dict . keys (): self . physical_id = event_dict [ \"PhysicalResourceId\" ] if \"Timestamp\" in event_dict . keys (): self . timestamp = event_dict [ \"Timestamp\" ] if \"ResourceStatusReason\" in event_dict . keys (): self . status_reason = event_dict [ \"ResourceStatusReason\" ] if \"ResourceProperties\" in event_dict . keys (): self . properties = json . loads ( event_dict [ \"ResourceProperties\" ]) def __str__ ( self ): return \" {} {} {} \" . format ( self . timestamp , self . logical_id , self . status ) def __repr__ ( self ): return \"<Event object {} at {} >\" . format ( self . event_id , hex ( id ( self ))) class Resource : def __init__ ( self , stack_id : str , resource_dict : dict , test_name : str = \"\" , uuid : UUID = None ): uuid = uuid if uuid else uuid4 () self . stack_id : str = stack_id self . test_name : str = test_name self . uuid : UUID = uuid self . logical_id : str = resource_dict [ \"LogicalResourceId\" ] self . type : str = resource_dict [ \"ResourceType\" ] self . status : str = resource_dict [ \"ResourceStatus\" ] self . physical_id : str = \"\" self . last_updated_timestamp : datetime = datetime . fromtimestamp ( 0 ) self . status_reason : str = \"\" if \"PhysicalResourceId\" in resource_dict . keys (): self . physical_id = resource_dict [ \"PhysicalResourceId\" ] if \"LastUpdatedTimestamp\" in resource_dict . keys (): self . last_updated_timestamp = resource_dict [ \"LastUpdatedTimestamp\" ] if \"ResourceStatusReason\" in resource_dict . keys (): self . status_reason = resource_dict [ \"ResourceStatusReason\" ] def __str__ ( self ): return \"<Resource {} {} >\" . format ( self . logical_id , self . status ) class Parameter : def __init__ ( self , param_dict : dict ): self . key : str = param_dict [ \"ParameterKey\" ] self . value : str = \"\" self . raw_value : str = \"\" self . use_previous_value : bool = False self . resolved_value : str = \"\" if \"ParameterValue\" in param_dict . keys (): self . value = param_dict [ \"ParameterValue\" ] if \"UsePreviousValue\" in param_dict . keys (): self . use_previous_value = param_dict [ \"UsePreviousValue\" ] if \"ResolvedValue\" in param_dict . keys (): self . resolved_value = param_dict [ \"ResolvedValue\" ] if self . value and not self . raw_value : self . raw_value = self . value def dump ( self ): param_dict = { \"ParameterKey\" : self . key } if self . value : param_dict [ \"ParameterValue\" ] = self . value if self . use_previous_value : param_dict [ \"UsePreviousValue\" ] = self . use_previous_value return param_dict class Output : def __init__ ( self , output_dict : dict ): self . key : str = output_dict [ \"OutputKey\" ] self . value : str = output_dict [ \"OutputValue\" ] self . description : str = \"\" self . export_name : str = \"\" if \"Description\" in output_dict . keys (): self . description = output_dict [ \"Description\" ] if \"ExportName\" in output_dict . keys (): self . export_name = output_dict [ \"ExportName\" ] class FilterableList ( list ): def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ): if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ): flist . append ( item ) return flist class Stacks ( FilterableList ): pass class Resources ( FilterableList ): pass class Events ( FilterableList ): pass class Tags ( FilterableList ): pass class Stack : # pylint: disable=too-many-instance-attributes REMOTE_TEMPLATE_PATH = Path ( \".taskcat/.remote_templates\" ) def __init__ ( self , region : TestRegion , stack_id : str , template : Template , test_name , uuid : UUID = None , ): uuid = uuid if uuid else uuid4 () self . test_name : str = test_name self . uuid : UUID = uuid self . id : str = stack_id self . template : Template = template self . name : str = self . _get_name () self . region : TestRegion = region self . region_name = region . name self . client : boto3 . client = region . client ( \"cloudformation\" ) self . completion_time : timedelta = timedelta ( 0 ) self . role_arn = region . role_arn # properties from additional cfn api calls self . _events : Events = Events () self . _resources : Resources = Resources () self . _children : Stacks = Stacks () # properties from describe_stacks response self . change_set_id : str = \"\" self . parameters : List [ Parameter ] = [] self . creation_time : datetime = datetime . fromtimestamp ( 0 ) self . deletion_time : datetime = datetime . fromtimestamp ( 0 ) self . _status : str = \"\" self . status_reason : str = \"\" self . disable_rollback : bool = False self . timeout_in_minutes : int = 0 self . capabilities : List [ str ] = [] self . outputs : List [ Output ] = [] self . tags : List [ Tag ] = [] self . parent_id : str = \"\" self . root_id : str = \"\" self . _launch_succeeded : bool = False self . _auto_refresh_interval : timedelta = timedelta ( seconds = 60 ) self . _last_event_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_resource_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_child_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () def __str__ ( self ): return self . id def __repr__ ( self ): return \"<Stack object {} at {} >\" . format ( self . name , hex ( id ( self ))) def _get_region ( self ) -> str : return self . id . split ( \":\" )[ 3 ] def _get_name ( self ) -> str : return self . id . split ( \":\" )[ 5 ] . split ( \"/\" )[ 1 ] def _auto_refresh ( self , last_refresh ): if datetime . now () - last_refresh > self . _auto_refresh_interval : return True return False @property def status ( self ): if self . _status in StackStatus . COMPLETE : if not self . launch_succeeded : self . _status = \"OUT_OF_ORDER_EVENT\" self . status_reason = ( \"COMPLETE event not detected. \" + \"Potential out-of-band action against the stack.\" ) return self . _status @status . setter def status ( self , status ): _complete = StackStatus . COMPLETE . copy () del _complete [ _complete . index ( \"DELETE_COMPLETE\" )] self . _status = status if status in StackStatus . FAILED : self . _launch_succeeded = False return if status in _complete : self . _launch_succeeded = True return return @property def launch_succeeded ( self ): return self . _launch_succeeded @classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t . dump () for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options )[ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack @staticmethod def _cfn_format_parameters ( parameters ): return [{ \"ParameterKey\" : k , \"ParameterValue\" : v } for k , v in parameters . items ()] @classmethod def _import_child ( # pylint: disable=too-many-locals cls , stack_properties : dict , parent_stack : \"Stack\" ) -> Optional [ \"Stack\" ]: try : url = \"\" for event in parent_stack . events (): if ( event . physical_id == stack_properties [ \"StackId\" ] and event . properties ): url = event . properties [ \"TemplateURL\" ] if url . startswith ( parent_stack . template . url_prefix ()): # Template is part of the project, discovering path relative_path = url . replace ( parent_stack . template . url_prefix (), \"\" ) . lstrip ( \"/\" ) absolute_path = parent_stack . template . project_root / relative_path if not absolute_path . is_file (): # try with the base folder stripped off relative_path2 = Path ( relative_path ) relative_path2 = relative_path2 . relative_to ( * relative_path2 . parts [: 1 ] ) absolute_path = parent_stack . template . project_root / relative_path2 if not absolute_path . is_file (): LOG . warning ( f \"Failed to find template for child stack \" f \" { stack_properties [ 'StackId' ] } . tried \" f \" { parent_stack . template . project_root / relative_path } \" f \" and { absolute_path } \" ) return None else : # Assuming template is remote to project and downloading it cfn_client = parent_stack . client tempate_body = cfn_client . get_template ( StackName = stack_properties [ \"StackId\" ] )[ \"TemplateBody\" ] path = parent_stack . template . project_root / Stack . REMOTE_TEMPLATE_PATH os . makedirs ( path , exist_ok = True ) fname = ( \"\" . join ( random . choice ( string . ascii_lowercase ) # nosec for _ in range ( 16 ) ) + \".template\" ) absolute_path = path / fname if not isinstance ( tempate_body , str ): tempate_body = ordered_dump ( tempate_body , dumper = yaml . SafeDumper ) if not absolute_path . exists (): with open ( absolute_path , \"w\" ) as fh : fh . write ( tempate_body ) template = Template ( template_path = str ( absolute_path ), project_root = parent_stack . template . project_root , url = url , template_cache = tcat_template_cache , ) stack = cls ( parent_stack . region , stack_properties [ \"StackId\" ], template , parent_stack . name , parent_stack . uuid , ) stack . set_stack_properties ( stack_properties ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to import child stack: { str ( e ) } \" ) LOG . debug ( \"traceback:\" , exc_info = True ) return None return stack @classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ], template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO: get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id )[ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple [ str , Callable ]] = [ ( \"Parameters\" , Parameter ), ( \"Outputs\" , Output ), ( \"Tags\" , Tag ), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , []): item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items (): if key in [ p [ 0 ] for p in iterable_props ]: # noqa: C412 continue key = pascal_to_snake ( key ) . replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () @staticmethod def _merge_props ( existing_props , new ): added = False for existing_id , prop in enumerate ( existing_props ): if prop . key == new . key : existing_props [ existing_id ] = new added = True if not added : existing_props . append ( new ) def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ): self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events @staticmethod def _is_generic ( event : Event ) -> bool : generic = False for regex in GENERIC_ERROR_PATTERNS : if re . search ( regex , event . status_reason ): generic = True return generic def _fetch_stack_events ( self ) -> None : self . _last_event_refresh = datetime . now () events = Events () for page in self . client . get_paginator ( \"describe_stack_events\" ) . paginate ( StackName = self . id ): for event in page [ \"StackEvents\" ]: events . append ( Event ( event )) self . _events = events def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ): self . _fetch_stack_resources () return self . _resources def _fetch_stack_resources ( self ) -> None : self . _last_resource_refresh = datetime . now () resources = Resources () for page in self . client . get_paginator ( \"list_stack_resources\" ) . paginate ( StackName = self . id ): for resource in page [ \"StackResourceSummaries\" ]: resources . append ( Resource ( self . id , resource , self . test_name , self . uuid )) self . _resources = resources @staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: { stack_id } \" ) def update ( self , * args , ** kwargs ): raise NotImplementedError ( \"Stack updates not implemented\" ) def _fetch_children ( self ) -> None : self . _last_child_refresh = datetime . now () for page in self . client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack in page [ \"Stacks\" ]: if self . _children . filter ( id = stack [ \"StackId\" ]): continue if \"ParentId\" in stack . keys (): if self . id == stack [ \"ParentId\" ]: stack_obj = Stack . _import_child ( stack , self ) if stack_obj : self . _children . append ( stack_obj ) def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ): self . _fetch_children () return self . _children def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ): descendants += stack . children () for child in stack . children (): descendants = recurse ( child , descendants ) return descendants return recurse ( self ) def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ([ self ]) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ) . filter ({ \"status\" : status }) return errors Variables GENERIC_ERROR_PATTERNS LOG Functions criteria_matches def criteria_matches ( criteria : dict , instance ) View Source def criteria_matches ( criteria : dict , instance ) : # fail if criteria includes an invalid property for k in criteria : if not hasattr ( instance , k ) : raise ValueError ( f \" {k} is not a valid property of {type(instance)} \" ) for k , v in criteria . items () : # matching is AND for multiple criteria , so as soon as one fails , # it ' s not a match if getattr ( instance , k ) != v : return False return True Classes Capabilities class Capabilities ( / , * args , ** kwargs ) View Source class Capabilities: IAM = \"CAPABILITY_IAM\" NAMED_IAM = \"CAPABILITY_NAMED_IAM\" AUTO_EXPAND = \"CAPABILITY_AUTO_EXPAND\" ALL = [ IAM , NAMED_IAM , AUTO_EXPAND ] Class variables ALL AUTO_EXPAND IAM NAMED_IAM Event class Event ( event_dict : dict ) View Source class Event : def __init__ ( self , event_dict : dict ): self . event_id : str = event_dict [ \"EventId\" ] self . stack_name : str = event_dict [ \"StackName\" ] self . logical_id : str = event_dict [ \"LogicalResourceId\" ] self . type : str = event_dict [ \"ResourceType\" ] self . status : str = event_dict [ \"ResourceStatus\" ] self . physical_id : str = \"\" self . timestamp : datetime = datetime . fromtimestamp ( 0 ) self . status_reason : str = \"\" self . properties : dict = {} if \"PhysicalResourceId\" in event_dict . keys (): self . physical_id = event_dict [ \"PhysicalResourceId\" ] if \"Timestamp\" in event_dict . keys (): self . timestamp = event_dict [ \"Timestamp\" ] if \"ResourceStatusReason\" in event_dict . keys (): self . status_reason = event_dict [ \"ResourceStatusReason\" ] if \"ResourceProperties\" in event_dict . keys (): self . properties = json . loads ( event_dict [ \"ResourceProperties\" ]) def __str__ ( self ): return \"{} {} {}\" . format ( self . timestamp , self . logical_id , self . status ) def __repr__ ( self ): return \"<Event object {} at {}>\" . format ( self . event_id , hex ( id ( self ))) Events class Events ( / , * args , ** kwargs ) View Source class Events ( FilterableList ): pass Ancestors (in MRO) taskcat._cfn.stack.FilterableList builtins.list Methods append def append ( self , object , / ) Append object to the end of the list. clear def clear ( self , / ) Remove all items from list. copy def copy ( self , / ) Return a shallow copy of the list. count def count ( self , value , / ) Return number of occurrences of value. extend def extend ( self , iterable , / ) Extend list by appending elements from the iterable. filter def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. insert def insert ( self , index , object , / ) Insert object before index. pop def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range. remove def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present. reverse def reverse ( self , / ) Reverse IN PLACE . sort def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order. FilterableList class FilterableList ( / , * args , ** kwargs ) View Source class FilterableList ( list ) : def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist Ancestors (in MRO) builtins.list Descendants taskcat._cfn.stack.Stacks taskcat._cfn.stack.Resources taskcat._cfn.stack.Events taskcat._cfn.stack.Tags Methods append def append ( self , object , / ) Append object to the end of the list. clear def clear ( self , / ) Remove all items from list. copy def copy ( self , / ) Return a shallow copy of the list. count def count ( self , value , / ) Return number of occurrences of value. extend def extend ( self , iterable , / ) Extend list by appending elements from the iterable. filter def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. insert def insert ( self , index , object , / ) Insert object before index. pop def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range. remove def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present. reverse def reverse ( self , / ) Reverse IN PLACE . sort def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order. Output class Output ( output_dict : dict ) View Source class Output : def __init__ ( self , output_dict : dict ): self . key : str = output_dict [ \"OutputKey\" ] self . value : str = output_dict [ \"OutputValue\" ] self . description : str = \"\" self . export_name : str = \"\" if \"Description\" in output_dict . keys (): self . description = output_dict [ \"Description\" ] if \"ExportName\" in output_dict . keys (): self . export_name = output_dict [ \"ExportName\" ] Parameter class Parameter ( param_dict : dict ) View Source class Parameter: def __init__ ( self , param_dict: dict ): self . key: str = param_dict [ \"ParameterKey\" ] self . value: str = \"\" self . raw_value: str = \"\" self . use_previous_value: bool = False self . resolved_value: str = \"\" if \"ParameterValue\" in param_dict . keys (): self . value = param_dict [ \"ParameterValue\" ] if \"UsePreviousValue\" in param_dict . keys (): self . use_previous_value = param_dict [ \"UsePreviousValue\" ] if \"ResolvedValue\" in param_dict . keys (): self . resolved_value = param_dict [ \"ResolvedValue\" ] if self . value and not self . raw_value: self . raw_value = self . value def dump ( self ): param_dict = { \"ParameterKey\" : self . key } if self . value: param_dict [ \"ParameterValue\" ] = self . value if self . use_previous_value: param_dict [ \"UsePreviousValue\" ] = self . use_previous_value return param_dict Methods dump def dump ( self ) View Source def dump ( self ) : param_dict = { \" ParameterKey \" : self . key } if self . value : param_dict [ \" ParameterValue \" ] = self . value if self . use_previous_value : param_dict [ \" UsePreviousValue \" ] = self . use_previous_value return param_dict Resource class Resource ( stack_id : str , resource_dict : dict , test_name : str = '' , uuid : uuid . UUID = None ) View Source class Resource: def __init__ ( self , stack_id: str , resource_dict: dict , test_name: str = \"\" , uuid: UUID = None ): uuid = uuid if uuid else uuid4 () self . stack_id: str = stack_id self . test_name: str = test_name self . uuid: UUID = uuid self . logical_id: str = resource_dict [ \"LogicalResourceId\" ] self . type: str = resource_dict [ \"ResourceType\" ] self . status: str = resource_dict [ \"ResourceStatus\" ] self . physical_id: str = \"\" self . last_updated_timestamp: datetime = datetime . fromtimestamp ( 0 ) self . status_reason: str = \"\" if \"PhysicalResourceId\" in resource_dict . keys (): self . physical_id = resource_dict [ \"PhysicalResourceId\" ] if \"LastUpdatedTimestamp\" in resource_dict . keys (): self . last_updated_timestamp = resource_dict [ \"LastUpdatedTimestamp\" ] if \"ResourceStatusReason\" in resource_dict . keys (): self . status_reason = resource_dict [ \"ResourceStatusReason\" ] def __str__ ( self ): return \"<Resource {} {}>\" . format ( self . logical_id , self . status ) Resources class Resources ( / , * args , ** kwargs ) View Source class Resources ( FilterableList ): pass Ancestors (in MRO) taskcat._cfn.stack.FilterableList builtins.list Methods append def append ( self , object , / ) Append object to the end of the list. clear def clear ( self , / ) Remove all items from list. copy def copy ( self , / ) Return a shallow copy of the list. count def count ( self , value , / ) Return number of occurrences of value. extend def extend ( self , iterable , / ) Extend list by appending elements from the iterable. filter def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. insert def insert ( self , index , object , / ) Insert object before index. pop def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range. remove def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present. reverse def reverse ( self , / ) Reverse IN PLACE . sort def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order. Stack class Stack ( region : taskcat . _dataclasses . TestRegion , stack_id : str , template : taskcat . _cfn . template . Template , test_name , uuid : uuid . UUID = None ) View Source class Stack : # pylint: disable=too-many-instance-attributes REMOTE_TEMPLATE_PATH = Path ( \".taskcat/.remote_templates\" ) def __init__ ( self , region : TestRegion , stack_id : str , template : Template , test_name , uuid : UUID = None , ): uuid = uuid if uuid else uuid4 () self . test_name : str = test_name self . uuid : UUID = uuid self . id : str = stack_id self . template : Template = template self . name : str = self . _get_name () self . region : TestRegion = region self . region_name = region . name self . client : boto3 . client = region . client ( \"cloudformation\" ) self . completion_time : timedelta = timedelta ( 0 ) self . role_arn = region . role_arn # properties from additional cfn api calls self . _events : Events = Events () self . _resources : Resources = Resources () self . _children : Stacks = Stacks () # properties from describe_stacks response self . change_set_id : str = \"\" self . parameters : List [ Parameter ] = [] self . creation_time : datetime = datetime . fromtimestamp ( 0 ) self . deletion_time : datetime = datetime . fromtimestamp ( 0 ) self . _status : str = \"\" self . status_reason : str = \"\" self . disable_rollback : bool = False self . timeout_in_minutes : int = 0 self . capabilities : List [ str ] = [] self . outputs : List [ Output ] = [] self . tags : List [ Tag ] = [] self . parent_id : str = \"\" self . root_id : str = \"\" self . _launch_succeeded : bool = False self . _auto_refresh_interval : timedelta = timedelta ( seconds = 60 ) self . _last_event_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_resource_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_child_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () def __str__ ( self ): return self . id def __repr__ ( self ): return \"<Stack object {} at {}>\" . format ( self . name , hex ( id ( self ))) def _get_region ( self ) -> str : return self . id . split ( \":\" )[ 3 ] def _get_name ( self ) -> str : return self . id . split ( \":\" )[ 5 ] . split ( \"/\" )[ 1 ] def _auto_refresh ( self , last_refresh ): if datetime . now () - last_refresh > self . _auto_refresh_interval : return True return False @ property def status ( self ): if self . _status in StackStatus . COMPLETE : if not self . launch_succeeded : self . _status = \"OUT_OF_ORDER_EVENT\" self . status_reason = ( \"COMPLETE event not detected. \" + \"Potential out-of-band action against the stack.\" ) return self . _status @ status . setter def status ( self , status ): _complete = StackStatus . COMPLETE . copy () del _complete [ _complete . index ( \"DELETE_COMPLETE\" )] self . _status = status if status in StackStatus . FAILED : self . _launch_succeeded = False return if status in _complete : self . _launch_succeeded = True return return @ property def launch_succeeded ( self ): return self . _launch_succeeded @ classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t . dump () for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options )[ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack @ staticmethod def _cfn_format_parameters ( parameters ): return [{ \"ParameterKey\" : k , \"ParameterValue\" : v } for k , v in parameters . items ()] @ classmethod def _import_child ( # pylint: disable=too-many-locals cls , stack_properties : dict , parent_stack : \"Stack\" ) -> Optional [ \"Stack\" ]: try : url = \"\" for event in parent_stack . events (): if ( event . physical_id == stack_properties [ \"StackId\" ] and event . properties ): url = event . properties [ \"TemplateURL\" ] if url . startswith ( parent_stack . template . url_prefix ()): # Template is part of the project, discovering path relative_path = url . replace ( parent_stack . template . url_prefix (), \"\" ) . lstrip ( \"/\" ) absolute_path = parent_stack . template . project_root / relative_path if not absolute_path . is_file (): # try with the base folder stripped off relative_path2 = Path ( relative_path ) relative_path2 = relative_path2 . relative_to ( * relative_path2 . parts [: 1 ] ) absolute_path = parent_stack . template . project_root / relative_path2 if not absolute_path . is_file (): LOG . warning ( f \"Failed to find template for child stack \" f \"{stack_properties['StackId']}. tried \" f \"{parent_stack.template.project_root / relative_path}\" f \" and {absolute_path}\" ) return None else : # Assuming template is remote to project and downloading it cfn_client = parent_stack . client tempate_body = cfn_client . get_template ( StackName = stack_properties [ \"StackId\" ] )[ \"TemplateBody\" ] path = parent_stack . template . project_root / Stack . REMOTE_TEMPLATE_PATH os . makedirs ( path , exist_ok = True ) fname = ( \"\" . join ( random . choice ( string . ascii_lowercase ) # nosec for _ in range ( 16 ) ) + \".template\" ) absolute_path = path / fname if not isinstance ( tempate_body , str ): tempate_body = ordered_dump ( tempate_body , dumper = yaml . SafeDumper ) if not absolute_path . exists (): with open ( absolute_path , \"w\" ) as fh : fh . write ( tempate_body ) template = Template ( template_path = str ( absolute_path ), project_root = parent_stack . template . project_root , url = url , template_cache = tcat_template_cache , ) stack = cls ( parent_stack . region , stack_properties [ \"StackId\" ], template , parent_stack . name , parent_stack . uuid , ) stack . set_stack_properties ( stack_properties ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to import child stack: {str(e)}\" ) LOG . debug ( \"traceback:\" , exc_info = True ) return None return stack @ classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ], template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO: get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id )[ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple [ str , Callable ]] = [ ( \"Parameters\" , Parameter ), ( \"Outputs\" , Output ), ( \"Tags\" , Tag ), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , []): item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items (): if key in [ p [ 0 ] for p in iterable_props ]: # noqa: C412 continue key = pascal_to_snake ( key ) . replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () @ staticmethod def _merge_props ( existing_props , new ): added = False for existing_id , prop in enumerate ( existing_props ): if prop . key == new . key : existing_props [ existing_id ] = new added = True if not added : existing_props . append ( new ) def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ): self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events @ staticmethod def _is_generic ( event : Event ) -> bool : generic = False for regex in GENERIC_ERROR_PATTERNS : if re . search ( regex , event . status_reason ): generic = True return generic def _fetch_stack_events ( self ) -> None : self . _last_event_refresh = datetime . now () events = Events () for page in self . client . get_paginator ( \"describe_stack_events\" ) . paginate ( StackName = self . id ): for event in page [ \"StackEvents\" ]: events . append ( Event ( event )) self . _events = events def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ): self . _fetch_stack_resources () return self . _resources def _fetch_stack_resources ( self ) -> None : self . _last_resource_refresh = datetime . now () resources = Resources () for page in self . client . get_paginator ( \"list_stack_resources\" ) . paginate ( StackName = self . id ): for resource in page [ \"StackResourceSummaries\" ]: resources . append ( Resource ( self . id , resource , self . test_name , self . uuid )) self . _resources = resources @ staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" ) def update ( self , * args , ** kwargs ): raise NotImplementedError ( \"Stack updates not implemented\" ) def _fetch_children ( self ) -> None : self . _last_child_refresh = datetime . now () for page in self . client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack in page [ \"Stacks\" ]: if self . _children . filter ( id = stack [ \"StackId\" ]): continue if \"ParentId\" in stack . keys (): if self . id == stack [ \"ParentId\" ]: stack_obj = Stack . _import_child ( stack , self ) if stack_obj : self . _children . append ( stack_obj ) def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ): self . _fetch_children () return self . _children def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ): descendants += stack . children () for child in stack . children (): descendants = recurse ( child , descendants ) return descendants return recurse ( self ) def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ([ self ]) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ) . filter ({ \"status\" : status }) return errors Class variables REMOTE_TEMPLATE_PATH Static methods create def create ( region : taskcat . _dataclasses . TestRegion , stack_name : str , template : taskcat . _cfn . template . Template , tags : List [ taskcat . _dataclasses . Tag ] = None , disable_rollback : bool = True , test_name : str = '' , uuid : uuid . UUID = None ) -> 'Stack' View Source @classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t.dump() for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options ) [ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack delete def delete ( client , stack_id ) -> None View Source @staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" ) import_existing def import_existing ( stack_properties : dict , template : taskcat . _cfn . template . Template , region : taskcat . _dataclasses . TestRegion , test_name : str , uid : uuid . UUID ) -> 'Stack' View Source @classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ] , template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack Instance variables launch_succeeded status Methods children def children ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ) : self . _fetch_children () return self . _children descendants def descendants ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ) : descendants += stack . children () for child in stack . children () : descendants = recurse ( child , descendants ) return descendants return recurse ( self ) error_events def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> taskcat . _cfn . stack . Events View Source def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ( [ self ] ) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ). filter ( { \"status\" : status } ) return errors events def events ( self , refresh : bool = False , include_generic : bool = True ) -> taskcat . _cfn . stack . Events View Source def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ) : self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events refresh def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False ) -> None View Source def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () resources def resources ( self , refresh : bool = False ) -> taskcat . _cfn . stack . Resources View Source def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ) : self . _fetch_stack_resources () return self . _resources set_stack_properties def set_stack_properties ( self , stack_properties : Union [ dict , NoneType ] = None ) -> None View Source def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO : get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id ) [ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple[str, Callable ] ] = [ (\"Parameters\", Parameter), (\"Outputs\", Output), (\"Tags\", Tag), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , [] ) : item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items () : if key in [ p[0 ] for p in iterable_props ]: # noqa : C412 continue key = pascal_to_snake ( key ). replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () update def update ( self , * args , ** kwargs ) View Source def update(self, *args, **kwargs): raise NotImplementedError(\"Stack updates not implemented\") StackStatus class StackStatus ( / , * args , ** kwargs ) View Source class StackStatus: COMPLETE = [ \"CREATE_COMPLETE\" , \"UPDATE_COMPLETE\" , \"DELETE_COMPLETE\" ] IN_PROGRESS = [ \"CREATE_IN_PROGRESS\" , \"DELETE_IN_PROGRESS\" , \"UPDATE_IN_PROGRESS\" , \"UPDATE_COMPLETE_CLEANUP_IN_PROGRESS\" , ] FAILED = [ \"DELETE_FAILED\" , \"CREATE_FAILED\" , \"ROLLBACK_IN_PROGRESS\" , \"ROLLBACK_FAILED\" , \"ROLLBACK_COMPLETE\" , \"UPDATE_ROLLBACK_IN_PROGRESS\" , \"UPDATE_ROLLBACK_FAILED\" , \"UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS\" , \"UPDATE_ROLLBACK_COMPLETE\" , \"OUT_OF_ORDER_EVENT\" , ] Class variables COMPLETE FAILED IN_PROGRESS Stacks class Stacks ( / , * args , ** kwargs ) View Source class Stacks ( FilterableList ): pass Ancestors (in MRO) taskcat._cfn.stack.FilterableList builtins.list Methods append def append ( self , object , / ) Append object to the end of the list. clear def clear ( self , / ) Remove all items from list. copy def copy ( self , / ) Return a shallow copy of the list. count def count ( self , value , / ) Return number of occurrences of value. extend def extend ( self , iterable , / ) Extend list by appending elements from the iterable. filter def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. insert def insert ( self , index , object , / ) Insert object before index. pop def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range. remove def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present. reverse def reverse ( self , / ) Reverse IN PLACE . sort def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order. Tags class Tags ( / , * args , ** kwargs ) View Source class Tags ( FilterableList ): pass Ancestors (in MRO) taskcat._cfn.stack.FilterableList builtins.list Methods append def append ( self , object , / ) Append object to the end of the list. clear def clear ( self , / ) Remove all items from list. copy def copy ( self , / ) Return a shallow copy of the list. count def count ( self , value , / ) Return number of occurrences of value. extend def extend ( self , iterable , / ) Extend list by appending elements from the iterable. filter def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist index def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present. insert def insert ( self , index , object , / ) Insert object before index. pop def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range. remove def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present. reverse def reverse ( self , / ) Reverse IN PLACE . sort def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order.","title":"Stack"},{"location":"reference/taskcat/_cfn/stack.html#module-taskcat_cfnstack","text":"None None View Source import json import logging import os import random import re import string from datetime import datetime , timedelta from pathlib import Path from threading import Timer from typing import Callable , List , Optional , Tuple from uuid import UUID , uuid4 import boto3 import yaml from taskcat._cfn.template import Template , tcat_template_cache from taskcat._common_utils import ordered_dump , pascal_to_snake , s3_url_maker from taskcat._dataclasses import Tag , TestRegion LOG = logging . getLogger ( __name__ ) GENERIC_ERROR_PATTERNS = [ r \"(The following resource\\(s\\) failed to create: )\" , r \"(^Resource creation cancelled$)\" , ] def criteria_matches ( criteria : dict , instance ): # fail if criteria includes an invalid property for k in criteria : if not hasattr ( instance , k ): raise ValueError ( f \" { k } is not a valid property of { type ( instance ) } \" ) for k , v in criteria . items (): # matching is AND for multiple criteria, so as soon as one fails, # it's not a match if getattr ( instance , k ) != v : return False return True class StackStatus : COMPLETE = [ \"CREATE_COMPLETE\" , \"UPDATE_COMPLETE\" , \"DELETE_COMPLETE\" ] IN_PROGRESS = [ \"CREATE_IN_PROGRESS\" , \"DELETE_IN_PROGRESS\" , \"UPDATE_IN_PROGRESS\" , \"UPDATE_COMPLETE_CLEANUP_IN_PROGRESS\" , ] FAILED = [ \"DELETE_FAILED\" , \"CREATE_FAILED\" , \"ROLLBACK_IN_PROGRESS\" , \"ROLLBACK_FAILED\" , \"ROLLBACK_COMPLETE\" , \"UPDATE_ROLLBACK_IN_PROGRESS\" , \"UPDATE_ROLLBACK_FAILED\" , \"UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS\" , \"UPDATE_ROLLBACK_COMPLETE\" , \"OUT_OF_ORDER_EVENT\" , ] class Capabilities : IAM = \"CAPABILITY_IAM\" NAMED_IAM = \"CAPABILITY_NAMED_IAM\" AUTO_EXPAND = \"CAPABILITY_AUTO_EXPAND\" ALL = [ IAM , NAMED_IAM , AUTO_EXPAND ] class Event : def __init__ ( self , event_dict : dict ): self . event_id : str = event_dict [ \"EventId\" ] self . stack_name : str = event_dict [ \"StackName\" ] self . logical_id : str = event_dict [ \"LogicalResourceId\" ] self . type : str = event_dict [ \"ResourceType\" ] self . status : str = event_dict [ \"ResourceStatus\" ] self . physical_id : str = \"\" self . timestamp : datetime = datetime . fromtimestamp ( 0 ) self . status_reason : str = \"\" self . properties : dict = {} if \"PhysicalResourceId\" in event_dict . keys (): self . physical_id = event_dict [ \"PhysicalResourceId\" ] if \"Timestamp\" in event_dict . keys (): self . timestamp = event_dict [ \"Timestamp\" ] if \"ResourceStatusReason\" in event_dict . keys (): self . status_reason = event_dict [ \"ResourceStatusReason\" ] if \"ResourceProperties\" in event_dict . keys (): self . properties = json . loads ( event_dict [ \"ResourceProperties\" ]) def __str__ ( self ): return \" {} {} {} \" . format ( self . timestamp , self . logical_id , self . status ) def __repr__ ( self ): return \"<Event object {} at {} >\" . format ( self . event_id , hex ( id ( self ))) class Resource : def __init__ ( self , stack_id : str , resource_dict : dict , test_name : str = \"\" , uuid : UUID = None ): uuid = uuid if uuid else uuid4 () self . stack_id : str = stack_id self . test_name : str = test_name self . uuid : UUID = uuid self . logical_id : str = resource_dict [ \"LogicalResourceId\" ] self . type : str = resource_dict [ \"ResourceType\" ] self . status : str = resource_dict [ \"ResourceStatus\" ] self . physical_id : str = \"\" self . last_updated_timestamp : datetime = datetime . fromtimestamp ( 0 ) self . status_reason : str = \"\" if \"PhysicalResourceId\" in resource_dict . keys (): self . physical_id = resource_dict [ \"PhysicalResourceId\" ] if \"LastUpdatedTimestamp\" in resource_dict . keys (): self . last_updated_timestamp = resource_dict [ \"LastUpdatedTimestamp\" ] if \"ResourceStatusReason\" in resource_dict . keys (): self . status_reason = resource_dict [ \"ResourceStatusReason\" ] def __str__ ( self ): return \"<Resource {} {} >\" . format ( self . logical_id , self . status ) class Parameter : def __init__ ( self , param_dict : dict ): self . key : str = param_dict [ \"ParameterKey\" ] self . value : str = \"\" self . raw_value : str = \"\" self . use_previous_value : bool = False self . resolved_value : str = \"\" if \"ParameterValue\" in param_dict . keys (): self . value = param_dict [ \"ParameterValue\" ] if \"UsePreviousValue\" in param_dict . keys (): self . use_previous_value = param_dict [ \"UsePreviousValue\" ] if \"ResolvedValue\" in param_dict . keys (): self . resolved_value = param_dict [ \"ResolvedValue\" ] if self . value and not self . raw_value : self . raw_value = self . value def dump ( self ): param_dict = { \"ParameterKey\" : self . key } if self . value : param_dict [ \"ParameterValue\" ] = self . value if self . use_previous_value : param_dict [ \"UsePreviousValue\" ] = self . use_previous_value return param_dict class Output : def __init__ ( self , output_dict : dict ): self . key : str = output_dict [ \"OutputKey\" ] self . value : str = output_dict [ \"OutputValue\" ] self . description : str = \"\" self . export_name : str = \"\" if \"Description\" in output_dict . keys (): self . description = output_dict [ \"Description\" ] if \"ExportName\" in output_dict . keys (): self . export_name = output_dict [ \"ExportName\" ] class FilterableList ( list ): def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ): if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ): flist . append ( item ) return flist class Stacks ( FilterableList ): pass class Resources ( FilterableList ): pass class Events ( FilterableList ): pass class Tags ( FilterableList ): pass class Stack : # pylint: disable=too-many-instance-attributes REMOTE_TEMPLATE_PATH = Path ( \".taskcat/.remote_templates\" ) def __init__ ( self , region : TestRegion , stack_id : str , template : Template , test_name , uuid : UUID = None , ): uuid = uuid if uuid else uuid4 () self . test_name : str = test_name self . uuid : UUID = uuid self . id : str = stack_id self . template : Template = template self . name : str = self . _get_name () self . region : TestRegion = region self . region_name = region . name self . client : boto3 . client = region . client ( \"cloudformation\" ) self . completion_time : timedelta = timedelta ( 0 ) self . role_arn = region . role_arn # properties from additional cfn api calls self . _events : Events = Events () self . _resources : Resources = Resources () self . _children : Stacks = Stacks () # properties from describe_stacks response self . change_set_id : str = \"\" self . parameters : List [ Parameter ] = [] self . creation_time : datetime = datetime . fromtimestamp ( 0 ) self . deletion_time : datetime = datetime . fromtimestamp ( 0 ) self . _status : str = \"\" self . status_reason : str = \"\" self . disable_rollback : bool = False self . timeout_in_minutes : int = 0 self . capabilities : List [ str ] = [] self . outputs : List [ Output ] = [] self . tags : List [ Tag ] = [] self . parent_id : str = \"\" self . root_id : str = \"\" self . _launch_succeeded : bool = False self . _auto_refresh_interval : timedelta = timedelta ( seconds = 60 ) self . _last_event_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_resource_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_child_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () def __str__ ( self ): return self . id def __repr__ ( self ): return \"<Stack object {} at {} >\" . format ( self . name , hex ( id ( self ))) def _get_region ( self ) -> str : return self . id . split ( \":\" )[ 3 ] def _get_name ( self ) -> str : return self . id . split ( \":\" )[ 5 ] . split ( \"/\" )[ 1 ] def _auto_refresh ( self , last_refresh ): if datetime . now () - last_refresh > self . _auto_refresh_interval : return True return False @property def status ( self ): if self . _status in StackStatus . COMPLETE : if not self . launch_succeeded : self . _status = \"OUT_OF_ORDER_EVENT\" self . status_reason = ( \"COMPLETE event not detected. \" + \"Potential out-of-band action against the stack.\" ) return self . _status @status . setter def status ( self , status ): _complete = StackStatus . COMPLETE . copy () del _complete [ _complete . index ( \"DELETE_COMPLETE\" )] self . _status = status if status in StackStatus . FAILED : self . _launch_succeeded = False return if status in _complete : self . _launch_succeeded = True return return @property def launch_succeeded ( self ): return self . _launch_succeeded @classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t . dump () for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options )[ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack @staticmethod def _cfn_format_parameters ( parameters ): return [{ \"ParameterKey\" : k , \"ParameterValue\" : v } for k , v in parameters . items ()] @classmethod def _import_child ( # pylint: disable=too-many-locals cls , stack_properties : dict , parent_stack : \"Stack\" ) -> Optional [ \"Stack\" ]: try : url = \"\" for event in parent_stack . events (): if ( event . physical_id == stack_properties [ \"StackId\" ] and event . properties ): url = event . properties [ \"TemplateURL\" ] if url . startswith ( parent_stack . template . url_prefix ()): # Template is part of the project, discovering path relative_path = url . replace ( parent_stack . template . url_prefix (), \"\" ) . lstrip ( \"/\" ) absolute_path = parent_stack . template . project_root / relative_path if not absolute_path . is_file (): # try with the base folder stripped off relative_path2 = Path ( relative_path ) relative_path2 = relative_path2 . relative_to ( * relative_path2 . parts [: 1 ] ) absolute_path = parent_stack . template . project_root / relative_path2 if not absolute_path . is_file (): LOG . warning ( f \"Failed to find template for child stack \" f \" { stack_properties [ 'StackId' ] } . tried \" f \" { parent_stack . template . project_root / relative_path } \" f \" and { absolute_path } \" ) return None else : # Assuming template is remote to project and downloading it cfn_client = parent_stack . client tempate_body = cfn_client . get_template ( StackName = stack_properties [ \"StackId\" ] )[ \"TemplateBody\" ] path = parent_stack . template . project_root / Stack . REMOTE_TEMPLATE_PATH os . makedirs ( path , exist_ok = True ) fname = ( \"\" . join ( random . choice ( string . ascii_lowercase ) # nosec for _ in range ( 16 ) ) + \".template\" ) absolute_path = path / fname if not isinstance ( tempate_body , str ): tempate_body = ordered_dump ( tempate_body , dumper = yaml . SafeDumper ) if not absolute_path . exists (): with open ( absolute_path , \"w\" ) as fh : fh . write ( tempate_body ) template = Template ( template_path = str ( absolute_path ), project_root = parent_stack . template . project_root , url = url , template_cache = tcat_template_cache , ) stack = cls ( parent_stack . region , stack_properties [ \"StackId\" ], template , parent_stack . name , parent_stack . uuid , ) stack . set_stack_properties ( stack_properties ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to import child stack: { str ( e ) } \" ) LOG . debug ( \"traceback:\" , exc_info = True ) return None return stack @classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ], template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO: get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id )[ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple [ str , Callable ]] = [ ( \"Parameters\" , Parameter ), ( \"Outputs\" , Output ), ( \"Tags\" , Tag ), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , []): item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items (): if key in [ p [ 0 ] for p in iterable_props ]: # noqa: C412 continue key = pascal_to_snake ( key ) . replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () @staticmethod def _merge_props ( existing_props , new ): added = False for existing_id , prop in enumerate ( existing_props ): if prop . key == new . key : existing_props [ existing_id ] = new added = True if not added : existing_props . append ( new ) def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ): self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events @staticmethod def _is_generic ( event : Event ) -> bool : generic = False for regex in GENERIC_ERROR_PATTERNS : if re . search ( regex , event . status_reason ): generic = True return generic def _fetch_stack_events ( self ) -> None : self . _last_event_refresh = datetime . now () events = Events () for page in self . client . get_paginator ( \"describe_stack_events\" ) . paginate ( StackName = self . id ): for event in page [ \"StackEvents\" ]: events . append ( Event ( event )) self . _events = events def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ): self . _fetch_stack_resources () return self . _resources def _fetch_stack_resources ( self ) -> None : self . _last_resource_refresh = datetime . now () resources = Resources () for page in self . client . get_paginator ( \"list_stack_resources\" ) . paginate ( StackName = self . id ): for resource in page [ \"StackResourceSummaries\" ]: resources . append ( Resource ( self . id , resource , self . test_name , self . uuid )) self . _resources = resources @staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: { stack_id } \" ) def update ( self , * args , ** kwargs ): raise NotImplementedError ( \"Stack updates not implemented\" ) def _fetch_children ( self ) -> None : self . _last_child_refresh = datetime . now () for page in self . client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack in page [ \"Stacks\" ]: if self . _children . filter ( id = stack [ \"StackId\" ]): continue if \"ParentId\" in stack . keys (): if self . id == stack [ \"ParentId\" ]: stack_obj = Stack . _import_child ( stack , self ) if stack_obj : self . _children . append ( stack_obj ) def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ): self . _fetch_children () return self . _children def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ): descendants += stack . children () for child in stack . children (): descendants = recurse ( child , descendants ) return descendants return recurse ( self ) def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ([ self ]) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ) . filter ({ \"status\" : status }) return errors","title":"Module taskcat._cfn.stack"},{"location":"reference/taskcat/_cfn/stack.html#variables","text":"GENERIC_ERROR_PATTERNS LOG","title":"Variables"},{"location":"reference/taskcat/_cfn/stack.html#functions","text":"","title":"Functions"},{"location":"reference/taskcat/_cfn/stack.html#criteria_matches","text":"def criteria_matches ( criteria : dict , instance ) View Source def criteria_matches ( criteria : dict , instance ) : # fail if criteria includes an invalid property for k in criteria : if not hasattr ( instance , k ) : raise ValueError ( f \" {k} is not a valid property of {type(instance)} \" ) for k , v in criteria . items () : # matching is AND for multiple criteria , so as soon as one fails , # it ' s not a match if getattr ( instance , k ) != v : return False return True","title":"criteria_matches"},{"location":"reference/taskcat/_cfn/stack.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cfn/stack.html#capabilities","text":"class Capabilities ( / , * args , ** kwargs ) View Source class Capabilities: IAM = \"CAPABILITY_IAM\" NAMED_IAM = \"CAPABILITY_NAMED_IAM\" AUTO_EXPAND = \"CAPABILITY_AUTO_EXPAND\" ALL = [ IAM , NAMED_IAM , AUTO_EXPAND ]","title":"Capabilities"},{"location":"reference/taskcat/_cfn/stack.html#class-variables","text":"ALL AUTO_EXPAND IAM NAMED_IAM","title":"Class variables"},{"location":"reference/taskcat/_cfn/stack.html#event","text":"class Event ( event_dict : dict ) View Source class Event : def __init__ ( self , event_dict : dict ): self . event_id : str = event_dict [ \"EventId\" ] self . stack_name : str = event_dict [ \"StackName\" ] self . logical_id : str = event_dict [ \"LogicalResourceId\" ] self . type : str = event_dict [ \"ResourceType\" ] self . status : str = event_dict [ \"ResourceStatus\" ] self . physical_id : str = \"\" self . timestamp : datetime = datetime . fromtimestamp ( 0 ) self . status_reason : str = \"\" self . properties : dict = {} if \"PhysicalResourceId\" in event_dict . keys (): self . physical_id = event_dict [ \"PhysicalResourceId\" ] if \"Timestamp\" in event_dict . keys (): self . timestamp = event_dict [ \"Timestamp\" ] if \"ResourceStatusReason\" in event_dict . keys (): self . status_reason = event_dict [ \"ResourceStatusReason\" ] if \"ResourceProperties\" in event_dict . keys (): self . properties = json . loads ( event_dict [ \"ResourceProperties\" ]) def __str__ ( self ): return \"{} {} {}\" . format ( self . timestamp , self . logical_id , self . status ) def __repr__ ( self ): return \"<Event object {} at {}>\" . format ( self . event_id , hex ( id ( self )))","title":"Event"},{"location":"reference/taskcat/_cfn/stack.html#events","text":"class Events ( / , * args , ** kwargs ) View Source class Events ( FilterableList ): pass","title":"Events"},{"location":"reference/taskcat/_cfn/stack.html#ancestors-in-mro","text":"taskcat._cfn.stack.FilterableList builtins.list","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/_cfn/stack.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#append","text":"def append ( self , object , / ) Append object to the end of the list.","title":"append"},{"location":"reference/taskcat/_cfn/stack.html#clear","text":"def clear ( self , / ) Remove all items from list.","title":"clear"},{"location":"reference/taskcat/_cfn/stack.html#copy","text":"def copy ( self , / ) Return a shallow copy of the list.","title":"copy"},{"location":"reference/taskcat/_cfn/stack.html#count","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"reference/taskcat/_cfn/stack.html#extend","text":"def extend ( self , iterable , / ) Extend list by appending elements from the iterable.","title":"extend"},{"location":"reference/taskcat/_cfn/stack.html#filter","text":"def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist","title":"filter"},{"location":"reference/taskcat/_cfn/stack.html#index","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"reference/taskcat/_cfn/stack.html#insert","text":"def insert ( self , index , object , / ) Insert object before index.","title":"insert"},{"location":"reference/taskcat/_cfn/stack.html#pop","text":"def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range.","title":"pop"},{"location":"reference/taskcat/_cfn/stack.html#remove","text":"def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present.","title":"remove"},{"location":"reference/taskcat/_cfn/stack.html#reverse","text":"def reverse ( self , / ) Reverse IN PLACE .","title":"reverse"},{"location":"reference/taskcat/_cfn/stack.html#sort","text":"def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order.","title":"sort"},{"location":"reference/taskcat/_cfn/stack.html#filterablelist","text":"class FilterableList ( / , * args , ** kwargs ) View Source class FilterableList ( list ) : def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist","title":"FilterableList"},{"location":"reference/taskcat/_cfn/stack.html#ancestors-in-mro_1","text":"builtins.list","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/_cfn/stack.html#descendants","text":"taskcat._cfn.stack.Stacks taskcat._cfn.stack.Resources taskcat._cfn.stack.Events taskcat._cfn.stack.Tags","title":"Descendants"},{"location":"reference/taskcat/_cfn/stack.html#methods_1","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#append_1","text":"def append ( self , object , / ) Append object to the end of the list.","title":"append"},{"location":"reference/taskcat/_cfn/stack.html#clear_1","text":"def clear ( self , / ) Remove all items from list.","title":"clear"},{"location":"reference/taskcat/_cfn/stack.html#copy_1","text":"def copy ( self , / ) Return a shallow copy of the list.","title":"copy"},{"location":"reference/taskcat/_cfn/stack.html#count_1","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"reference/taskcat/_cfn/stack.html#extend_1","text":"def extend ( self , iterable , / ) Extend list by appending elements from the iterable.","title":"extend"},{"location":"reference/taskcat/_cfn/stack.html#filter_1","text":"def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist","title":"filter"},{"location":"reference/taskcat/_cfn/stack.html#index_1","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"reference/taskcat/_cfn/stack.html#insert_1","text":"def insert ( self , index , object , / ) Insert object before index.","title":"insert"},{"location":"reference/taskcat/_cfn/stack.html#pop_1","text":"def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range.","title":"pop"},{"location":"reference/taskcat/_cfn/stack.html#remove_1","text":"def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present.","title":"remove"},{"location":"reference/taskcat/_cfn/stack.html#reverse_1","text":"def reverse ( self , / ) Reverse IN PLACE .","title":"reverse"},{"location":"reference/taskcat/_cfn/stack.html#sort_1","text":"def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order.","title":"sort"},{"location":"reference/taskcat/_cfn/stack.html#output","text":"class Output ( output_dict : dict ) View Source class Output : def __init__ ( self , output_dict : dict ): self . key : str = output_dict [ \"OutputKey\" ] self . value : str = output_dict [ \"OutputValue\" ] self . description : str = \"\" self . export_name : str = \"\" if \"Description\" in output_dict . keys (): self . description = output_dict [ \"Description\" ] if \"ExportName\" in output_dict . keys (): self . export_name = output_dict [ \"ExportName\" ]","title":"Output"},{"location":"reference/taskcat/_cfn/stack.html#parameter","text":"class Parameter ( param_dict : dict ) View Source class Parameter: def __init__ ( self , param_dict: dict ): self . key: str = param_dict [ \"ParameterKey\" ] self . value: str = \"\" self . raw_value: str = \"\" self . use_previous_value: bool = False self . resolved_value: str = \"\" if \"ParameterValue\" in param_dict . keys (): self . value = param_dict [ \"ParameterValue\" ] if \"UsePreviousValue\" in param_dict . keys (): self . use_previous_value = param_dict [ \"UsePreviousValue\" ] if \"ResolvedValue\" in param_dict . keys (): self . resolved_value = param_dict [ \"ResolvedValue\" ] if self . value and not self . raw_value: self . raw_value = self . value def dump ( self ): param_dict = { \"ParameterKey\" : self . key } if self . value: param_dict [ \"ParameterValue\" ] = self . value if self . use_previous_value: param_dict [ \"UsePreviousValue\" ] = self . use_previous_value return param_dict","title":"Parameter"},{"location":"reference/taskcat/_cfn/stack.html#methods_2","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#dump","text":"def dump ( self ) View Source def dump ( self ) : param_dict = { \" ParameterKey \" : self . key } if self . value : param_dict [ \" ParameterValue \" ] = self . value if self . use_previous_value : param_dict [ \" UsePreviousValue \" ] = self . use_previous_value return param_dict","title":"dump"},{"location":"reference/taskcat/_cfn/stack.html#resource","text":"class Resource ( stack_id : str , resource_dict : dict , test_name : str = '' , uuid : uuid . UUID = None ) View Source class Resource: def __init__ ( self , stack_id: str , resource_dict: dict , test_name: str = \"\" , uuid: UUID = None ): uuid = uuid if uuid else uuid4 () self . stack_id: str = stack_id self . test_name: str = test_name self . uuid: UUID = uuid self . logical_id: str = resource_dict [ \"LogicalResourceId\" ] self . type: str = resource_dict [ \"ResourceType\" ] self . status: str = resource_dict [ \"ResourceStatus\" ] self . physical_id: str = \"\" self . last_updated_timestamp: datetime = datetime . fromtimestamp ( 0 ) self . status_reason: str = \"\" if \"PhysicalResourceId\" in resource_dict . keys (): self . physical_id = resource_dict [ \"PhysicalResourceId\" ] if \"LastUpdatedTimestamp\" in resource_dict . keys (): self . last_updated_timestamp = resource_dict [ \"LastUpdatedTimestamp\" ] if \"ResourceStatusReason\" in resource_dict . keys (): self . status_reason = resource_dict [ \"ResourceStatusReason\" ] def __str__ ( self ): return \"<Resource {} {}>\" . format ( self . logical_id , self . status )","title":"Resource"},{"location":"reference/taskcat/_cfn/stack.html#resources","text":"class Resources ( / , * args , ** kwargs ) View Source class Resources ( FilterableList ): pass","title":"Resources"},{"location":"reference/taskcat/_cfn/stack.html#ancestors-in-mro_2","text":"taskcat._cfn.stack.FilterableList builtins.list","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/_cfn/stack.html#methods_3","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#append_2","text":"def append ( self , object , / ) Append object to the end of the list.","title":"append"},{"location":"reference/taskcat/_cfn/stack.html#clear_2","text":"def clear ( self , / ) Remove all items from list.","title":"clear"},{"location":"reference/taskcat/_cfn/stack.html#copy_2","text":"def copy ( self , / ) Return a shallow copy of the list.","title":"copy"},{"location":"reference/taskcat/_cfn/stack.html#count_2","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"reference/taskcat/_cfn/stack.html#extend_2","text":"def extend ( self , iterable , / ) Extend list by appending elements from the iterable.","title":"extend"},{"location":"reference/taskcat/_cfn/stack.html#filter_2","text":"def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist","title":"filter"},{"location":"reference/taskcat/_cfn/stack.html#index_2","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"reference/taskcat/_cfn/stack.html#insert_2","text":"def insert ( self , index , object , / ) Insert object before index.","title":"insert"},{"location":"reference/taskcat/_cfn/stack.html#pop_2","text":"def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range.","title":"pop"},{"location":"reference/taskcat/_cfn/stack.html#remove_2","text":"def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present.","title":"remove"},{"location":"reference/taskcat/_cfn/stack.html#reverse_2","text":"def reverse ( self , / ) Reverse IN PLACE .","title":"reverse"},{"location":"reference/taskcat/_cfn/stack.html#sort_2","text":"def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order.","title":"sort"},{"location":"reference/taskcat/_cfn/stack.html#stack","text":"class Stack ( region : taskcat . _dataclasses . TestRegion , stack_id : str , template : taskcat . _cfn . template . Template , test_name , uuid : uuid . UUID = None ) View Source class Stack : # pylint: disable=too-many-instance-attributes REMOTE_TEMPLATE_PATH = Path ( \".taskcat/.remote_templates\" ) def __init__ ( self , region : TestRegion , stack_id : str , template : Template , test_name , uuid : UUID = None , ): uuid = uuid if uuid else uuid4 () self . test_name : str = test_name self . uuid : UUID = uuid self . id : str = stack_id self . template : Template = template self . name : str = self . _get_name () self . region : TestRegion = region self . region_name = region . name self . client : boto3 . client = region . client ( \"cloudformation\" ) self . completion_time : timedelta = timedelta ( 0 ) self . role_arn = region . role_arn # properties from additional cfn api calls self . _events : Events = Events () self . _resources : Resources = Resources () self . _children : Stacks = Stacks () # properties from describe_stacks response self . change_set_id : str = \"\" self . parameters : List [ Parameter ] = [] self . creation_time : datetime = datetime . fromtimestamp ( 0 ) self . deletion_time : datetime = datetime . fromtimestamp ( 0 ) self . _status : str = \"\" self . status_reason : str = \"\" self . disable_rollback : bool = False self . timeout_in_minutes : int = 0 self . capabilities : List [ str ] = [] self . outputs : List [ Output ] = [] self . tags : List [ Tag ] = [] self . parent_id : str = \"\" self . root_id : str = \"\" self . _launch_succeeded : bool = False self . _auto_refresh_interval : timedelta = timedelta ( seconds = 60 ) self . _last_event_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_resource_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _last_child_refresh : datetime = datetime . fromtimestamp ( 0 ) self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () def __str__ ( self ): return self . id def __repr__ ( self ): return \"<Stack object {} at {}>\" . format ( self . name , hex ( id ( self ))) def _get_region ( self ) -> str : return self . id . split ( \":\" )[ 3 ] def _get_name ( self ) -> str : return self . id . split ( \":\" )[ 5 ] . split ( \"/\" )[ 1 ] def _auto_refresh ( self , last_refresh ): if datetime . now () - last_refresh > self . _auto_refresh_interval : return True return False @ property def status ( self ): if self . _status in StackStatus . COMPLETE : if not self . launch_succeeded : self . _status = \"OUT_OF_ORDER_EVENT\" self . status_reason = ( \"COMPLETE event not detected. \" + \"Potential out-of-band action against the stack.\" ) return self . _status @ status . setter def status ( self , status ): _complete = StackStatus . COMPLETE . copy () del _complete [ _complete . index ( \"DELETE_COMPLETE\" )] self . _status = status if status in StackStatus . FAILED : self . _launch_succeeded = False return if status in _complete : self . _launch_succeeded = True return return @ property def launch_succeeded ( self ): return self . _launch_succeeded @ classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t . dump () for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options )[ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack @ staticmethod def _cfn_format_parameters ( parameters ): return [{ \"ParameterKey\" : k , \"ParameterValue\" : v } for k , v in parameters . items ()] @ classmethod def _import_child ( # pylint: disable=too-many-locals cls , stack_properties : dict , parent_stack : \"Stack\" ) -> Optional [ \"Stack\" ]: try : url = \"\" for event in parent_stack . events (): if ( event . physical_id == stack_properties [ \"StackId\" ] and event . properties ): url = event . properties [ \"TemplateURL\" ] if url . startswith ( parent_stack . template . url_prefix ()): # Template is part of the project, discovering path relative_path = url . replace ( parent_stack . template . url_prefix (), \"\" ) . lstrip ( \"/\" ) absolute_path = parent_stack . template . project_root / relative_path if not absolute_path . is_file (): # try with the base folder stripped off relative_path2 = Path ( relative_path ) relative_path2 = relative_path2 . relative_to ( * relative_path2 . parts [: 1 ] ) absolute_path = parent_stack . template . project_root / relative_path2 if not absolute_path . is_file (): LOG . warning ( f \"Failed to find template for child stack \" f \"{stack_properties['StackId']}. tried \" f \"{parent_stack.template.project_root / relative_path}\" f \" and {absolute_path}\" ) return None else : # Assuming template is remote to project and downloading it cfn_client = parent_stack . client tempate_body = cfn_client . get_template ( StackName = stack_properties [ \"StackId\" ] )[ \"TemplateBody\" ] path = parent_stack . template . project_root / Stack . REMOTE_TEMPLATE_PATH os . makedirs ( path , exist_ok = True ) fname = ( \"\" . join ( random . choice ( string . ascii_lowercase ) # nosec for _ in range ( 16 ) ) + \".template\" ) absolute_path = path / fname if not isinstance ( tempate_body , str ): tempate_body = ordered_dump ( tempate_body , dumper = yaml . SafeDumper ) if not absolute_path . exists (): with open ( absolute_path , \"w\" ) as fh : fh . write ( tempate_body ) template = Template ( template_path = str ( absolute_path ), project_root = parent_stack . template . project_root , url = url , template_cache = tcat_template_cache , ) stack = cls ( parent_stack . region , stack_properties [ \"StackId\" ], template , parent_stack . name , parent_stack . uuid , ) stack . set_stack_properties ( stack_properties ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to import child stack: {str(e)}\" ) LOG . debug ( \"traceback:\" , exc_info = True ) return None return stack @ classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ], template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now () def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO: get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id )[ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple [ str , Callable ]] = [ ( \"Parameters\" , Parameter ), ( \"Outputs\" , Output ), ( \"Tags\" , Tag ), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , []): item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items (): if key in [ p [ 0 ] for p in iterable_props ]: # noqa: C412 continue key = pascal_to_snake ( key ) . replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start () @ staticmethod def _merge_props ( existing_props , new ): added = False for existing_id , prop in enumerate ( existing_props ): if prop . key == new . key : existing_props [ existing_id ] = new added = True if not added : existing_props . append ( new ) def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ): self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events @ staticmethod def _is_generic ( event : Event ) -> bool : generic = False for regex in GENERIC_ERROR_PATTERNS : if re . search ( regex , event . status_reason ): generic = True return generic def _fetch_stack_events ( self ) -> None : self . _last_event_refresh = datetime . now () events = Events () for page in self . client . get_paginator ( \"describe_stack_events\" ) . paginate ( StackName = self . id ): for event in page [ \"StackEvents\" ]: events . append ( Event ( event )) self . _events = events def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ): self . _fetch_stack_resources () return self . _resources def _fetch_stack_resources ( self ) -> None : self . _last_resource_refresh = datetime . now () resources = Resources () for page in self . client . get_paginator ( \"list_stack_resources\" ) . paginate ( StackName = self . id ): for resource in page [ \"StackResourceSummaries\" ]: resources . append ( Resource ( self . id , resource , self . test_name , self . uuid )) self . _resources = resources @ staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" ) def update ( self , * args , ** kwargs ): raise NotImplementedError ( \"Stack updates not implemented\" ) def _fetch_children ( self ) -> None : self . _last_child_refresh = datetime . now () for page in self . client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack in page [ \"Stacks\" ]: if self . _children . filter ( id = stack [ \"StackId\" ]): continue if \"ParentId\" in stack . keys (): if self . id == stack [ \"ParentId\" ]: stack_obj = Stack . _import_child ( stack , self ) if stack_obj : self . _children . append ( stack_obj ) def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ): self . _fetch_children () return self . _children def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ): descendants += stack . children () for child in stack . children (): descendants = recurse ( child , descendants ) return descendants return recurse ( self ) def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ([ self ]) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ) . filter ({ \"status\" : status }) return errors","title":"Stack"},{"location":"reference/taskcat/_cfn/stack.html#class-variables_1","text":"REMOTE_TEMPLATE_PATH","title":"Class variables"},{"location":"reference/taskcat/_cfn/stack.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/_cfn/stack.html#create","text":"def create ( region : taskcat . _dataclasses . TestRegion , stack_name : str , template : taskcat . _cfn . template . Template , tags : List [ taskcat . _dataclasses . Tag ] = None , disable_rollback : bool = True , test_name : str = '' , uuid : uuid . UUID = None ) -> 'Stack' View Source @classmethod def create ( cls , region : TestRegion , stack_name : str , template : Template , tags : List [ Tag ] = None , disable_rollback : bool = True , test_name : str = \"\" , uuid : UUID = None , ) -> \"Stack\" : parameters = cls . _cfn_format_parameters ( region . parameters ) uuid = uuid if uuid else uuid4 () cfn_client = region . client ( \"cloudformation\" ) tags = [ t.dump() for t in tags ] if tags else [] template = Template ( template_path = template . template_path , project_root = template . project_root , s3_key_prefix = template . s3_key_prefix , url = s3_url_maker ( region . s3_bucket . name , template . s3_key , region . client ( \"s3\" ), region . s3_bucket . auto_generated , ), template_cache = tcat_template_cache , ) create_options = { \"StackName\" : stack_name , \"TemplateURL\" : template . url , \"Parameters\" : parameters , \"DisableRollback\" : disable_rollback , \"Tags\" : tags , \"Capabilities\" : Capabilities . ALL , } if region . role_arn : create_options [ \"RoleARN\" ] = region . role_arn stack_id = cfn_client . create_stack ( ** create_options ) [ \"StackId\" ] stack = cls ( region , stack_id , template , test_name , uuid ) # fetch property values from cfn stack . refresh () return stack","title":"create"},{"location":"reference/taskcat/_cfn/stack.html#delete","text":"def delete ( client , stack_id ) -> None View Source @staticmethod def delete ( client , stack_id ) -> None : client . delete_stack ( StackName = stack_id ) LOG . info ( f \"Deleting stack: {stack_id}\" )","title":"delete"},{"location":"reference/taskcat/_cfn/stack.html#import_existing","text":"def import_existing ( stack_properties : dict , template : taskcat . _cfn . template . Template , region : taskcat . _dataclasses . TestRegion , test_name : str , uid : uuid . UUID ) -> 'Stack' View Source @classmethod def import_existing ( cls , stack_properties : dict , template : Template , region : TestRegion , test_name : str , uid : UUID , ) -> \"Stack\" : stack = cls ( region , stack_properties [ \"StackId\" ] , template , test_name , uid ) stack . set_stack_properties ( stack_properties ) return stack","title":"import_existing"},{"location":"reference/taskcat/_cfn/stack.html#instance-variables","text":"launch_succeeded status","title":"Instance variables"},{"location":"reference/taskcat/_cfn/stack.html#methods_4","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#children","text":"def children ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def children ( self , refresh = False ) -> Stacks : if ( refresh or not self . _children or self . _auto_refresh ( self . _last_child_refresh ) ) : self . _fetch_children () return self . _children","title":"children"},{"location":"reference/taskcat/_cfn/stack.html#descendants_1","text":"def descendants ( self , refresh = False ) -> taskcat . _cfn . stack . Stacks View Source def descendants ( self , refresh = False ) -> Stacks : if refresh or not self . _children : self . _fetch_children () def recurse ( stack : Stack , descendants : Stacks = None ) -> Stacks : descendants = descendants if descendants else Stacks () if stack . children ( refresh = refresh ) : descendants += stack . children () for child in stack . children () : descendants = recurse ( child , descendants ) return descendants return recurse ( self )","title":"descendants"},{"location":"reference/taskcat/_cfn/stack.html#error_events","text":"def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> taskcat . _cfn . stack . Events View Source def error_events ( self , recurse : bool = True , include_generic : bool = False , refresh = False ) -> Events : errors = Events () stacks = Stacks ( [ self ] ) if recurse : stacks += self . descendants () for stack in stacks : for status in StackStatus . FAILED : errors += stack . events ( refresh = refresh , include_generic = include_generic ). filter ( { \"status\" : status } ) return errors","title":"error_events"},{"location":"reference/taskcat/_cfn/stack.html#events_1","text":"def events ( self , refresh : bool = False , include_generic : bool = True ) -> taskcat . _cfn . stack . Events View Source def events ( self , refresh : bool = False , include_generic : bool = True ) -> Events : if refresh or not self . _events or self . _auto_refresh ( self . _last_event_refresh ) : self . _fetch_stack_events () events = self . _events if not include_generic : events = Events ([ event for event in events if not self . _is_generic ( event )]) return events","title":"events"},{"location":"reference/taskcat/_cfn/stack.html#refresh","text":"def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False ) -> None View Source def refresh ( self , properties : bool = True , events : bool = False , resources : bool = False , children : bool = False , ) -> None : if properties : self . set_stack_properties () if events : self . _fetch_stack_events () self . _last_event_refresh = datetime . now () if resources : self . _fetch_stack_resources () self . _last_resource_refresh = datetime . now () if children : self . _fetch_children () self . _last_child_refresh = datetime . now ()","title":"refresh"},{"location":"reference/taskcat/_cfn/stack.html#resources_1","text":"def resources ( self , refresh : bool = False ) -> taskcat . _cfn . stack . Resources View Source def resources ( self , refresh : bool = False ) -> Resources : if ( refresh or not self . _resources or self . _auto_refresh ( self . _last_resource_refresh ) ) : self . _fetch_stack_resources () return self . _resources","title":"resources"},{"location":"reference/taskcat/_cfn/stack.html#set_stack_properties","text":"def set_stack_properties ( self , stack_properties : Union [ dict , NoneType ] = None ) -> None View Source def set_stack_properties ( self , stack_properties : Optional [ dict ] = None ) -> None : # TODO : get time to complete for complete stacks and % complete props : dict = stack_properties if stack_properties else {} self . _timer . cancel () if not props : describe_stacks = self . client . describe_stacks props = describe_stacks ( StackName = self . id ) [ \"Stacks\" ][ 0 ] iterable_props : List [ Tuple[str, Callable ] ] = [ (\"Parameters\", Parameter), (\"Outputs\", Output), (\"Tags\", Tag), ] for prop_name , prop_class in iterable_props : for item in props . get ( prop_name , [] ) : item = prop_class ( item ) self . _merge_props ( getattr ( self , prop_name . lower ()), item ) for key , value in props . items () : if key in [ p[0 ] for p in iterable_props ]: # noqa : C412 continue key = pascal_to_snake ( key ). replace ( \"stack_\" , \"\" ) setattr ( self , key , value ) if self . status in StackStatus . IN_PROGRESS : self . _timer = Timer ( self . _auto_refresh_interval . total_seconds (), self . refresh ) self . _timer . start ()","title":"set_stack_properties"},{"location":"reference/taskcat/_cfn/stack.html#update","text":"def update ( self , * args , ** kwargs ) View Source def update(self, *args, **kwargs): raise NotImplementedError(\"Stack updates not implemented\")","title":"update"},{"location":"reference/taskcat/_cfn/stack.html#stackstatus","text":"class StackStatus ( / , * args , ** kwargs ) View Source class StackStatus: COMPLETE = [ \"CREATE_COMPLETE\" , \"UPDATE_COMPLETE\" , \"DELETE_COMPLETE\" ] IN_PROGRESS = [ \"CREATE_IN_PROGRESS\" , \"DELETE_IN_PROGRESS\" , \"UPDATE_IN_PROGRESS\" , \"UPDATE_COMPLETE_CLEANUP_IN_PROGRESS\" , ] FAILED = [ \"DELETE_FAILED\" , \"CREATE_FAILED\" , \"ROLLBACK_IN_PROGRESS\" , \"ROLLBACK_FAILED\" , \"ROLLBACK_COMPLETE\" , \"UPDATE_ROLLBACK_IN_PROGRESS\" , \"UPDATE_ROLLBACK_FAILED\" , \"UPDATE_ROLLBACK_COMPLETE_CLEANUP_IN_PROGRESS\" , \"UPDATE_ROLLBACK_COMPLETE\" , \"OUT_OF_ORDER_EVENT\" , ]","title":"StackStatus"},{"location":"reference/taskcat/_cfn/stack.html#class-variables_2","text":"COMPLETE FAILED IN_PROGRESS","title":"Class variables"},{"location":"reference/taskcat/_cfn/stack.html#stacks","text":"class Stacks ( / , * args , ** kwargs ) View Source class Stacks ( FilterableList ): pass","title":"Stacks"},{"location":"reference/taskcat/_cfn/stack.html#ancestors-in-mro_3","text":"taskcat._cfn.stack.FilterableList builtins.list","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/_cfn/stack.html#methods_5","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#append_3","text":"def append ( self , object , / ) Append object to the end of the list.","title":"append"},{"location":"reference/taskcat/_cfn/stack.html#clear_3","text":"def clear ( self , / ) Remove all items from list.","title":"clear"},{"location":"reference/taskcat/_cfn/stack.html#copy_3","text":"def copy ( self , / ) Return a shallow copy of the list.","title":"copy"},{"location":"reference/taskcat/_cfn/stack.html#count_3","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"reference/taskcat/_cfn/stack.html#extend_3","text":"def extend ( self , iterable , / ) Extend list by appending elements from the iterable.","title":"extend"},{"location":"reference/taskcat/_cfn/stack.html#filter_3","text":"def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist","title":"filter"},{"location":"reference/taskcat/_cfn/stack.html#index_3","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"reference/taskcat/_cfn/stack.html#insert_3","text":"def insert ( self , index , object , / ) Insert object before index.","title":"insert"},{"location":"reference/taskcat/_cfn/stack.html#pop_3","text":"def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range.","title":"pop"},{"location":"reference/taskcat/_cfn/stack.html#remove_3","text":"def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present.","title":"remove"},{"location":"reference/taskcat/_cfn/stack.html#reverse_3","text":"def reverse ( self , / ) Reverse IN PLACE .","title":"reverse"},{"location":"reference/taskcat/_cfn/stack.html#sort_3","text":"def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order.","title":"sort"},{"location":"reference/taskcat/_cfn/stack.html#tags","text":"class Tags ( / , * args , ** kwargs ) View Source class Tags ( FilterableList ): pass","title":"Tags"},{"location":"reference/taskcat/_cfn/stack.html#ancestors-in-mro_4","text":"taskcat._cfn.stack.FilterableList builtins.list","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/_cfn/stack.html#methods_6","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack.html#append_4","text":"def append ( self , object , / ) Append object to the end of the list.","title":"append"},{"location":"reference/taskcat/_cfn/stack.html#clear_4","text":"def clear ( self , / ) Remove all items from list.","title":"clear"},{"location":"reference/taskcat/_cfn/stack.html#copy_4","text":"def copy ( self , / ) Return a shallow copy of the list.","title":"copy"},{"location":"reference/taskcat/_cfn/stack.html#count_4","text":"def count ( self , value , / ) Return number of occurrences of value.","title":"count"},{"location":"reference/taskcat/_cfn/stack.html#extend_4","text":"def extend ( self , iterable , / ) Extend list by appending elements from the iterable.","title":"extend"},{"location":"reference/taskcat/_cfn/stack.html#filter_4","text":"def filter ( self , criteria : Union [ dict , NoneType ] = None , ** kwargs ) View Source def filter ( self , criteria : Optional [ dict ] = None , ** kwargs ) : if not criteria and not kwargs : return self if not criteria : criteria = kwargs flist = FilterableList () for item in self : if criteria_matches ( criteria , item ) : flist . append ( item ) return flist","title":"filter"},{"location":"reference/taskcat/_cfn/stack.html#index_4","text":"def index ( self , value , start = 0 , stop = 9223372036854775807 , / ) Return first index of value. Raises ValueError if the value is not present.","title":"index"},{"location":"reference/taskcat/_cfn/stack.html#insert_4","text":"def insert ( self , index , object , / ) Insert object before index.","title":"insert"},{"location":"reference/taskcat/_cfn/stack.html#pop_4","text":"def pop ( self , index =- 1 , / ) Remove and return item at index (default last). Raises IndexError if list is empty or index is out of range.","title":"pop"},{"location":"reference/taskcat/_cfn/stack.html#remove_4","text":"def remove ( self , value , / ) Remove first occurrence of value. Raises ValueError if the value is not present.","title":"remove"},{"location":"reference/taskcat/_cfn/stack.html#reverse_4","text":"def reverse ( self , / ) Reverse IN PLACE .","title":"reverse"},{"location":"reference/taskcat/_cfn/stack.html#sort_4","text":"def sort ( self , / , * , key = None , reverse = False ) Sort the list in ascending order and return None. The sort is in-place (i.e. the list itself is modified) and stable (i.e. the order of two equal elements is maintained). If a key function is given, apply it once to each list item and sort them, ascending or descending, according to their function values. The reverse flag can be set to sort in descending order.","title":"sort"},{"location":"reference/taskcat/_cfn/stack_url_helper.html","text":"Module taskcat._cfn.stack_url_helper Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import json import logging import os from pathlib import Path from urllib.parse import urlparse LOG = logging . getLogger ( __name__ ) class StackURLHelper : MAX_DEPTH = 20 # Handle at most 20 levels of nesting in TemplateURL expressions # TODO: Allow user to inject this # SUBSTITUTION = { # \"QSS3BucketName\": \"aws-quickstart\", # \"QSS3KeyPrefix\": \"QSS3KeyPrefix/\", # \"qss3KeyPrefix\": \"qss3KeyPrefix/\", # \"AWS::Region\": \"us-east-1\", # \"AWS::AccountId\": \"8888XXXX9999\", # } SUBSTITUTION = { \"AWS::Region\" : \"us-east-1\" , \"AWS::URLSuffix\" : \"amazonaws.com\" , \"AWS::AccountId\" : \"8888XXXX9999\" , } def __init__ ( self , template_mappings = None , template_parameters = None , parameter_values = None , ): if template_mappings : self . mappings = template_mappings else : self . mappings = {} if template_parameters : self . template_parameters = template_parameters else : self . template_parameters = {} if parameter_values : self . parameter_values = parameter_values else : self . parameter_values = {} default_parameters : dict = {} for parameter in self . template_parameters : properties = self . template_parameters . get ( parameter ) if \"Default\" in properties . keys (): default_parameters [ parameter ] = properties [ \"Default\" ] self . SUBSTITUTION . update ( default_parameters ) self . SUBSTITUTION . update ( self . parameter_values ) def rewrite_vars ( self , original_string , depth = 1 ): \"\"\"Replace the ${var} placeholders with ##var##\"\"\" parts = original_string . split ( \"${\" ) parts = parts [ 1 ] . split ( \"}\" ) rep_text = \"${\" + parts [ 0 ] + \"}\" rep_with = \"##\" + parts [ 0 ] + \"##\" result = original_string . replace ( rep_text , rep_with ) if len ( result . split ( \"${\" )) > 1 : result = self . rewrite_vars ( result , depth = ( depth + 1 )) return result def rewrite_sub_vars ( self , original_string , depth = 1 ): \"\"\"Replace the '##var##' placeholders with 'var'\"\"\" if \"##\" not in original_string : return original_string parts = original_string . split ( \"##\" ) parts = parts [ 1 ] . split ( \"##\" ) rep_text = \"##\" + parts [ 0 ] + \"##\" rep_with = \"\" + parts [ 0 ] + \"\" result = original_string . replace ( rep_text , rep_with ) if \"##\" in result : # Recurse if we have more variables result = self . rewrite_sub_vars ( result , depth = ( depth + 1 )) return result @staticmethod def rewrite_sub_vars_with_values ( expression , values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" result = expression # replace each key we have a value for for key in values : rep_text = \"##\" + key + \"##\" rep_with = \"\" + str ( values [ key ]) + \"\" result = result . replace ( rep_text , rep_with ) return result @staticmethod def values_to_dict ( values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" # Create dictionary of values values_dict_string = values . replace ( \"(\" , \"{\" ) values_dict_string = values_dict_string . replace ( \")\" , \"}\" ) values_dict_string = values_dict_string . replace ( \"'\" , '\"' ) # for values or keys not quoted # Split by : values_split_string = values_dict_string # Trim stuff so we can get the key values values_split_string = values_split_string . replace ( \" \" , \"\" ) values_split_string = values_split_string . replace ( \"{\" , \"\" ) values_split_string = values_split_string . replace ( \"}\" , \"\" ) values_split = values_split_string . split ( \",\" ) values_split_final = [] for value in values_split : values = value . split ( \":\" ) values_split_final . extend ( values ) for value in values_split_final : if value [ 0 ] != \"'\" and value [ - 1 ] != \"'\" : if value [ 0 ] != '\"' and value [ - 1 ] != '\"' : values_dict_string = values_dict_string . replace ( value , '\"' + value + '\"' ) values_dict = json . loads ( values_dict_string ) return values_dict def evaluate_fn_sub ( self , expression ): \"\"\" Return expression with values replaced \"\"\" results = [] # Builtins - Fudge some defaults here since we don't have runtime info # ${AWS::Region} ${AWS::AccountId} expression = self . rewrite_sub_vars_with_values ( expression , self . SUBSTITUTION ) # Handle Sub of form [ StringToSub, { \"key\" : \"value\", \"key\": \"value\" }] if \"[\" in expression : temp_expression = expression . split ( \"[\" )[ 1 ] . split ( \",\" )[ 0 ] values = expression . split ( \"[\" )[ 1 ] . split ( \"(\" )[ 1 ] . split ( \")\" )[ 0 ] values = self . values_to_dict ( \"(\" + values + \")\" ) temp_expression = self . rewrite_sub_vars_with_values ( temp_expression , values ) else : temp_expression = expression . split ( \"': '\" )[ 1 ] . split ( \"'\" )[ 0 ] # if we still have them we just use their values (ie: Parameters) result = self . rewrite_sub_vars ( temp_expression ) results . append ( result ) return results @staticmethod def evaluate_fn_join ( expression ): \"\"\" Return the joined stuff \"\"\" results = [] new_values_list = [] temp = expression . split ( \"[\" )[ 1 ] delimiter = temp . split ( \",\" )[ 0 ] . strip ( \"'\" ) values = expression . split ( \"[\" )[ 2 ] values = values . split ( \"]]\" )[ 0 ] values_list = values . split ( \", \" ) for value in values_list : new_values_list . append ( value . strip ( \"'\" )) result = delimiter . join ( new_values_list ) results . append ( result ) return results @staticmethod def evaluate_fn_if ( expression ): \"\"\" Return both possible parts of the expression \"\"\" results = [] value_true = expression . split ( \",\" )[ 1 ] . strip () value_false = expression . split ( \",\" )[ 2 ] . strip () . strip ( \"]\" ) # if we don't have '' this can break things results . append ( \"'\" + value_true . strip ( \"'\" ) + \"'\" ) results . append ( \"'\" + value_false . strip ( \"'\" ) + \"'\" ) return results def evaluate_fn_ref ( self , expression ): \"\"\"Since this is runtime data the best we can do is the name in place\"\"\" # TODO: Allow user to inject RunTime values for these results = [] temp = expression . split ( \": \" )[ 1 ] if temp . strip ( \"'\" ) in self . SUBSTITUTION . keys (): temp = self . SUBSTITUTION [ temp . strip ( \"'\" )] temp = \"'\" + temp + \"'\" results . append ( temp ) return results def find_in_map_lookup ( self , mappings_map , first_key , final_key ): step1 = self . mappings [ mappings_map . strip ( \"'\" )] step2 = step1 [ first_key . strip ( \"'\" )] result = step2 [ final_key . strip ( \"'\" )] return result def evaluate_fn_findinmap ( self , expression ): result = [] mappings_map = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 0 ] . strip () first_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 1 ] . strip () final_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 2 ] . strip () result . append ( \"'\" + self . find_in_map_lookup ( mappings_map , first_key , final_key ) + \"'\" ) return result @staticmethod def evaluate_fn_getatt ( expression ): raise Exception ( \"Fn::GetAtt: not supported\" ) @staticmethod def evaluate_fn_split ( expression ): raise Exception ( \"Fn::Split: not supported\" ) def evaluate_expression_controller ( self , expression ): \"\"\"Figure out what type of expression and pass off to handler\"\"\" results = [] if \"Fn::If\" in expression : results = self . evaluate_fn_if ( expression ) elif \"Fn::Sub\" in expression : results = self . evaluate_fn_sub ( expression ) elif \"Fn::Join\" in expression : results = self . evaluate_fn_join ( expression ) elif \"Ref\" in expression : results = self . evaluate_fn_ref ( expression ) elif \"Fn::FindInMap\" in expression : results = self . evaluate_fn_findinmap ( expression ) elif \"Fn::GetAtt\" in expression : results = self . evaluate_fn_getatt ( expression ) elif \"Fn::Split\" in expression : results = self . evaluate_fn_split ( expression ) else : # This is a NON expression repl { and } with ( and ) to break recursion results . append ( \"(\" + expression + \")\" ) return results def evaluate_string ( self , template_url , depth = 0 ): \"\"\"Recursively find expressions in the URL and send them to be evaluated\"\"\" # Recursion bail out if depth > self . MAX_DEPTH : raise Exception ( \"Template URL contains more than {} levels or nesting\" . format ( self . MAX_DEPTH ) ) template_urls = [] # Evaluate expressions if \"{\" in template_url : parts = template_url . split ( \"{\" ) parts = parts [ - 1 ] . split ( \"}\" ) # Last open bracket # This function will handle Fn::Sub Fn::If etc. replacements = self . evaluate_expression_controller ( parts [ 0 ] ) # First closed bracket after for replacement in replacements : template_url_temp = template_url template_url_temp = template_url_temp . replace ( \"{\" + parts [ 0 ] + \"}\" , replacement ) evaluated_strings = self . evaluate_string ( template_url_temp , depth = ( depth + 1 ) ) for evaluated_string in evaluated_strings : template_urls . append ( evaluated_string ) else : template_urls . append ( template_url ) return template_urls def _flatten_template_controller ( self , template_url ): \"\"\" Recursively evaluate subs/ifs\"\"\" url_list = [] # Replace ${SOMEVAR} with ##SOMEVAR## so finding actual \"expressions\" is easier template_url_string = str ( template_url ) parts = template_url_string . split ( \"${\" ) if len ( parts ) > 1 : template_url_string = self . rewrite_vars ( template_url_string ) # Evaluate expressions recursively if \"{\" in template_url_string : replacements = self . evaluate_string ( template_url_string ) # first closed bracket for replacement in replacements : url_list . append ( replacement ) else : url_list . append ( template_url ) return url_list def flatten_template_url ( self , template_url ): \"\"\"Flatten template_url and return all permutations\"\"\" path_list = [] url_list = self . _flatten_template_controller ( template_url ) # Extract the path portion from the URL for url in url_list : # TODO: figure where the ' is coming from output = urlparse ( str ( url . strip ( \"'\" ))) path_list . append ( output . path ) path_list = list ( dict . fromkeys ( path_list )) # print(url_list) # print(path_list) return path_list @staticmethod def _remove_one_level ( path_string ): result = path_string result = result . find ( \"/\" , 0 ) result = path_string [ result + 1 : len ( path_string )] return result def find_local_child_template ( self , parent_template_path , child_template_path ): final_template_path = \"\" # Start where the Parent template is project_root = Path ( os . path . dirname ( parent_template_path )) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) # Take the path piece by piece and try in current folder while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) # Take the path piece by piece and try in one folder up folder project_root = Path ( os . path . normpath ( os . path . dirname ( parent_template_path ) + \"/../\" ) ) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) return \"\" def template_url_to_path ( self , current_template_path , template_url , ): child_local_paths = [] child_template_paths = self . flatten_template_url ( template_url ) # TODO: Add logic to try for S3 paths for child_template_path in child_template_paths : child_local_paths . append ( self . find_local_child_template ( current_template_path , child_template_path ) ) return child_local_paths Variables LOG Classes StackURLHelper class StackURLHelper ( template_mappings = None , template_parameters = None , parameter_values = None ) View Source class StackURLHelper : MAX_DEPTH = 20 # Handle at most 20 levels of nesting in TemplateURL expressions # TODO: Allow user to inject this # SUBSTITUTION = { # \"QSS3BucketName\": \"aws-quickstart\", # \"QSS3KeyPrefix\": \"QSS3KeyPrefix/\", # \"qss3KeyPrefix\": \"qss3KeyPrefix/\", # \"AWS::Region\": \"us-east-1\", # \"AWS::AccountId\": \"8888XXXX9999\", # } SUBSTITUTION = { \"AWS::Region\" : \"us-east-1\" , \"AWS::URLSuffix\" : \"amazonaws.com\" , \"AWS::AccountId\" : \"8888XXXX9999\" , } def __init__ ( self , template_mappings = None , template_parameters = None , parameter_values = None , ): if template_mappings : self . mappings = template_mappings else : self . mappings = {} if template_parameters : self . template_parameters = template_parameters else : self . template_parameters = {} if parameter_values : self . parameter_values = parameter_values else : self . parameter_values = {} default_parameters : dict = {} for parameter in self . template_parameters : properties = self . template_parameters . get ( parameter ) if \"Default\" in properties . keys (): default_parameters [ parameter ] = properties [ \"Default\" ] self . SUBSTITUTION . update ( default_parameters ) self . SUBSTITUTION . update ( self . parameter_values ) def rewrite_vars ( self , original_string , depth = 1 ): \"\"\"Replace the ${var} placeholders with ##var##\"\"\" parts = original_string . split ( \"${\" ) parts = parts [ 1 ] . split ( \"}\" ) rep_text = \"${\" + parts [ 0 ] + \"}\" rep_with = \"##\" + parts [ 0 ] + \"##\" result = original_string . replace ( rep_text , rep_with ) if len ( result . split ( \"${\" )) > 1 : result = self . rewrite_vars ( result , depth = ( depth + 1 )) return result def rewrite_sub_vars ( self , original_string , depth = 1 ): \"\"\"Replace the '##var##' placeholders with 'var'\"\"\" if \"##\" not in original_string : return original_string parts = original_string . split ( \"##\" ) parts = parts [ 1 ] . split ( \"##\" ) rep_text = \"##\" + parts [ 0 ] + \"##\" rep_with = \"\" + parts [ 0 ] + \"\" result = original_string . replace ( rep_text , rep_with ) if \"##\" in result : # Recurse if we have more variables result = self . rewrite_sub_vars ( result , depth = ( depth + 1 )) return result @ staticmethod def rewrite_sub_vars_with_values ( expression , values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" result = expression # replace each key we have a value for for key in values : rep_text = \"##\" + key + \"##\" rep_with = \"\" + str ( values [ key ]) + \"\" result = result . replace ( rep_text , rep_with ) return result @ staticmethod def values_to_dict ( values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" # Create dictionary of values values_dict_string = values . replace ( \"(\" , \"{\" ) values_dict_string = values_dict_string . replace ( \")\" , \"}\" ) values_dict_string = values_dict_string . replace ( \"'\" , '\"' ) # for values or keys not quoted # Split by : values_split_string = values_dict_string # Trim stuff so we can get the key values values_split_string = values_split_string . replace ( \" \" , \"\" ) values_split_string = values_split_string . replace ( \"{\" , \"\" ) values_split_string = values_split_string . replace ( \"}\" , \"\" ) values_split = values_split_string . split ( \",\" ) values_split_final = [] for value in values_split : values = value . split ( \":\" ) values_split_final . extend ( values ) for value in values_split_final : if value [ 0 ] != \"'\" and value [ - 1 ] != \"'\" : if value [ 0 ] != '\"' and value [ - 1 ] != '\"' : values_dict_string = values_dict_string . replace ( value , '\"' + value + '\"' ) values_dict = json . loads ( values_dict_string ) return values_dict def evaluate_fn_sub ( self , expression ): \"\"\" Return expression with values replaced \"\"\" results = [] # Builtins - Fudge some defaults here since we don't have runtime info # ${AWS::Region} ${AWS::AccountId} expression = self . rewrite_sub_vars_with_values ( expression , self . SUBSTITUTION ) # Handle Sub of form [ StringToSub, { \"key\" : \"value\", \"key\": \"value\" }] if \"[\" in expression : temp_expression = expression . split ( \"[\" )[ 1 ] . split ( \",\" )[ 0 ] values = expression . split ( \"[\" )[ 1 ] . split ( \"(\" )[ 1 ] . split ( \")\" )[ 0 ] values = self . values_to_dict ( \"(\" + values + \")\" ) temp_expression = self . rewrite_sub_vars_with_values ( temp_expression , values ) else : temp_expression = expression . split ( \"': '\" )[ 1 ] . split ( \"'\" )[ 0 ] # if we still have them we just use their values (ie: Parameters) result = self . rewrite_sub_vars ( temp_expression ) results . append ( result ) return results @ staticmethod def evaluate_fn_join ( expression ): \"\"\" Return the joined stuff \"\"\" results = [] new_values_list = [] temp = expression . split ( \"[\" )[ 1 ] delimiter = temp . split ( \",\" )[ 0 ] . strip ( \"'\" ) values = expression . split ( \"[\" )[ 2 ] values = values . split ( \"]]\" )[ 0 ] values_list = values . split ( \", \" ) for value in values_list : new_values_list . append ( value . strip ( \"'\" )) result = delimiter . join ( new_values_list ) results . append ( result ) return results @ staticmethod def evaluate_fn_if ( expression ): \"\"\" Return both possible parts of the expression \"\"\" results = [] value_true = expression . split ( \",\" )[ 1 ] . strip () value_false = expression . split ( \",\" )[ 2 ] . strip () . strip ( \"]\" ) # if we don't have '' this can break things results . append ( \"'\" + value_true . strip ( \"'\" ) + \"'\" ) results . append ( \"'\" + value_false . strip ( \"'\" ) + \"'\" ) return results def evaluate_fn_ref ( self , expression ): \"\"\"Since this is runtime data the best we can do is the name in place\"\"\" # TODO: Allow user to inject RunTime values for these results = [] temp = expression . split ( \": \" )[ 1 ] if temp . strip ( \"'\" ) in self . SUBSTITUTION . keys (): temp = self . SUBSTITUTION [ temp . strip ( \"'\" )] temp = \"'\" + temp + \"'\" results . append ( temp ) return results def find_in_map_lookup ( self , mappings_map , first_key , final_key ): step1 = self . mappings [ mappings_map . strip ( \"'\" )] step2 = step1 [ first_key . strip ( \"'\" )] result = step2 [ final_key . strip ( \"'\" )] return result def evaluate_fn_findinmap ( self , expression ): result = [] mappings_map = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 0 ] . strip () first_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 1 ] . strip () final_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 2 ] . strip () result . append ( \"'\" + self . find_in_map_lookup ( mappings_map , first_key , final_key ) + \"'\" ) return result @ staticmethod def evaluate_fn_getatt ( expression ): raise Exception ( \"Fn::GetAtt: not supported\" ) @ staticmethod def evaluate_fn_split ( expression ): raise Exception ( \"Fn::Split: not supported\" ) def evaluate_expression_controller ( self , expression ): \"\"\"Figure out what type of expression and pass off to handler\"\"\" results = [] if \"Fn::If\" in expression : results = self . evaluate_fn_if ( expression ) elif \"Fn::Sub\" in expression : results = self . evaluate_fn_sub ( expression ) elif \"Fn::Join\" in expression : results = self . evaluate_fn_join ( expression ) elif \"Ref\" in expression : results = self . evaluate_fn_ref ( expression ) elif \"Fn::FindInMap\" in expression : results = self . evaluate_fn_findinmap ( expression ) elif \"Fn::GetAtt\" in expression : results = self . evaluate_fn_getatt ( expression ) elif \"Fn::Split\" in expression : results = self . evaluate_fn_split ( expression ) else : # This is a NON expression repl { and } with ( and ) to break recursion results . append ( \"(\" + expression + \")\" ) return results def evaluate_string ( self , template_url , depth = 0 ): \"\"\"Recursively find expressions in the URL and send them to be evaluated\"\"\" # Recursion bail out if depth > self . MAX_DEPTH : raise Exception ( \"Template URL contains more than {} levels or nesting\" . format ( self . MAX_DEPTH ) ) template_urls = [] # Evaluate expressions if \"{\" in template_url : parts = template_url . split ( \"{\" ) parts = parts [ - 1 ] . split ( \"}\" ) # Last open bracket # This function will handle Fn::Sub Fn::If etc. replacements = self . evaluate_expression_controller ( parts [ 0 ] ) # First closed bracket after for replacement in replacements : template_url_temp = template_url template_url_temp = template_url_temp . replace ( \"{\" + parts [ 0 ] + \"}\" , replacement ) evaluated_strings = self . evaluate_string ( template_url_temp , depth = ( depth + 1 ) ) for evaluated_string in evaluated_strings : template_urls . append ( evaluated_string ) else : template_urls . append ( template_url ) return template_urls def _flatten_template_controller ( self , template_url ): \"\"\" Recursively evaluate subs/ifs\"\"\" url_list = [] # Replace ${SOMEVAR} with ##SOMEVAR## so finding actual \"expressions\" is easier template_url_string = str ( template_url ) parts = template_url_string . split ( \"${\" ) if len ( parts ) > 1 : template_url_string = self . rewrite_vars ( template_url_string ) # Evaluate expressions recursively if \"{\" in template_url_string : replacements = self . evaluate_string ( template_url_string ) # first closed bracket for replacement in replacements : url_list . append ( replacement ) else : url_list . append ( template_url ) return url_list def flatten_template_url ( self , template_url ): \"\"\"Flatten template_url and return all permutations\"\"\" path_list = [] url_list = self . _flatten_template_controller ( template_url ) # Extract the path portion from the URL for url in url_list : # TODO: figure where the ' is coming from output = urlparse ( str ( url . strip ( \"'\" ))) path_list . append ( output . path ) path_list = list ( dict . fromkeys ( path_list )) # print(url_list) # print(path_list) return path_list @ staticmethod def _remove_one_level ( path_string ): result = path_string result = result . find ( \"/\" , 0 ) result = path_string [ result + 1 : len ( path_string )] return result def find_local_child_template ( self , parent_template_path , child_template_path ): final_template_path = \"\" # Start where the Parent template is project_root = Path ( os . path . dirname ( parent_template_path )) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) # Take the path piece by piece and try in current folder while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) # Take the path piece by piece and try in one folder up folder project_root = Path ( os . path . normpath ( os . path . dirname ( parent_template_path ) + \"/../\" ) ) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) return \"\" def template_url_to_path ( self , current_template_path , template_url , ): child_local_paths = [] child_template_paths = self . flatten_template_url ( template_url ) # TODO: Add logic to try for S3 paths for child_template_path in child_template_paths : child_local_paths . append ( self . find_local_child_template ( current_template_path , child_template_path ) ) return child_local_paths Class variables MAX_DEPTH SUBSTITUTION Static methods evaluate_fn_getatt def evaluate_fn_getatt ( expression ) View Source @staticmethod def evaluate_fn_getatt ( expression ) : raise Exception ( \"Fn::GetAtt: not supported\" ) evaluate_fn_if def evaluate_fn_if ( expression ) Return both possible parts of the expression View Source @staticmethod def evaluate_fn_if ( expression ) : \"\"\" Return both possible parts of the expression \"\"\" results = [] value_true = expression . split ( \",\" ) [ 1 ] . strip () value_false = expression . split ( \",\" ) [ 2 ] . strip (). strip ( \"]\" ) # if we don 't have '' this can break things results.append(\"' \" + value_true.strip(\" '\") + \"' \") results.append(\" '\" + value_false.strip(\"' \") + \" '\" ) return results evaluate_fn_join def evaluate_fn_join ( expression ) Return the joined stuff View Source @staticmethod def evaluate_fn_join ( expression ) : \"\"\" Return the joined stuff \"\"\" results = [] new_values_list = [] temp = expression . split ( \"[\" ) [ 1 ] delimiter = temp . split ( \",\" ) [ 0 ] . strip ( \"'\" ) values = expression . split ( \"[\" ) [ 2 ] values = values . split ( \"]]\" ) [ 0 ] values_list = values . split ( \", \" ) for value in values_list : new_values_list . append ( value . strip ( \"'\" )) result = delimiter . join ( new_values_list ) results . append ( result ) return results evaluate_fn_split def evaluate_fn_split ( expression ) View Source @staticmethod def evaluate_fn_split ( expression ) : raise Exception ( \"Fn::Split: not supported\" ) rewrite_sub_vars_with_values def rewrite_sub_vars_with_values ( expression , values ) Rewrite sub vars with actual variable values View Source @staticmethod def rewrite_sub_vars_with_values ( expression , values ) : \"\"\"Rewrite sub vars with actual variable values\"\"\" result = expression # replace each key we have a value for for key in values : rep_text = \"##\" + key + \"##\" rep_with = \"\" + str ( values [ key ] ) + \"\" result = result . replace ( rep_text , rep_with ) return result values_to_dict def values_to_dict ( values ) Rewrite sub vars with actual variable values View Source @ staticmethod def values_to_dict ( values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" # Create dictionary of values values_dict_string = values . replace ( \"(\" , \"{\" ) values_dict_string = values_dict_string . replace ( \")\" , \"}\" ) values_dict_string = values_dict_string . replace ( \"'\" , '\"' ) # for values or keys not quoted # Split by : values_split_string = values_dict_string # Trim stuff so we can get the key values values_split_string = values_split_string . replace ( \" \" , \"\" ) values_split_string = values_split_string . replace ( \"{\" , \"\" ) values_split_string = values_split_string . replace ( \"}\" , \"\" ) values_split = values_split_string . split ( \",\" ) values_split_final = [] for value in values_split : values = value . split ( \":\" ) values_split_final . extend ( values ) for value in values_split_final : if value [ 0 ] != \"'\" and value [ - 1 ] != \"'\" : if value [ 0 ] != '\"' and value [ - 1 ] != '\"' : values_dict_string = values_dict_string . replace ( value , '\"' + value + '\"' ) values_dict = json . loads ( values_dict_string ) return values_dict Methods evaluate_expression_controller def evaluate_expression_controller ( self , expression ) Figure out what type of expression and pass off to handler View Source def evaluate_expression_controller ( self , expression ) : \"\"\" Figure out what type of expression and pass off to handler \"\"\" results = [] if \" Fn::If \" in expression : results = self . evaluate_fn_if ( expression ) elif \" Fn::Sub \" in expression : results = self . evaluate_fn_sub ( expression ) elif \" Fn::Join \" in expression : results = self . evaluate_fn_join ( expression ) elif \" Ref \" in expression : results = self . evaluate_fn_ref ( expression ) elif \" Fn::FindInMap \" in expression : results = self . evaluate_fn_findinmap ( expression ) elif \" Fn::GetAtt \" in expression : results = self . evaluate_fn_getatt ( expression ) elif \" Fn::Split \" in expression : results = self . evaluate_fn_split ( expression ) else : # This is a NON expression repl { and } with ( and ) to break recursion results . append ( \" ( \" + expression + \" ) \" ) return results evaluate_fn_findinmap def evaluate_fn_findinmap ( self , expression ) View Source def evaluate_fn_findinmap ( self , expression ) : result = [] mappings_map = expression . split ( \" [ \" ) [ 1 ]. split ( \" ] \" ) [ 0 ]. split ( \" , \" ) [ 0 ]. strip () first_key = expression . split ( \" [ \" ) [ 1 ]. split ( \" ] \" ) [ 0 ]. split ( \" , \" ) [ 1 ]. strip () final_key = expression . split ( \" [ \" ) [ 1 ]. split ( \" ] \" ) [ 0 ]. split ( \" , \" ) [ 2 ]. strip () result . append ( \" ' \" + self . find_in_map_lookup ( mappings_map , first_key , final_key ) + \" ' \" ) return result evaluate_fn_ref def evaluate_fn_ref ( self , expression ) Since this is runtime data the best we can do is the name in place View Source def evaluate_fn_ref ( self , expression ) : \"\"\" Since this is runtime data the best we can do is the name in place \"\"\" # TODO : Allow user to inject RunTime values for these results = [] temp = expression . split ( \" : \" ) [ 1 ] if temp . strip ( \" ' \" ) in self . SUBSTITUTION . keys () : temp = self . SUBSTITUTION [ temp . strip ( \" ' \" ) ] temp = \" ' \" + temp + \" ' \" results . append ( temp ) return results evaluate_fn_sub def evaluate_fn_sub ( self , expression ) Return expression with values replaced View Source def evaluate_fn_sub ( self , expression ): \"\"\" Return expression with values replaced \"\"\" results = [] # Builtins - Fudge some defaults here since we don't have runtime info # ${AWS::Region} ${AWS::AccountId} expression = self . rewrite_sub_vars_with_values ( expression , self . SUBSTITUTION ) # Handle Sub of form [ StringToSub, { \"key\" : \"value\", \"key\": \"value\" }] if \"[\" in expression : temp_expression = expression . split ( \"[\" )[ 1 ] . split ( \",\" )[ 0 ] values = expression . split ( \"[\" )[ 1 ] . split ( \"(\" )[ 1 ] . split ( \")\" )[ 0 ] values = self . values_to_dict ( \"(\" + values + \")\" ) temp_expression = self . rewrite_sub_vars_with_values ( temp_expression , values ) else : temp_expression = expression . split ( \"': '\" )[ 1 ] . split ( \"'\" )[ 0 ] # if we still have them we just use their values (ie: Parameters) result = self . rewrite_sub_vars ( temp_expression ) results . append ( result ) return results evaluate_string def evaluate_string ( self , template_url , depth = 0 ) Recursively find expressions in the URL and send them to be evaluated View Source def evaluate_string ( self , template_url , depth = 0 ) : \"\"\" Recursively find expressions in the URL and send them to be evaluated \"\"\" # Recursion bail out if depth > self . MAX_DEPTH : raise Exception ( \" Template URL contains more than {} levels or nesting \" . format ( self . MAX_DEPTH ) ) template_urls = [] # Evaluate expressions if \" { \" in template_url : parts = template_url . split ( \" { \" ) parts = parts [ - 1 ]. split ( \" } \" ) # Last open bracket # This function will handle Fn :: Sub Fn :: If etc . replacements = self . evaluate_expression_controller ( parts [ 0 ] ) # First closed bracket after for replacement in replacements : template_url_temp = template_url template_url_temp = template_url_temp . replace ( \" { \" + parts [ 0 ] + \" } \" , replacement ) evaluated_strings = self . evaluate_string ( template_url_temp , depth = ( depth + 1 ) ) for evaluated_string in evaluated_strings : template_urls . append ( evaluated_string ) else : template_urls . append ( template_url ) return template_urls find_in_map_lookup def find_in_map_lookup ( self , mappings_map , first_key , final_key ) View Source def find_in_map_lookup ( self , mappings_map , first_key , final_key ) : step1 = self . mappings [ mappings_map . strip ( \" ' \" ) ] step2 = step1 [ first_key . strip ( \" ' \" ) ] result = step2 [ final_key . strip ( \" ' \" ) ] return result find_local_child_template def find_local_child_template ( self , parent_template_path , child_template_path ) View Source def find_local_child_template ( self , parent_template_path , child_template_path ) : final_template_path = \"\" # Start where the Parent template is project_root = Path ( os . path . dirname ( parent_template_path )) # Get rid of any \" // \" child_template_path_tmp = os . path . normpath ( child_template_path ) # Take the path piece by piece and try in current folder while \" / \" in str ( child_template_path_tmp ) : child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \" / \" . join ( [ str ( project_root ) , str ( child_template_path_tmp ) ] ) ) if final_template_path . exists () and final_template_path . is_file () : return str ( final_template_path ) # Take the path piece by piece and try in one folder up folder project_root = Path ( os . path . normpath ( os . path . dirname ( parent_template_path ) + \" /../ \" ) ) # Get rid of any \" // \" child_template_path_tmp = os . path . normpath ( child_template_path ) while \" / \" in str ( child_template_path_tmp ) : child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \" / \" . join ( [ str ( project_root ) , str ( child_template_path_tmp ) ] ) ) if final_template_path . exists () and final_template_path . is_file () : return str ( final_template_path ) return \"\" flatten_template_url def flatten_template_url ( self , template_url ) Flatten template_url and return all permutations View Source def flatten_template_url ( self , template_url ) : \"\"\" Flatten template_url and return all permutations \"\"\" path_list = [] url_list = self . _flatten_template_controller ( template_url ) # Extract the path portion from the URL for url in url_list : # TODO : figure where the ' is coming from output = urlparse ( str ( url . strip ( \" ' \" ))) path_list . append ( output . path ) path_list = list ( dict . fromkeys ( path_list )) # print ( url_list ) # print ( path_list ) return path_list rewrite_sub_vars def rewrite_sub_vars ( self , original_string , depth = 1 ) Replace the '##var##' placeholders with 'var' View Source def rewrite_sub_vars ( self , original_string , depth = 1 ): \"\"\"Replace the '##var##' placeholders with 'var'\"\"\" if \"##\" not in original_string : return original_string parts = original_string . split ( \"##\" ) parts = parts [ 1 ] . split ( \"##\" ) rep_text = \"##\" + parts [ 0 ] + \"##\" rep_with = \"\" + parts [ 0 ] + \"\" result = original_string . replace ( rep_text , rep_with ) if \"##\" in result : # Recurse if we have more variables result = self . rewrite_sub_vars ( result , depth = ( depth + 1 )) return result rewrite_vars def rewrite_vars ( self , original_string , depth = 1 ) Replace the ${var} placeholders with ##var## View Source def rewrite_vars ( self , original_string , depth = 1 ): \"\"\"Replace the ${var} placeholders with ##var##\"\"\" parts = original_string . split ( \"${\" ) parts = parts [ 1 ] . split ( \"}\" ) rep_text = \"${\" + parts [ 0 ] + \"}\" rep_with = \"##\" + parts [ 0 ] + \"##\" result = original_string . replace ( rep_text , rep_with ) if len ( result . split ( \"${\" )) > 1 : result = self . rewrite_vars ( result , depth = ( depth + 1 )) return result template_url_to_path def template_url_to_path ( self , current_template_path , template_url ) View Source def template_url_to_path ( self , current_template_path , template_url , ) : child_local_paths = [] child_template_paths = self . flatten_template_url ( template_url ) # TODO : Add logic to try for S3 paths for child_template_path in child_template_paths : child_local_paths . append ( self . find_local_child_template ( current_template_path , child_template_path ) ) return child_local_paths","title":"Stack Url Helper"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#module-taskcat_cfnstack_url_helper","text":"Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. View Source \"\"\" Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. \"\"\" import json import logging import os from pathlib import Path from urllib.parse import urlparse LOG = logging . getLogger ( __name__ ) class StackURLHelper : MAX_DEPTH = 20 # Handle at most 20 levels of nesting in TemplateURL expressions # TODO: Allow user to inject this # SUBSTITUTION = { # \"QSS3BucketName\": \"aws-quickstart\", # \"QSS3KeyPrefix\": \"QSS3KeyPrefix/\", # \"qss3KeyPrefix\": \"qss3KeyPrefix/\", # \"AWS::Region\": \"us-east-1\", # \"AWS::AccountId\": \"8888XXXX9999\", # } SUBSTITUTION = { \"AWS::Region\" : \"us-east-1\" , \"AWS::URLSuffix\" : \"amazonaws.com\" , \"AWS::AccountId\" : \"8888XXXX9999\" , } def __init__ ( self , template_mappings = None , template_parameters = None , parameter_values = None , ): if template_mappings : self . mappings = template_mappings else : self . mappings = {} if template_parameters : self . template_parameters = template_parameters else : self . template_parameters = {} if parameter_values : self . parameter_values = parameter_values else : self . parameter_values = {} default_parameters : dict = {} for parameter in self . template_parameters : properties = self . template_parameters . get ( parameter ) if \"Default\" in properties . keys (): default_parameters [ parameter ] = properties [ \"Default\" ] self . SUBSTITUTION . update ( default_parameters ) self . SUBSTITUTION . update ( self . parameter_values ) def rewrite_vars ( self , original_string , depth = 1 ): \"\"\"Replace the ${var} placeholders with ##var##\"\"\" parts = original_string . split ( \"${\" ) parts = parts [ 1 ] . split ( \"}\" ) rep_text = \"${\" + parts [ 0 ] + \"}\" rep_with = \"##\" + parts [ 0 ] + \"##\" result = original_string . replace ( rep_text , rep_with ) if len ( result . split ( \"${\" )) > 1 : result = self . rewrite_vars ( result , depth = ( depth + 1 )) return result def rewrite_sub_vars ( self , original_string , depth = 1 ): \"\"\"Replace the '##var##' placeholders with 'var'\"\"\" if \"##\" not in original_string : return original_string parts = original_string . split ( \"##\" ) parts = parts [ 1 ] . split ( \"##\" ) rep_text = \"##\" + parts [ 0 ] + \"##\" rep_with = \"\" + parts [ 0 ] + \"\" result = original_string . replace ( rep_text , rep_with ) if \"##\" in result : # Recurse if we have more variables result = self . rewrite_sub_vars ( result , depth = ( depth + 1 )) return result @staticmethod def rewrite_sub_vars_with_values ( expression , values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" result = expression # replace each key we have a value for for key in values : rep_text = \"##\" + key + \"##\" rep_with = \"\" + str ( values [ key ]) + \"\" result = result . replace ( rep_text , rep_with ) return result @staticmethod def values_to_dict ( values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" # Create dictionary of values values_dict_string = values . replace ( \"(\" , \"{\" ) values_dict_string = values_dict_string . replace ( \")\" , \"}\" ) values_dict_string = values_dict_string . replace ( \"'\" , '\"' ) # for values or keys not quoted # Split by : values_split_string = values_dict_string # Trim stuff so we can get the key values values_split_string = values_split_string . replace ( \" \" , \"\" ) values_split_string = values_split_string . replace ( \"{\" , \"\" ) values_split_string = values_split_string . replace ( \"}\" , \"\" ) values_split = values_split_string . split ( \",\" ) values_split_final = [] for value in values_split : values = value . split ( \":\" ) values_split_final . extend ( values ) for value in values_split_final : if value [ 0 ] != \"'\" and value [ - 1 ] != \"'\" : if value [ 0 ] != '\"' and value [ - 1 ] != '\"' : values_dict_string = values_dict_string . replace ( value , '\"' + value + '\"' ) values_dict = json . loads ( values_dict_string ) return values_dict def evaluate_fn_sub ( self , expression ): \"\"\" Return expression with values replaced \"\"\" results = [] # Builtins - Fudge some defaults here since we don't have runtime info # ${AWS::Region} ${AWS::AccountId} expression = self . rewrite_sub_vars_with_values ( expression , self . SUBSTITUTION ) # Handle Sub of form [ StringToSub, { \"key\" : \"value\", \"key\": \"value\" }] if \"[\" in expression : temp_expression = expression . split ( \"[\" )[ 1 ] . split ( \",\" )[ 0 ] values = expression . split ( \"[\" )[ 1 ] . split ( \"(\" )[ 1 ] . split ( \")\" )[ 0 ] values = self . values_to_dict ( \"(\" + values + \")\" ) temp_expression = self . rewrite_sub_vars_with_values ( temp_expression , values ) else : temp_expression = expression . split ( \"': '\" )[ 1 ] . split ( \"'\" )[ 0 ] # if we still have them we just use their values (ie: Parameters) result = self . rewrite_sub_vars ( temp_expression ) results . append ( result ) return results @staticmethod def evaluate_fn_join ( expression ): \"\"\" Return the joined stuff \"\"\" results = [] new_values_list = [] temp = expression . split ( \"[\" )[ 1 ] delimiter = temp . split ( \",\" )[ 0 ] . strip ( \"'\" ) values = expression . split ( \"[\" )[ 2 ] values = values . split ( \"]]\" )[ 0 ] values_list = values . split ( \", \" ) for value in values_list : new_values_list . append ( value . strip ( \"'\" )) result = delimiter . join ( new_values_list ) results . append ( result ) return results @staticmethod def evaluate_fn_if ( expression ): \"\"\" Return both possible parts of the expression \"\"\" results = [] value_true = expression . split ( \",\" )[ 1 ] . strip () value_false = expression . split ( \",\" )[ 2 ] . strip () . strip ( \"]\" ) # if we don't have '' this can break things results . append ( \"'\" + value_true . strip ( \"'\" ) + \"'\" ) results . append ( \"'\" + value_false . strip ( \"'\" ) + \"'\" ) return results def evaluate_fn_ref ( self , expression ): \"\"\"Since this is runtime data the best we can do is the name in place\"\"\" # TODO: Allow user to inject RunTime values for these results = [] temp = expression . split ( \": \" )[ 1 ] if temp . strip ( \"'\" ) in self . SUBSTITUTION . keys (): temp = self . SUBSTITUTION [ temp . strip ( \"'\" )] temp = \"'\" + temp + \"'\" results . append ( temp ) return results def find_in_map_lookup ( self , mappings_map , first_key , final_key ): step1 = self . mappings [ mappings_map . strip ( \"'\" )] step2 = step1 [ first_key . strip ( \"'\" )] result = step2 [ final_key . strip ( \"'\" )] return result def evaluate_fn_findinmap ( self , expression ): result = [] mappings_map = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 0 ] . strip () first_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 1 ] . strip () final_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 2 ] . strip () result . append ( \"'\" + self . find_in_map_lookup ( mappings_map , first_key , final_key ) + \"'\" ) return result @staticmethod def evaluate_fn_getatt ( expression ): raise Exception ( \"Fn::GetAtt: not supported\" ) @staticmethod def evaluate_fn_split ( expression ): raise Exception ( \"Fn::Split: not supported\" ) def evaluate_expression_controller ( self , expression ): \"\"\"Figure out what type of expression and pass off to handler\"\"\" results = [] if \"Fn::If\" in expression : results = self . evaluate_fn_if ( expression ) elif \"Fn::Sub\" in expression : results = self . evaluate_fn_sub ( expression ) elif \"Fn::Join\" in expression : results = self . evaluate_fn_join ( expression ) elif \"Ref\" in expression : results = self . evaluate_fn_ref ( expression ) elif \"Fn::FindInMap\" in expression : results = self . evaluate_fn_findinmap ( expression ) elif \"Fn::GetAtt\" in expression : results = self . evaluate_fn_getatt ( expression ) elif \"Fn::Split\" in expression : results = self . evaluate_fn_split ( expression ) else : # This is a NON expression repl { and } with ( and ) to break recursion results . append ( \"(\" + expression + \")\" ) return results def evaluate_string ( self , template_url , depth = 0 ): \"\"\"Recursively find expressions in the URL and send them to be evaluated\"\"\" # Recursion bail out if depth > self . MAX_DEPTH : raise Exception ( \"Template URL contains more than {} levels or nesting\" . format ( self . MAX_DEPTH ) ) template_urls = [] # Evaluate expressions if \"{\" in template_url : parts = template_url . split ( \"{\" ) parts = parts [ - 1 ] . split ( \"}\" ) # Last open bracket # This function will handle Fn::Sub Fn::If etc. replacements = self . evaluate_expression_controller ( parts [ 0 ] ) # First closed bracket after for replacement in replacements : template_url_temp = template_url template_url_temp = template_url_temp . replace ( \"{\" + parts [ 0 ] + \"}\" , replacement ) evaluated_strings = self . evaluate_string ( template_url_temp , depth = ( depth + 1 ) ) for evaluated_string in evaluated_strings : template_urls . append ( evaluated_string ) else : template_urls . append ( template_url ) return template_urls def _flatten_template_controller ( self , template_url ): \"\"\" Recursively evaluate subs/ifs\"\"\" url_list = [] # Replace ${SOMEVAR} with ##SOMEVAR## so finding actual \"expressions\" is easier template_url_string = str ( template_url ) parts = template_url_string . split ( \"${\" ) if len ( parts ) > 1 : template_url_string = self . rewrite_vars ( template_url_string ) # Evaluate expressions recursively if \"{\" in template_url_string : replacements = self . evaluate_string ( template_url_string ) # first closed bracket for replacement in replacements : url_list . append ( replacement ) else : url_list . append ( template_url ) return url_list def flatten_template_url ( self , template_url ): \"\"\"Flatten template_url and return all permutations\"\"\" path_list = [] url_list = self . _flatten_template_controller ( template_url ) # Extract the path portion from the URL for url in url_list : # TODO: figure where the ' is coming from output = urlparse ( str ( url . strip ( \"'\" ))) path_list . append ( output . path ) path_list = list ( dict . fromkeys ( path_list )) # print(url_list) # print(path_list) return path_list @staticmethod def _remove_one_level ( path_string ): result = path_string result = result . find ( \"/\" , 0 ) result = path_string [ result + 1 : len ( path_string )] return result def find_local_child_template ( self , parent_template_path , child_template_path ): final_template_path = \"\" # Start where the Parent template is project_root = Path ( os . path . dirname ( parent_template_path )) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) # Take the path piece by piece and try in current folder while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) # Take the path piece by piece and try in one folder up folder project_root = Path ( os . path . normpath ( os . path . dirname ( parent_template_path ) + \"/../\" ) ) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) return \"\" def template_url_to_path ( self , current_template_path , template_url , ): child_local_paths = [] child_template_paths = self . flatten_template_url ( template_url ) # TODO: Add logic to try for S3 paths for child_template_path in child_template_paths : child_local_paths . append ( self . find_local_child_template ( current_template_path , child_template_path ) ) return child_local_paths","title":"Module taskcat._cfn.stack_url_helper"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#stackurlhelper","text":"class StackURLHelper ( template_mappings = None , template_parameters = None , parameter_values = None ) View Source class StackURLHelper : MAX_DEPTH = 20 # Handle at most 20 levels of nesting in TemplateURL expressions # TODO: Allow user to inject this # SUBSTITUTION = { # \"QSS3BucketName\": \"aws-quickstart\", # \"QSS3KeyPrefix\": \"QSS3KeyPrefix/\", # \"qss3KeyPrefix\": \"qss3KeyPrefix/\", # \"AWS::Region\": \"us-east-1\", # \"AWS::AccountId\": \"8888XXXX9999\", # } SUBSTITUTION = { \"AWS::Region\" : \"us-east-1\" , \"AWS::URLSuffix\" : \"amazonaws.com\" , \"AWS::AccountId\" : \"8888XXXX9999\" , } def __init__ ( self , template_mappings = None , template_parameters = None , parameter_values = None , ): if template_mappings : self . mappings = template_mappings else : self . mappings = {} if template_parameters : self . template_parameters = template_parameters else : self . template_parameters = {} if parameter_values : self . parameter_values = parameter_values else : self . parameter_values = {} default_parameters : dict = {} for parameter in self . template_parameters : properties = self . template_parameters . get ( parameter ) if \"Default\" in properties . keys (): default_parameters [ parameter ] = properties [ \"Default\" ] self . SUBSTITUTION . update ( default_parameters ) self . SUBSTITUTION . update ( self . parameter_values ) def rewrite_vars ( self , original_string , depth = 1 ): \"\"\"Replace the ${var} placeholders with ##var##\"\"\" parts = original_string . split ( \"${\" ) parts = parts [ 1 ] . split ( \"}\" ) rep_text = \"${\" + parts [ 0 ] + \"}\" rep_with = \"##\" + parts [ 0 ] + \"##\" result = original_string . replace ( rep_text , rep_with ) if len ( result . split ( \"${\" )) > 1 : result = self . rewrite_vars ( result , depth = ( depth + 1 )) return result def rewrite_sub_vars ( self , original_string , depth = 1 ): \"\"\"Replace the '##var##' placeholders with 'var'\"\"\" if \"##\" not in original_string : return original_string parts = original_string . split ( \"##\" ) parts = parts [ 1 ] . split ( \"##\" ) rep_text = \"##\" + parts [ 0 ] + \"##\" rep_with = \"\" + parts [ 0 ] + \"\" result = original_string . replace ( rep_text , rep_with ) if \"##\" in result : # Recurse if we have more variables result = self . rewrite_sub_vars ( result , depth = ( depth + 1 )) return result @ staticmethod def rewrite_sub_vars_with_values ( expression , values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" result = expression # replace each key we have a value for for key in values : rep_text = \"##\" + key + \"##\" rep_with = \"\" + str ( values [ key ]) + \"\" result = result . replace ( rep_text , rep_with ) return result @ staticmethod def values_to_dict ( values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" # Create dictionary of values values_dict_string = values . replace ( \"(\" , \"{\" ) values_dict_string = values_dict_string . replace ( \")\" , \"}\" ) values_dict_string = values_dict_string . replace ( \"'\" , '\"' ) # for values or keys not quoted # Split by : values_split_string = values_dict_string # Trim stuff so we can get the key values values_split_string = values_split_string . replace ( \" \" , \"\" ) values_split_string = values_split_string . replace ( \"{\" , \"\" ) values_split_string = values_split_string . replace ( \"}\" , \"\" ) values_split = values_split_string . split ( \",\" ) values_split_final = [] for value in values_split : values = value . split ( \":\" ) values_split_final . extend ( values ) for value in values_split_final : if value [ 0 ] != \"'\" and value [ - 1 ] != \"'\" : if value [ 0 ] != '\"' and value [ - 1 ] != '\"' : values_dict_string = values_dict_string . replace ( value , '\"' + value + '\"' ) values_dict = json . loads ( values_dict_string ) return values_dict def evaluate_fn_sub ( self , expression ): \"\"\" Return expression with values replaced \"\"\" results = [] # Builtins - Fudge some defaults here since we don't have runtime info # ${AWS::Region} ${AWS::AccountId} expression = self . rewrite_sub_vars_with_values ( expression , self . SUBSTITUTION ) # Handle Sub of form [ StringToSub, { \"key\" : \"value\", \"key\": \"value\" }] if \"[\" in expression : temp_expression = expression . split ( \"[\" )[ 1 ] . split ( \",\" )[ 0 ] values = expression . split ( \"[\" )[ 1 ] . split ( \"(\" )[ 1 ] . split ( \")\" )[ 0 ] values = self . values_to_dict ( \"(\" + values + \")\" ) temp_expression = self . rewrite_sub_vars_with_values ( temp_expression , values ) else : temp_expression = expression . split ( \"': '\" )[ 1 ] . split ( \"'\" )[ 0 ] # if we still have them we just use their values (ie: Parameters) result = self . rewrite_sub_vars ( temp_expression ) results . append ( result ) return results @ staticmethod def evaluate_fn_join ( expression ): \"\"\" Return the joined stuff \"\"\" results = [] new_values_list = [] temp = expression . split ( \"[\" )[ 1 ] delimiter = temp . split ( \",\" )[ 0 ] . strip ( \"'\" ) values = expression . split ( \"[\" )[ 2 ] values = values . split ( \"]]\" )[ 0 ] values_list = values . split ( \", \" ) for value in values_list : new_values_list . append ( value . strip ( \"'\" )) result = delimiter . join ( new_values_list ) results . append ( result ) return results @ staticmethod def evaluate_fn_if ( expression ): \"\"\" Return both possible parts of the expression \"\"\" results = [] value_true = expression . split ( \",\" )[ 1 ] . strip () value_false = expression . split ( \",\" )[ 2 ] . strip () . strip ( \"]\" ) # if we don't have '' this can break things results . append ( \"'\" + value_true . strip ( \"'\" ) + \"'\" ) results . append ( \"'\" + value_false . strip ( \"'\" ) + \"'\" ) return results def evaluate_fn_ref ( self , expression ): \"\"\"Since this is runtime data the best we can do is the name in place\"\"\" # TODO: Allow user to inject RunTime values for these results = [] temp = expression . split ( \": \" )[ 1 ] if temp . strip ( \"'\" ) in self . SUBSTITUTION . keys (): temp = self . SUBSTITUTION [ temp . strip ( \"'\" )] temp = \"'\" + temp + \"'\" results . append ( temp ) return results def find_in_map_lookup ( self , mappings_map , first_key , final_key ): step1 = self . mappings [ mappings_map . strip ( \"'\" )] step2 = step1 [ first_key . strip ( \"'\" )] result = step2 [ final_key . strip ( \"'\" )] return result def evaluate_fn_findinmap ( self , expression ): result = [] mappings_map = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 0 ] . strip () first_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 1 ] . strip () final_key = expression . split ( \"[\" )[ 1 ] . split ( \"]\" )[ 0 ] . split ( \",\" )[ 2 ] . strip () result . append ( \"'\" + self . find_in_map_lookup ( mappings_map , first_key , final_key ) + \"'\" ) return result @ staticmethod def evaluate_fn_getatt ( expression ): raise Exception ( \"Fn::GetAtt: not supported\" ) @ staticmethod def evaluate_fn_split ( expression ): raise Exception ( \"Fn::Split: not supported\" ) def evaluate_expression_controller ( self , expression ): \"\"\"Figure out what type of expression and pass off to handler\"\"\" results = [] if \"Fn::If\" in expression : results = self . evaluate_fn_if ( expression ) elif \"Fn::Sub\" in expression : results = self . evaluate_fn_sub ( expression ) elif \"Fn::Join\" in expression : results = self . evaluate_fn_join ( expression ) elif \"Ref\" in expression : results = self . evaluate_fn_ref ( expression ) elif \"Fn::FindInMap\" in expression : results = self . evaluate_fn_findinmap ( expression ) elif \"Fn::GetAtt\" in expression : results = self . evaluate_fn_getatt ( expression ) elif \"Fn::Split\" in expression : results = self . evaluate_fn_split ( expression ) else : # This is a NON expression repl { and } with ( and ) to break recursion results . append ( \"(\" + expression + \")\" ) return results def evaluate_string ( self , template_url , depth = 0 ): \"\"\"Recursively find expressions in the URL and send them to be evaluated\"\"\" # Recursion bail out if depth > self . MAX_DEPTH : raise Exception ( \"Template URL contains more than {} levels or nesting\" . format ( self . MAX_DEPTH ) ) template_urls = [] # Evaluate expressions if \"{\" in template_url : parts = template_url . split ( \"{\" ) parts = parts [ - 1 ] . split ( \"}\" ) # Last open bracket # This function will handle Fn::Sub Fn::If etc. replacements = self . evaluate_expression_controller ( parts [ 0 ] ) # First closed bracket after for replacement in replacements : template_url_temp = template_url template_url_temp = template_url_temp . replace ( \"{\" + parts [ 0 ] + \"}\" , replacement ) evaluated_strings = self . evaluate_string ( template_url_temp , depth = ( depth + 1 ) ) for evaluated_string in evaluated_strings : template_urls . append ( evaluated_string ) else : template_urls . append ( template_url ) return template_urls def _flatten_template_controller ( self , template_url ): \"\"\" Recursively evaluate subs/ifs\"\"\" url_list = [] # Replace ${SOMEVAR} with ##SOMEVAR## so finding actual \"expressions\" is easier template_url_string = str ( template_url ) parts = template_url_string . split ( \"${\" ) if len ( parts ) > 1 : template_url_string = self . rewrite_vars ( template_url_string ) # Evaluate expressions recursively if \"{\" in template_url_string : replacements = self . evaluate_string ( template_url_string ) # first closed bracket for replacement in replacements : url_list . append ( replacement ) else : url_list . append ( template_url ) return url_list def flatten_template_url ( self , template_url ): \"\"\"Flatten template_url and return all permutations\"\"\" path_list = [] url_list = self . _flatten_template_controller ( template_url ) # Extract the path portion from the URL for url in url_list : # TODO: figure where the ' is coming from output = urlparse ( str ( url . strip ( \"'\" ))) path_list . append ( output . path ) path_list = list ( dict . fromkeys ( path_list )) # print(url_list) # print(path_list) return path_list @ staticmethod def _remove_one_level ( path_string ): result = path_string result = result . find ( \"/\" , 0 ) result = path_string [ result + 1 : len ( path_string )] return result def find_local_child_template ( self , parent_template_path , child_template_path ): final_template_path = \"\" # Start where the Parent template is project_root = Path ( os . path . dirname ( parent_template_path )) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) # Take the path piece by piece and try in current folder while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) # Take the path piece by piece and try in one folder up folder project_root = Path ( os . path . normpath ( os . path . dirname ( parent_template_path ) + \"/../\" ) ) # Get rid of any \"//\" child_template_path_tmp = os . path . normpath ( child_template_path ) while \"/\" in str ( child_template_path_tmp ): child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \"/\" . join ([ str ( project_root ), str ( child_template_path_tmp )]) ) if final_template_path . exists () and final_template_path . is_file (): return str ( final_template_path ) return \"\" def template_url_to_path ( self , current_template_path , template_url , ): child_local_paths = [] child_template_paths = self . flatten_template_url ( template_url ) # TODO: Add logic to try for S3 paths for child_template_path in child_template_paths : child_local_paths . append ( self . find_local_child_template ( current_template_path , child_template_path ) ) return child_local_paths","title":"StackURLHelper"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#class-variables","text":"MAX_DEPTH SUBSTITUTION","title":"Class variables"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_getatt","text":"def evaluate_fn_getatt ( expression ) View Source @staticmethod def evaluate_fn_getatt ( expression ) : raise Exception ( \"Fn::GetAtt: not supported\" )","title":"evaluate_fn_getatt"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_if","text":"def evaluate_fn_if ( expression ) Return both possible parts of the expression View Source @staticmethod def evaluate_fn_if ( expression ) : \"\"\" Return both possible parts of the expression \"\"\" results = [] value_true = expression . split ( \",\" ) [ 1 ] . strip () value_false = expression . split ( \",\" ) [ 2 ] . strip (). strip ( \"]\" ) # if we don 't have '' this can break things results.append(\"' \" + value_true.strip(\" '\") + \"' \") results.append(\" '\" + value_false.strip(\"' \") + \" '\" ) return results","title":"evaluate_fn_if"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_join","text":"def evaluate_fn_join ( expression ) Return the joined stuff View Source @staticmethod def evaluate_fn_join ( expression ) : \"\"\" Return the joined stuff \"\"\" results = [] new_values_list = [] temp = expression . split ( \"[\" ) [ 1 ] delimiter = temp . split ( \",\" ) [ 0 ] . strip ( \"'\" ) values = expression . split ( \"[\" ) [ 2 ] values = values . split ( \"]]\" ) [ 0 ] values_list = values . split ( \", \" ) for value in values_list : new_values_list . append ( value . strip ( \"'\" )) result = delimiter . join ( new_values_list ) results . append ( result ) return results","title":"evaluate_fn_join"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_split","text":"def evaluate_fn_split ( expression ) View Source @staticmethod def evaluate_fn_split ( expression ) : raise Exception ( \"Fn::Split: not supported\" )","title":"evaluate_fn_split"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#rewrite_sub_vars_with_values","text":"def rewrite_sub_vars_with_values ( expression , values ) Rewrite sub vars with actual variable values View Source @staticmethod def rewrite_sub_vars_with_values ( expression , values ) : \"\"\"Rewrite sub vars with actual variable values\"\"\" result = expression # replace each key we have a value for for key in values : rep_text = \"##\" + key + \"##\" rep_with = \"\" + str ( values [ key ] ) + \"\" result = result . replace ( rep_text , rep_with ) return result","title":"rewrite_sub_vars_with_values"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#values_to_dict","text":"def values_to_dict ( values ) Rewrite sub vars with actual variable values View Source @ staticmethod def values_to_dict ( values ): \"\"\"Rewrite sub vars with actual variable values\"\"\" # Create dictionary of values values_dict_string = values . replace ( \"(\" , \"{\" ) values_dict_string = values_dict_string . replace ( \")\" , \"}\" ) values_dict_string = values_dict_string . replace ( \"'\" , '\"' ) # for values or keys not quoted # Split by : values_split_string = values_dict_string # Trim stuff so we can get the key values values_split_string = values_split_string . replace ( \" \" , \"\" ) values_split_string = values_split_string . replace ( \"{\" , \"\" ) values_split_string = values_split_string . replace ( \"}\" , \"\" ) values_split = values_split_string . split ( \",\" ) values_split_final = [] for value in values_split : values = value . split ( \":\" ) values_split_final . extend ( values ) for value in values_split_final : if value [ 0 ] != \"'\" and value [ - 1 ] != \"'\" : if value [ 0 ] != '\"' and value [ - 1 ] != '\"' : values_dict_string = values_dict_string . replace ( value , '\"' + value + '\"' ) values_dict = json . loads ( values_dict_string ) return values_dict","title":"values_to_dict"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_expression_controller","text":"def evaluate_expression_controller ( self , expression ) Figure out what type of expression and pass off to handler View Source def evaluate_expression_controller ( self , expression ) : \"\"\" Figure out what type of expression and pass off to handler \"\"\" results = [] if \" Fn::If \" in expression : results = self . evaluate_fn_if ( expression ) elif \" Fn::Sub \" in expression : results = self . evaluate_fn_sub ( expression ) elif \" Fn::Join \" in expression : results = self . evaluate_fn_join ( expression ) elif \" Ref \" in expression : results = self . evaluate_fn_ref ( expression ) elif \" Fn::FindInMap \" in expression : results = self . evaluate_fn_findinmap ( expression ) elif \" Fn::GetAtt \" in expression : results = self . evaluate_fn_getatt ( expression ) elif \" Fn::Split \" in expression : results = self . evaluate_fn_split ( expression ) else : # This is a NON expression repl { and } with ( and ) to break recursion results . append ( \" ( \" + expression + \" ) \" ) return results","title":"evaluate_expression_controller"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_findinmap","text":"def evaluate_fn_findinmap ( self , expression ) View Source def evaluate_fn_findinmap ( self , expression ) : result = [] mappings_map = expression . split ( \" [ \" ) [ 1 ]. split ( \" ] \" ) [ 0 ]. split ( \" , \" ) [ 0 ]. strip () first_key = expression . split ( \" [ \" ) [ 1 ]. split ( \" ] \" ) [ 0 ]. split ( \" , \" ) [ 1 ]. strip () final_key = expression . split ( \" [ \" ) [ 1 ]. split ( \" ] \" ) [ 0 ]. split ( \" , \" ) [ 2 ]. strip () result . append ( \" ' \" + self . find_in_map_lookup ( mappings_map , first_key , final_key ) + \" ' \" ) return result","title":"evaluate_fn_findinmap"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_ref","text":"def evaluate_fn_ref ( self , expression ) Since this is runtime data the best we can do is the name in place View Source def evaluate_fn_ref ( self , expression ) : \"\"\" Since this is runtime data the best we can do is the name in place \"\"\" # TODO : Allow user to inject RunTime values for these results = [] temp = expression . split ( \" : \" ) [ 1 ] if temp . strip ( \" ' \" ) in self . SUBSTITUTION . keys () : temp = self . SUBSTITUTION [ temp . strip ( \" ' \" ) ] temp = \" ' \" + temp + \" ' \" results . append ( temp ) return results","title":"evaluate_fn_ref"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_fn_sub","text":"def evaluate_fn_sub ( self , expression ) Return expression with values replaced View Source def evaluate_fn_sub ( self , expression ): \"\"\" Return expression with values replaced \"\"\" results = [] # Builtins - Fudge some defaults here since we don't have runtime info # ${AWS::Region} ${AWS::AccountId} expression = self . rewrite_sub_vars_with_values ( expression , self . SUBSTITUTION ) # Handle Sub of form [ StringToSub, { \"key\" : \"value\", \"key\": \"value\" }] if \"[\" in expression : temp_expression = expression . split ( \"[\" )[ 1 ] . split ( \",\" )[ 0 ] values = expression . split ( \"[\" )[ 1 ] . split ( \"(\" )[ 1 ] . split ( \")\" )[ 0 ] values = self . values_to_dict ( \"(\" + values + \")\" ) temp_expression = self . rewrite_sub_vars_with_values ( temp_expression , values ) else : temp_expression = expression . split ( \"': '\" )[ 1 ] . split ( \"'\" )[ 0 ] # if we still have them we just use their values (ie: Parameters) result = self . rewrite_sub_vars ( temp_expression ) results . append ( result ) return results","title":"evaluate_fn_sub"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#evaluate_string","text":"def evaluate_string ( self , template_url , depth = 0 ) Recursively find expressions in the URL and send them to be evaluated View Source def evaluate_string ( self , template_url , depth = 0 ) : \"\"\" Recursively find expressions in the URL and send them to be evaluated \"\"\" # Recursion bail out if depth > self . MAX_DEPTH : raise Exception ( \" Template URL contains more than {} levels or nesting \" . format ( self . MAX_DEPTH ) ) template_urls = [] # Evaluate expressions if \" { \" in template_url : parts = template_url . split ( \" { \" ) parts = parts [ - 1 ]. split ( \" } \" ) # Last open bracket # This function will handle Fn :: Sub Fn :: If etc . replacements = self . evaluate_expression_controller ( parts [ 0 ] ) # First closed bracket after for replacement in replacements : template_url_temp = template_url template_url_temp = template_url_temp . replace ( \" { \" + parts [ 0 ] + \" } \" , replacement ) evaluated_strings = self . evaluate_string ( template_url_temp , depth = ( depth + 1 ) ) for evaluated_string in evaluated_strings : template_urls . append ( evaluated_string ) else : template_urls . append ( template_url ) return template_urls","title":"evaluate_string"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#find_in_map_lookup","text":"def find_in_map_lookup ( self , mappings_map , first_key , final_key ) View Source def find_in_map_lookup ( self , mappings_map , first_key , final_key ) : step1 = self . mappings [ mappings_map . strip ( \" ' \" ) ] step2 = step1 [ first_key . strip ( \" ' \" ) ] result = step2 [ final_key . strip ( \" ' \" ) ] return result","title":"find_in_map_lookup"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#find_local_child_template","text":"def find_local_child_template ( self , parent_template_path , child_template_path ) View Source def find_local_child_template ( self , parent_template_path , child_template_path ) : final_template_path = \"\" # Start where the Parent template is project_root = Path ( os . path . dirname ( parent_template_path )) # Get rid of any \" // \" child_template_path_tmp = os . path . normpath ( child_template_path ) # Take the path piece by piece and try in current folder while \" / \" in str ( child_template_path_tmp ) : child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \" / \" . join ( [ str ( project_root ) , str ( child_template_path_tmp ) ] ) ) if final_template_path . exists () and final_template_path . is_file () : return str ( final_template_path ) # Take the path piece by piece and try in one folder up folder project_root = Path ( os . path . normpath ( os . path . dirname ( parent_template_path ) + \" /../ \" ) ) # Get rid of any \" // \" child_template_path_tmp = os . path . normpath ( child_template_path ) while \" / \" in str ( child_template_path_tmp ) : child_template_path_tmp = self . _remove_one_level ( child_template_path_tmp ) final_template_path = Path ( \" / \" . join ( [ str ( project_root ) , str ( child_template_path_tmp ) ] ) ) if final_template_path . exists () and final_template_path . is_file () : return str ( final_template_path ) return \"\"","title":"find_local_child_template"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#flatten_template_url","text":"def flatten_template_url ( self , template_url ) Flatten template_url and return all permutations View Source def flatten_template_url ( self , template_url ) : \"\"\" Flatten template_url and return all permutations \"\"\" path_list = [] url_list = self . _flatten_template_controller ( template_url ) # Extract the path portion from the URL for url in url_list : # TODO : figure where the ' is coming from output = urlparse ( str ( url . strip ( \" ' \" ))) path_list . append ( output . path ) path_list = list ( dict . fromkeys ( path_list )) # print ( url_list ) # print ( path_list ) return path_list","title":"flatten_template_url"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#rewrite_sub_vars","text":"def rewrite_sub_vars ( self , original_string , depth = 1 ) Replace the '##var##' placeholders with 'var' View Source def rewrite_sub_vars ( self , original_string , depth = 1 ): \"\"\"Replace the '##var##' placeholders with 'var'\"\"\" if \"##\" not in original_string : return original_string parts = original_string . split ( \"##\" ) parts = parts [ 1 ] . split ( \"##\" ) rep_text = \"##\" + parts [ 0 ] + \"##\" rep_with = \"\" + parts [ 0 ] + \"\" result = original_string . replace ( rep_text , rep_with ) if \"##\" in result : # Recurse if we have more variables result = self . rewrite_sub_vars ( result , depth = ( depth + 1 )) return result","title":"rewrite_sub_vars"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#rewrite_vars","text":"def rewrite_vars ( self , original_string , depth = 1 ) Replace the ${var} placeholders with ##var## View Source def rewrite_vars ( self , original_string , depth = 1 ): \"\"\"Replace the ${var} placeholders with ##var##\"\"\" parts = original_string . split ( \"${\" ) parts = parts [ 1 ] . split ( \"}\" ) rep_text = \"${\" + parts [ 0 ] + \"}\" rep_with = \"##\" + parts [ 0 ] + \"##\" result = original_string . replace ( rep_text , rep_with ) if len ( result . split ( \"${\" )) > 1 : result = self . rewrite_vars ( result , depth = ( depth + 1 )) return result","title":"rewrite_vars"},{"location":"reference/taskcat/_cfn/stack_url_helper.html#template_url_to_path","text":"def template_url_to_path ( self , current_template_path , template_url ) View Source def template_url_to_path ( self , current_template_path , template_url , ) : child_local_paths = [] child_template_paths = self . flatten_template_url ( template_url ) # TODO : Add logic to try for S3 paths for child_template_path in child_template_paths : child_local_paths . append ( self . find_local_child_template ( current_template_path , child_template_path ) ) return child_local_paths","title":"template_url_to_path"},{"location":"reference/taskcat/_cfn/template.html","text":"Module taskcat._cfn.template None None View Source import logging import re from pathlib import Path from time import sleep from typing import Dict , List , Union from yaml . scanner import ScannerError import cfnlint from taskcat . _ cfn . stack_url_helper import StackURLHelper from taskcat . exceptions import TaskCatException LOG = logging . getLogger ( __ name__ ) class TemplateCache : def __ init__ ( self , store : dict = None ) : self . _ templates = store if store else {} self . _ lock : Dict [ str , bool ] = {} def get ( self , template_path: str ) -> cfnlint . Template : while self . _ lock . get ( template_path ) : sleep ( 0.1 ) if template_path not in self . _ templates : try : self . _ lock [ template_path ] = True try : self . _ templates [ template_path ] = cfnlint . decode . cfn_yaml . load ( template_path ) except ScannerError as e : LOG . error ( f \"Failed to parse template {template_path} {e.problem} at \" f \"{e.problem_mark}\" ) raise self . _ lock [ template_path ] = False except Exception : # pylint : disable = broad - except self . _ lock [ template_path ] = False raise return self . _ templates [ template_path ] template_cache_store: Dict [ str , cfnlint . Template ] = {} tcat_template_cache = TemplateCache ( template_cache_store ) # pylint : disable = C0103 class Template : def __ init__ ( self , template_path: Union [ str , Path ], project_root: Union [ str , Path ] = \"\" , url : str = \"\" , s3_key_prefix: str = \"\" , template_cache: TemplateCache = tcat_template_cache , ) : self . template_cache = template_cache self . template_path: Path = Path ( template_path ). expanduser (). resolve () self . template = self . template_cache . get ( str ( self . template_path )) with open ( template_path , \"r\" ) as file_handle: self . raw_template = file_handle . read () project_root = ( project_root if project_root else self . template_path . parent . parent ) self . project_root = Path ( project_root ). expanduser (). resolve () self . url = url self . _ s3_key_prefix = s3_key_prefix self . children : List [ Template ] = [] self . _ find_children () def __ str__ ( self ) : return str ( self . template ) def __ repr__ ( self ) : return f \"<Template {self.template_path} at {hex(id(self))}>\" @property def s3_key ( self ) : suffix = str ( self . template_path . relative_to ( self . project_root ). as_posix ()) return self . _ s3_key_prefix + suffix @property def s3_key_prefix ( self ) : return self . _ s3_key_prefix @property def linesplit ( self ) : return self . raw_template . split ( \"\\n\" ) def write ( self ) : \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle: file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _ find_children () def _ template_url_to_path ( self , template_url , template_mappings = None , ) : try : helper = StackURLHelper ( template_mappings = template_mappings , template_parameters = self . template . get ( \"Parameters\" ), ) urls = helper . template_url_to_path ( current_template_path = self . template_path , template_url = template_url ) if len ( urls ) > 0 : return urls [ 0 ] except Exception as e : # pylint : disable = broad - except LOG . debug ( \"Traceback:\" , exc_info = True ) LOG . error ( \"TemplateURL parsing error: %s \" % str(e)) LOG . warning ( \"Failed to discover path for %s, path %s does not exist\" , template_url , None , ) return \"\" def _ get_relative_url ( self , path : str ) -> str : suffix = str ( path ). replace ( str ( self . project_root ), \"\" ) url = self . url_prefix () + suffix return url def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \")[0:-suffix_length]) return url_prefix def _find_children(self) -> None: # noqa: C901 children = set() if \" Resources \" not in self.template: raise TaskCatException( f\" did not receive a valid template : { self . template_path } does not \" f\" have a Resources section \" ) for resource in self.template[\" Resources \"].keys(): resource = self.template[\" Resources \"][resource] if resource[\" Type \"] == \" AWS :: CloudFormation :: Stack \": child_name = self._template_url_to_path( template_url=resource[\" Properties \"][\" TemplateURL \"], ) # print(child_name) if child_name: # for child_url in child_name: children.add(child_name) for child in children: child_template_instance = None for descendent in self.descendents: if str(descendent.template_path) == str(child): child_template_instance = descendent if not child_template_instance: try: child_template_instance = Template( child, self.project_root, self._get_relative_url(child), self._s3_key_prefix, tcat_template_cache, ) except Exception: # pylint: disable=broad-except LOG.debug(\" Traceback : \", exc_info=True) LOG.error(f\" Failed to add child template { child } \") if isinstance(child_template_instance, Template): self.children.append(child_template_instance) @property def descendents(self) -> List[\" Template \"]: desc_map = {} def recurse(template): for child in template.children: desc_map[str(child.template_path)] = child recurse(child) recurse(self) return list(desc_map.values()) def parameters( self, ) -> Dict[str, Union[None, str, int, bool, List[Union[int, str]]]]: parameters = {} for param_key, param in self.template.get(\" Parameters \", {}).items(): parameters[param_key] = param.get(\" Default \" ) return parameters Variables LOG tcat_template_cache template_cache_store Classes Template class Template ( template_path : Union [ str , pathlib . Path ], project_root : Union [ str , pathlib . Path ] = '' , url : str = '' , s3_key_prefix : str = '' , template_cache : taskcat . _cfn . template . TemplateCache = < taskcat . _cfn . template . TemplateCache object at 0x10ee7c490 > ) View Source class Template : def __ init__ ( self , template_path: Union [ str , Path ], project_root: Union [ str , Path ] = \"\" , url : str = \"\" , s3_key_prefix: str = \"\" , template_cache: TemplateCache = tcat_template_cache , ) : self . template_cache = template_cache self . template_path: Path = Path ( template_path ). expanduser (). resolve () self . template = self . template_cache . get ( str ( self . template_path )) with open ( template_path , \"r\" ) as file_handle: self . raw_template = file_handle . read () project_root = ( project_root if project_root else self . template_path . parent . parent ) self . project_root = Path ( project_root ). expanduser (). resolve () self . url = url self . _ s3_key_prefix = s3_key_prefix self . children : List [ Template ] = [] self . _ find_children () def __ str__ ( self ) : return str ( self . template ) def __ repr__ ( self ) : return f \"<Template {self.template_path} at {hex(id(self))}>\" @property def s3_key ( self ) : suffix = str ( self . template_path . relative_to ( self . project_root ). as_posix ()) return self . _ s3_key_prefix + suffix @property def s3_key_prefix ( self ) : return self . _ s3_key_prefix @property def linesplit ( self ) : return self . raw_template . split ( \"\\n\" ) def write ( self ) : \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle: file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _ find_children () def _ template_url_to_path ( self , template_url , template_mappings = None , ) : try : helper = StackURLHelper ( template_mappings = template_mappings , template_parameters = self . template . get ( \"Parameters\" ), ) urls = helper . template_url_to_path ( current_template_path = self . template_path , template_url = template_url ) if len ( urls ) > 0 : return urls [ 0 ] except Exception as e : # pylint : disable = broad - except LOG . debug ( \"Traceback:\" , exc_info = True ) LOG . error ( \"TemplateURL parsing error: %s \" % str(e)) LOG . warning ( \"Failed to discover path for %s, path %s does not exist\" , template_url , None , ) return \"\" def _ get_relative_url ( self , path : str ) -> str : suffix = str ( path ). replace ( str ( self . project_root ), \"\" ) url = self . url_prefix () + suffix return url def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \")[0:-suffix_length]) return url_prefix def _find_children(self) -> None: # noqa: C901 children = set() if \" Resources \" not in self.template: raise TaskCatException( f\" did not receive a valid template : { self . template_path } does not \" f\" have a Resources section \" ) for resource in self.template[\" Resources \"].keys(): resource = self.template[\" Resources \"][resource] if resource[\" Type \"] == \" AWS :: CloudFormation :: Stack \": child_name = self._template_url_to_path( template_url=resource[\" Properties \"][\" TemplateURL \"], ) # print(child_name) if child_name: # for child_url in child_name: children.add(child_name) for child in children: child_template_instance = None for descendent in self.descendents: if str(descendent.template_path) == str(child): child_template_instance = descendent if not child_template_instance: try: child_template_instance = Template( child, self.project_root, self._get_relative_url(child), self._s3_key_prefix, tcat_template_cache, ) except Exception: # pylint: disable=broad-except LOG.debug(\" Traceback : \", exc_info=True) LOG.error(f\" Failed to add child template { child } \") if isinstance(child_template_instance, Template): self.children.append(child_template_instance) @property def descendents(self) -> List[\" Template \"]: desc_map = {} def recurse(template): for child in template.children: desc_map[str(child.template_path)] = child recurse(child) recurse(self) return list(desc_map.values()) def parameters( self, ) -> Dict[str, Union[None, str, int, bool, List[Union[int, str]]]]: parameters = {} for param_key, param in self.template.get(\" Parameters \", {}).items(): parameters[param_key] = param.get(\" Default \" ) return parameters Instance variables descendents linesplit s3_key s3_key_prefix Methods parameters def parameters ( self ) -> Dict [ str , Union [ NoneType , str , int , bool , List [ Union [ int , str ]]]] View Source def parameters ( self , ) -> Dict [ str, Union[None, str, int, bool, List[Union[int, str ] ]]]: parameters = {} for param_key , param in self . template . get ( \"Parameters\" , {} ). items () : parameters [ param_key ] = param . get ( \"Default\" ) return parameters url_prefix def url_prefix ( self ) -> str View Source def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \" )[ 0 :- suffix_length ]) return url_prefix write def write ( self ) writes raw_template back to file, and reloads decoded template, useful if the template has been modified View Source def write ( self ): \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle : file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _find_children () TemplateCache class TemplateCache ( store : dict = None ) View Source class TemplateCache : def __init__ ( self , store : dict = None ) : self . _templates = store if store else {} self . _lock : Dict [ str, bool ] = {} def get ( self , template_path : str ) -> cfnlint . Template : while self . _lock . get ( template_path ) : sleep ( 0.1 ) if template_path not in self . _templates : try : self . _lock [ template_path ] = True try : self . _templates [ template_path ] = cfnlint . decode . cfn_yaml . load ( template_path ) except ScannerError as e : LOG . error ( f \"Failed to parse template {template_path} {e.problem} at \" f \"{e.problem_mark}\" ) raise self . _lock [ template_path ] = False except Exception : # pylint : disable = broad - except self . _lock [ template_path ] = False raise return self . _templates [ template_path ] Methods get def get ( self , template_path : str ) -> cfnlint . decorators . refactored . refactored .< locals >. cls_wrapper .< locals >. Wrapped View Source def get ( self , template_path : str ) -> cfnlint . Template : while self . _lock . get ( template_path ) : sleep ( 0.1 ) if template_path not in self . _templates : try : self . _lock [ template_path ] = True try : self . _templates [ template_path ] = cfnlint . decode . cfn_yaml . load ( template_path ) except ScannerError as e : LOG . error ( f \"Failed to parse template {template_path} {e.problem} at \" f \"{e.problem_mark}\" ) raise self . _lock [ template_path ] = False except Exception : # pylint : disable = broad - except self . _lock [ template_path ] = False raise return self . _templates [ template_path ]","title":"Template"},{"location":"reference/taskcat/_cfn/template.html#module-taskcat_cfntemplate","text":"None None View Source import logging import re from pathlib import Path from time import sleep from typing import Dict , List , Union from yaml . scanner import ScannerError import cfnlint from taskcat . _ cfn . stack_url_helper import StackURLHelper from taskcat . exceptions import TaskCatException LOG = logging . getLogger ( __ name__ ) class TemplateCache : def __ init__ ( self , store : dict = None ) : self . _ templates = store if store else {} self . _ lock : Dict [ str , bool ] = {} def get ( self , template_path: str ) -> cfnlint . Template : while self . _ lock . get ( template_path ) : sleep ( 0.1 ) if template_path not in self . _ templates : try : self . _ lock [ template_path ] = True try : self . _ templates [ template_path ] = cfnlint . decode . cfn_yaml . load ( template_path ) except ScannerError as e : LOG . error ( f \"Failed to parse template {template_path} {e.problem} at \" f \"{e.problem_mark}\" ) raise self . _ lock [ template_path ] = False except Exception : # pylint : disable = broad - except self . _ lock [ template_path ] = False raise return self . _ templates [ template_path ] template_cache_store: Dict [ str , cfnlint . Template ] = {} tcat_template_cache = TemplateCache ( template_cache_store ) # pylint : disable = C0103 class Template : def __ init__ ( self , template_path: Union [ str , Path ], project_root: Union [ str , Path ] = \"\" , url : str = \"\" , s3_key_prefix: str = \"\" , template_cache: TemplateCache = tcat_template_cache , ) : self . template_cache = template_cache self . template_path: Path = Path ( template_path ). expanduser (). resolve () self . template = self . template_cache . get ( str ( self . template_path )) with open ( template_path , \"r\" ) as file_handle: self . raw_template = file_handle . read () project_root = ( project_root if project_root else self . template_path . parent . parent ) self . project_root = Path ( project_root ). expanduser (). resolve () self . url = url self . _ s3_key_prefix = s3_key_prefix self . children : List [ Template ] = [] self . _ find_children () def __ str__ ( self ) : return str ( self . template ) def __ repr__ ( self ) : return f \"<Template {self.template_path} at {hex(id(self))}>\" @property def s3_key ( self ) : suffix = str ( self . template_path . relative_to ( self . project_root ). as_posix ()) return self . _ s3_key_prefix + suffix @property def s3_key_prefix ( self ) : return self . _ s3_key_prefix @property def linesplit ( self ) : return self . raw_template . split ( \"\\n\" ) def write ( self ) : \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle: file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _ find_children () def _ template_url_to_path ( self , template_url , template_mappings = None , ) : try : helper = StackURLHelper ( template_mappings = template_mappings , template_parameters = self . template . get ( \"Parameters\" ), ) urls = helper . template_url_to_path ( current_template_path = self . template_path , template_url = template_url ) if len ( urls ) > 0 : return urls [ 0 ] except Exception as e : # pylint : disable = broad - except LOG . debug ( \"Traceback:\" , exc_info = True ) LOG . error ( \"TemplateURL parsing error: %s \" % str(e)) LOG . warning ( \"Failed to discover path for %s, path %s does not exist\" , template_url , None , ) return \"\" def _ get_relative_url ( self , path : str ) -> str : suffix = str ( path ). replace ( str ( self . project_root ), \"\" ) url = self . url_prefix () + suffix return url def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \")[0:-suffix_length]) return url_prefix def _find_children(self) -> None: # noqa: C901 children = set() if \" Resources \" not in self.template: raise TaskCatException( f\" did not receive a valid template : { self . template_path } does not \" f\" have a Resources section \" ) for resource in self.template[\" Resources \"].keys(): resource = self.template[\" Resources \"][resource] if resource[\" Type \"] == \" AWS :: CloudFormation :: Stack \": child_name = self._template_url_to_path( template_url=resource[\" Properties \"][\" TemplateURL \"], ) # print(child_name) if child_name: # for child_url in child_name: children.add(child_name) for child in children: child_template_instance = None for descendent in self.descendents: if str(descendent.template_path) == str(child): child_template_instance = descendent if not child_template_instance: try: child_template_instance = Template( child, self.project_root, self._get_relative_url(child), self._s3_key_prefix, tcat_template_cache, ) except Exception: # pylint: disable=broad-except LOG.debug(\" Traceback : \", exc_info=True) LOG.error(f\" Failed to add child template { child } \") if isinstance(child_template_instance, Template): self.children.append(child_template_instance) @property def descendents(self) -> List[\" Template \"]: desc_map = {} def recurse(template): for child in template.children: desc_map[str(child.template_path)] = child recurse(child) recurse(self) return list(desc_map.values()) def parameters( self, ) -> Dict[str, Union[None, str, int, bool, List[Union[int, str]]]]: parameters = {} for param_key, param in self.template.get(\" Parameters \", {}).items(): parameters[param_key] = param.get(\" Default \" ) return parameters","title":"Module taskcat._cfn.template"},{"location":"reference/taskcat/_cfn/template.html#variables","text":"LOG tcat_template_cache template_cache_store","title":"Variables"},{"location":"reference/taskcat/_cfn/template.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cfn/template.html#template","text":"class Template ( template_path : Union [ str , pathlib . Path ], project_root : Union [ str , pathlib . Path ] = '' , url : str = '' , s3_key_prefix : str = '' , template_cache : taskcat . _cfn . template . TemplateCache = < taskcat . _cfn . template . TemplateCache object at 0x10ee7c490 > ) View Source class Template : def __ init__ ( self , template_path: Union [ str , Path ], project_root: Union [ str , Path ] = \"\" , url : str = \"\" , s3_key_prefix: str = \"\" , template_cache: TemplateCache = tcat_template_cache , ) : self . template_cache = template_cache self . template_path: Path = Path ( template_path ). expanduser (). resolve () self . template = self . template_cache . get ( str ( self . template_path )) with open ( template_path , \"r\" ) as file_handle: self . raw_template = file_handle . read () project_root = ( project_root if project_root else self . template_path . parent . parent ) self . project_root = Path ( project_root ). expanduser (). resolve () self . url = url self . _ s3_key_prefix = s3_key_prefix self . children : List [ Template ] = [] self . _ find_children () def __ str__ ( self ) : return str ( self . template ) def __ repr__ ( self ) : return f \"<Template {self.template_path} at {hex(id(self))}>\" @property def s3_key ( self ) : suffix = str ( self . template_path . relative_to ( self . project_root ). as_posix ()) return self . _ s3_key_prefix + suffix @property def s3_key_prefix ( self ) : return self . _ s3_key_prefix @property def linesplit ( self ) : return self . raw_template . split ( \"\\n\" ) def write ( self ) : \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle: file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _ find_children () def _ template_url_to_path ( self , template_url , template_mappings = None , ) : try : helper = StackURLHelper ( template_mappings = template_mappings , template_parameters = self . template . get ( \"Parameters\" ), ) urls = helper . template_url_to_path ( current_template_path = self . template_path , template_url = template_url ) if len ( urls ) > 0 : return urls [ 0 ] except Exception as e : # pylint : disable = broad - except LOG . debug ( \"Traceback:\" , exc_info = True ) LOG . error ( \"TemplateURL parsing error: %s \" % str(e)) LOG . warning ( \"Failed to discover path for %s, path %s does not exist\" , template_url , None , ) return \"\" def _ get_relative_url ( self , path : str ) -> str : suffix = str ( path ). replace ( str ( self . project_root ), \"\" ) url = self . url_prefix () + suffix return url def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \")[0:-suffix_length]) return url_prefix def _find_children(self) -> None: # noqa: C901 children = set() if \" Resources \" not in self.template: raise TaskCatException( f\" did not receive a valid template : { self . template_path } does not \" f\" have a Resources section \" ) for resource in self.template[\" Resources \"].keys(): resource = self.template[\" Resources \"][resource] if resource[\" Type \"] == \" AWS :: CloudFormation :: Stack \": child_name = self._template_url_to_path( template_url=resource[\" Properties \"][\" TemplateURL \"], ) # print(child_name) if child_name: # for child_url in child_name: children.add(child_name) for child in children: child_template_instance = None for descendent in self.descendents: if str(descendent.template_path) == str(child): child_template_instance = descendent if not child_template_instance: try: child_template_instance = Template( child, self.project_root, self._get_relative_url(child), self._s3_key_prefix, tcat_template_cache, ) except Exception: # pylint: disable=broad-except LOG.debug(\" Traceback : \", exc_info=True) LOG.error(f\" Failed to add child template { child } \") if isinstance(child_template_instance, Template): self.children.append(child_template_instance) @property def descendents(self) -> List[\" Template \"]: desc_map = {} def recurse(template): for child in template.children: desc_map[str(child.template_path)] = child recurse(child) recurse(self) return list(desc_map.values()) def parameters( self, ) -> Dict[str, Union[None, str, int, bool, List[Union[int, str]]]]: parameters = {} for param_key, param in self.template.get(\" Parameters \", {}).items(): parameters[param_key] = param.get(\" Default \" ) return parameters","title":"Template"},{"location":"reference/taskcat/_cfn/template.html#instance-variables","text":"descendents linesplit s3_key s3_key_prefix","title":"Instance variables"},{"location":"reference/taskcat/_cfn/template.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/template.html#parameters","text":"def parameters ( self ) -> Dict [ str , Union [ NoneType , str , int , bool , List [ Union [ int , str ]]]] View Source def parameters ( self , ) -> Dict [ str, Union[None, str, int, bool, List[Union[int, str ] ]]]: parameters = {} for param_key , param in self . template . get ( \"Parameters\" , {} ). items () : parameters [ param_key ] = param . get ( \"Default\" ) return parameters","title":"parameters"},{"location":"reference/taskcat/_cfn/template.html#url_prefix","text":"def url_prefix ( self ) -> str View Source def url_prefix ( self ) -> str : if not self . url : return \"\" regionless_url = re . sub ( r \" \\.s3\\. (. * ) \\.amazonaws\\.com \", \" . s3 . amazonaws . com \", self.url, ) suffix = str(self.template_path).replace(str(self.project_root), \"\") suffix_length = len(suffix.lstrip(\" / \").split(\" / \")) url_prefix = \" / \".join(regionless_url.split(\" / \" )[ 0 :- suffix_length ]) return url_prefix","title":"url_prefix"},{"location":"reference/taskcat/_cfn/template.html#write","text":"def write ( self ) writes raw_template back to file, and reloads decoded template, useful if the template has been modified View Source def write ( self ): \"\"\"writes raw_template back to file, and reloads decoded template, useful if the template has been modified\"\"\" with open ( str ( self . template_path ), \"w\" ) as file_handle : file_handle . write ( self . raw_template ) self . template = cfnlint . decode . cfn_yaml . load ( self . template_path ) self . _find_children ()","title":"write"},{"location":"reference/taskcat/_cfn/template.html#templatecache","text":"class TemplateCache ( store : dict = None ) View Source class TemplateCache : def __init__ ( self , store : dict = None ) : self . _templates = store if store else {} self . _lock : Dict [ str, bool ] = {} def get ( self , template_path : str ) -> cfnlint . Template : while self . _lock . get ( template_path ) : sleep ( 0.1 ) if template_path not in self . _templates : try : self . _lock [ template_path ] = True try : self . _templates [ template_path ] = cfnlint . decode . cfn_yaml . load ( template_path ) except ScannerError as e : LOG . error ( f \"Failed to parse template {template_path} {e.problem} at \" f \"{e.problem_mark}\" ) raise self . _lock [ template_path ] = False except Exception : # pylint : disable = broad - except self . _lock [ template_path ] = False raise return self . _templates [ template_path ]","title":"TemplateCache"},{"location":"reference/taskcat/_cfn/template.html#methods_1","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/template.html#get","text":"def get ( self , template_path : str ) -> cfnlint . decorators . refactored . refactored .< locals >. cls_wrapper .< locals >. Wrapped View Source def get ( self , template_path : str ) -> cfnlint . Template : while self . _lock . get ( template_path ) : sleep ( 0.1 ) if template_path not in self . _templates : try : self . _lock [ template_path ] = True try : self . _templates [ template_path ] = cfnlint . decode . cfn_yaml . load ( template_path ) except ScannerError as e : LOG . error ( f \"Failed to parse template {template_path} {e.problem} at \" f \"{e.problem_mark}\" ) raise self . _lock [ template_path ] = False except Exception : # pylint : disable = broad - except self . _lock [ template_path ] = False raise return self . _templates [ template_path ]","title":"get"},{"location":"reference/taskcat/_cfn/threaded.html","text":"Module taskcat._cfn.threaded None None View Source import logging import uuid from functools import partial from multiprocessing.dummy import Pool as ThreadPool from typing import Dict , List import boto3 from taskcat._cfn.stack import Stack , Stacks , StackStatus from taskcat._client_factory import Boto3Cache from taskcat._common_utils import merge_dicts from taskcat._dataclasses import Tag , TestObj , TestRegion from taskcat.exceptions import TaskCatException LOG = logging . getLogger ( __name__ ) def fan_out ( func , partial_kwargs , payload , threads ): pool = ThreadPool ( threads ) if partial_kwargs : func = partial ( func , ** partial_kwargs ) results = pool . map ( func , payload ) pool . close () pool . join () return results class Stacker : NULL_UUID = uuid . UUID ( int = 0 ) def __init__ ( self , project_name : str , tests : Dict [ str , TestObj ], uid : uuid . UUID = NULL_UUID , stack_name_prefix : str = \"tCaT\" , shorten_stack_name : bool = False , tags : list = None , ): self . tests = tests self . project_name = project_name self . stack_name_prefix = stack_name_prefix self . shorten_stack_name = shorten_stack_name self . tags = tags if tags else [] self . uid = uuid . uuid4 () if uid == Stacker . NULL_UUID else uid self . stacks : Stacks = Stacks () @staticmethod def _tests_to_list ( tests : Dict [ str , TestObj ]): return list ( tests . values ()) def create_stacks ( self , threads : int = 8 ): if self . stacks : raise TaskCatException ( \"Stacker already initialised with stack objects\" ) tests = self . _tests_to_list ( self . tests ) tags = [ Tag ({ \"Key\" : \"taskcat-id\" , \"Value\" : self . uid . hex })] tags += [ Tag ( t ) for t in self . tags if t . key not in [ \"taskcat-project-name\" , \"taskcat-test-name\" , \"taskcat-id\" ] ] fan_out ( self . _create_stacks_for_test , { \"tags\" : tags }, tests , threads ) def _create_stacks_for_test ( self , test , tags , threads : int = 32 ): stack_name = test . stack_name tags . append ( Tag ({ \"Key\" : \"taskcat-project-name\" , \"Value\" : self . project_name })) tags . append ( Tag ({ \"Key\" : \"taskcat-test-name\" , \"Value\" : test . name })) tags += test . tags partial_kwargs = { \"stack_name\" : stack_name , \"template\" : test . template , \"tags\" : tags , \"test_name\" : test . name , } stacks = fan_out ( Stack . create , partial_kwargs , test . regions , threads ) self . stacks += stacks # Not used by tCat at present def update_stacks ( self ): raise NotImplementedError () def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ): if deep : raise NotImplementedError ( \"deep delete not yet implemented\" ) fan_out ( self . _delete_stacks_per_client , None , self . _group_stacks ( self . stacks . filter ( criteria )), threads , ) def _delete_stacks_per_client ( self , stacks , threads = 8 ): fan_out ( self . _delete_stack , None , stacks [ \"Stacks\" ], threads ) @staticmethod def _delete_stack ( stack : Stack ): stack . delete ( stack_id = stack . id , client = stack . client ) stack . refresh () def status ( self , recurse : bool = False , threads : int = 32 , ** kwargs ): if recurse : raise NotImplementedError ( \"recurse not implemented\" ) stacks = self . stacks . filter ( kwargs ) per_region_stacks = self . _group_stacks ( stacks ) results = fan_out ( self . _status_per_client , None , per_region_stacks , threads ) statuses : Dict [ str , dict ] = { \"IN_PROGRESS\" : {}, \"COMPLETE\" : {}, \"FAILED\" : {}} for region in results : for status in region : statuses [ status [ 1 ]][ status [ 0 ]] = status [ 2 ] return statuses def _status_per_client ( self , stacks , threads : int = 8 ): return fan_out ( self . _status , None , stacks [ \"Stacks\" ], threads ) @staticmethod def _status ( stack : Stack ): for status_group in [ \"COMPLETE\" , \"IN_PROGRESS\" , \"FAILED\" ]: if stack . status in getattr ( StackStatus , status_group ): return stack . id , status_group , stack . status_reason raise TaskCatException ( f \"Invalid stack { stack } \" ) def events ( self , recurse = False , threads : int = 32 , ** kwargs ): if recurse : raise NotImplementedError ( \"recurse not implemented\" ) per_region_stacks = self . _group_stacks ( self . stacks ) results = fan_out ( self . _events_per_client , { \"criteria\" : kwargs }, per_region_stacks , threads ) return merge_dicts ( results ) def _events_per_client ( self , stacks , criteria , threads : int = 8 ): results = fan_out ( self . _describe_stack_events , { \"criteria\" : criteria }, stacks [ \"Stacks\" ], threads , ) return merge_dicts ( results ) @staticmethod def _describe_stack_events ( stack : Stack , criteria ): return { stack . id : stack . events () . filter ( criteria )} def resources ( self , recurse = False , threads : int = 32 , ** kwargs ): if recurse : raise NotImplementedError ( \"recurse not implemented\" ) results = fan_out ( self . _resources_per_client , { \"criteria\" : kwargs }, self . _group_stacks ( self . stacks ), threads , ) return merge_dicts ( results ) def _resources_per_client ( self , stacks , criteria , threads : int = 8 ): results = fan_out ( self . _resources , { \"criteria\" : criteria }, stacks [ \"Stacks\" ], threads ) return merge_dicts ( results ) @staticmethod def _resources ( stack : Stack , criteria ): return { stack . id : stack . resources () . filter ( criteria )} @classmethod def from_existing ( cls , uid : uuid . UUID , project_name : str , tests : Dict [ str , TestObj ], include_deleted = False , recurse = False , threads = 32 , ): if include_deleted : raise NotImplementedError ( \"including deleted stacks not implemented\" ) if recurse : raise NotImplementedError ( \"recurse not implemented\" ) clients : Dict [ boto3 . client , List [ TestRegion ]] = {} for test in tests . values (): for region in test . regions : client = region . client ( \"cloudformation\" ) if client not in clients : clients [ client ] = [] clients [ client ] . append ( region ) results = fan_out ( Stacker . _import_stacks_per_client , { \"uid\" : uid , \"project_name\" : project_name , \"tests\" : tests }, clients . items (), threads , ) stacker = Stacker ( project_name , tests , uid ) stacker . stacks = Stacks ([ item for sublist in results for item in sublist ]) return stacker @staticmethod def _import_stacks_per_client ( clients , uid , project_name , tests ): # pylint: disable=too-many-locals stacks = Stacks () client , region = clients for page in client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack_props in page [ \"Stacks\" ]: if stack_props . get ( \"ParentId\" ): continue match = False project = \"\" test = \"\" for tag in stack_props [ \"Tags\" ]: k , v = ( tag [ \"Key\" ], tag [ \"Value\" ]) if k == \"taskcat-id\" and v == uid . hex : match = True elif k == \"taskcat-test-name\" and v in tests : test = v elif k == \"taskcat-project-name\" and v == project_name : project = v if match and test and project : stack = Stack . import_existing ( stack_props , tests [ test ] . template , region [ 0 ], test , uid , ) stacks . append ( stack ) return stacks @staticmethod def _group_stacks ( stacks : Stacks ) -> List [ dict ]: stacks_by_client : dict = {} for stack in stacks : client = stack . client if client not in stacks_by_client : stacks_by_client [ client ] = { \"Client\" : client , \"Stacks\" : []} stacks_by_client [ client ][ \"Stacks\" ] . append ( stack ) return [ stacks_by_client [ r ] for r in stacks_by_client ] @staticmethod def list_stacks ( profiles , regions ): stacks = fan_out ( Stacker . _list_per_profile , { \"regions\" : regions , \"boto_cache\" : Boto3Cache ()}, profiles , threads = 8 , ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _list_per_profile ( profile , regions , boto_cache ): stacks = fan_out ( Stacker . _get_taskcat_stacks , { \"boto_cache\" : boto_cache , \"profile\" : profile }, regions , threads = len ( regions ), ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _get_taskcat_stacks ( region , boto_cache : Boto3Cache , profile : str ): stacks = [] try : cfn = boto_cache . client ( \"cloudformation\" , profile = profile , region = region ) for page in cfn . get_paginator ( \"describe_stacks\" ) . paginate (): for stack_props in page [ \"Stacks\" ]: if stack_props . get ( \"ParentId\" ): continue stack_id = stack_props [ \"StackId\" ] stack_name = stack_id . split ( \"/\" )[ 1 ] stack = { \"region\" : region , \"profile\" : profile , \"stack-id\" : stack_id , \"stack-name\" : stack_name , } for tag in stack_props [ \"Tags\" ]: k , v = ( tag [ \"Key\" ], tag [ \"Value\" ]) if k . startswith ( \"taskcat-\" ): stack [ k ] = v if stack . get ( \"taskcat-id\" ): stack [ \"taskcat-id\" ] = uuid . UUID ( stack [ \"taskcat-id\" ]) stacks . append ( stack ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to fetch stacks for region { region } using profile \" f \" { profile } { type ( e ) } { e } \" ) LOG . debug ( \"Traceback:\" , exc_info = True ) return stacks Variables LOG Functions fan_out def fan_out ( func , partial_kwargs , payload , threads ) View Source def fan_out ( func , partial_kwargs , payload , threads ): pool = ThreadPool ( threads ) if partial_kwargs : func = partial ( func , ** partial_kwargs ) results = pool . map ( func , payload ) pool . close () pool . join () return results Classes Stacker class Stacker ( project_name : str , tests : Dict [ str , taskcat . _dataclasses . TestObj ], uid : uuid . UUID = UUID ( '00000000-0000-0000-0000-000000000000' ), stack_name_prefix : str = 'tCaT' , shorten_stack_name : bool = False , tags : list = None ) View Source class Stacker : NULL_UUID = uuid . UUID ( int = 0 ) def __init__ ( self , project_name : str , tests : Dict [ str, TestObj ] , uid : uuid . UUID = NULL_UUID , stack_name_prefix : str = \"tCaT\" , shorten_stack_name : bool = False , tags : list = None , ) : self . tests = tests self . project_name = project_name self . stack_name_prefix = stack_name_prefix self . shorten_stack_name = shorten_stack_name self . tags = tags if tags else [] self . uid = uuid . uuid4 () if uid == Stacker . NULL_UUID else uid self . stacks : Stacks = Stacks () @staticmethod def _tests_to_list ( tests : Dict [ str, TestObj ] ) : return list ( tests . values ()) def create_stacks ( self , threads : int = 8 ) : if self . stacks : raise TaskCatException ( \"Stacker already initialised with stack objects\" ) tests = self . _tests_to_list ( self . tests ) tags = [ Tag({\"Key\": \"taskcat-id\", \"Value\": self.uid.hex}) ] tags += [ Tag(t) for t in self.tags if t.key not in [\"taskcat-project-name\", \"taskcat-test-name\", \"taskcat-id\" ] ] fan_out ( self . _create_stacks_for_test , { \"tags\" : tags } , tests , threads ) def _create_stacks_for_test ( self , test , tags , threads : int = 32 ) : stack_name = test . stack_name tags . append ( Tag ( { \"Key\" : \"taskcat-project-name\" , \"Value\" : self . project_name } )) tags . append ( Tag ( { \"Key\" : \"taskcat-test-name\" , \"Value\" : test . name } )) tags += test . tags partial_kwargs = { \"stack_name\" : stack_name , \"template\" : test . template , \"tags\" : tags , \"test_name\" : test . name , } stacks = fan_out ( Stack . create , partial_kwargs , test . regions , threads ) self . stacks += stacks # Not used by tCat at present def update_stacks ( self ) : raise NotImplementedError () def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ) : if deep : raise NotImplementedError ( \"deep delete not yet implemented\" ) fan_out ( self . _delete_stacks_per_client , None , self . _group_stacks ( self . stacks . filter ( criteria )), threads , ) def _delete_stacks_per_client ( self , stacks , threads = 8 ) : fan_out ( self . _delete_stack , None , stacks [ \"Stacks\" ] , threads ) @staticmethod def _delete_stack ( stack : Stack ) : stack . delete ( stack_id = stack . id , client = stack . client ) stack . refresh () def status ( self , recurse : bool = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \"recurse not implemented\" ) stacks = self . stacks . filter ( kwargs ) per_region_stacks = self . _group_stacks ( stacks ) results = fan_out ( self . _status_per_client , None , per_region_stacks , threads ) statuses : Dict [ str, dict ] = { \"IN_PROGRESS\" : {} , \"COMPLETE\" : {} , \"FAILED\" : {}} for region in results : for status in region : statuses [ status[1 ] ] [ status[0 ] ] = status [ 2 ] return statuses def _status_per_client ( self , stacks , threads : int = 8 ) : return fan_out ( self . _status , None , stacks [ \"Stacks\" ] , threads ) @staticmethod def _status ( stack : Stack ) : for status_group in [ \"COMPLETE\", \"IN_PROGRESS\", \"FAILED\" ] : if stack . status in getattr ( StackStatus , status_group ) : return stack . id , status_group , stack . status_reason raise TaskCatException ( f \"Invalid stack {stack}\" ) def events ( self , recurse = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \"recurse not implemented\" ) per_region_stacks = self . _group_stacks ( self . stacks ) results = fan_out ( self . _events_per_client , { \"criteria\" : kwargs } , per_region_stacks , threads ) return merge_dicts ( results ) def _events_per_client ( self , stacks , criteria , threads : int = 8 ) : results = fan_out ( self . _describe_stack_events , { \"criteria\" : criteria } , stacks [ \"Stacks\" ] , threads , ) return merge_dicts ( results ) @staticmethod def _describe_stack_events ( stack : Stack , criteria ) : return { stack . id : stack . events (). filter ( criteria ) } def resources ( self , recurse = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \"recurse not implemented\" ) results = fan_out ( self . _resources_per_client , { \"criteria\" : kwargs } , self . _group_stacks ( self . stacks ), threads , ) return merge_dicts ( results ) def _resources_per_client ( self , stacks , criteria , threads : int = 8 ) : results = fan_out ( self . _resources , { \"criteria\" : criteria } , stacks [ \"Stacks\" ] , threads ) return merge_dicts ( results ) @staticmethod def _resources ( stack : Stack , criteria ) : return { stack . id : stack . resources (). filter ( criteria ) } @classmethod def from_existing ( cls , uid : uuid . UUID , project_name : str , tests : Dict [ str, TestObj ] , include_deleted = False , recurse = False , threads = 32 , ) : if include_deleted : raise NotImplementedError ( \"including deleted stacks not implemented\" ) if recurse : raise NotImplementedError ( \"recurse not implemented\" ) clients : Dict [ boto3.client, List[TestRegion ] ] = {} for test in tests . values () : for region in test . regions : client = region . client ( \"cloudformation\" ) if client not in clients : clients [ client ] = [] clients [ client ] . append ( region ) results = fan_out ( Stacker . _import_stacks_per_client , { \"uid\" : uid , \"project_name\" : project_name , \"tests\" : tests } , clients . items (), threads , ) stacker = Stacker ( project_name , tests , uid ) stacker . stacks = Stacks ( [ item for sublist in results for item in sublist ] ) return stacker @staticmethod def _import_stacks_per_client ( clients , uid , project_name , tests ) : # pylint : disable = too - many - locals stacks = Stacks () client , region = clients for page in client . get_paginator ( \"describe_stacks\" ). paginate () : for stack_props in page [ \"Stacks\" ] : if stack_props . get ( \"ParentId\" ) : continue match = False project = \"\" test = \"\" for tag in stack_props [ \"Tags\" ] : k , v = ( tag [ \"Key\" ] , tag [ \"Value\" ] ) if k == \"taskcat-id\" and v == uid . hex : match = True elif k == \"taskcat-test-name\" and v in tests : test = v elif k == \"taskcat-project-name\" and v == project_name : project = v if match and test and project : stack = Stack . import_existing ( stack_props , tests [ test ] . template , region [ 0 ] , test , uid , ) stacks . append ( stack ) return stacks @staticmethod def _group_stacks ( stacks : Stacks ) -> List [ dict ] : stacks_by_client : dict = {} for stack in stacks : client = stack . client if client not in stacks_by_client : stacks_by_client [ client ] = { \"Client\" : client , \"Stacks\" : []} stacks_by_client [ client ][ \"Stacks\" ] . append ( stack ) return [ stacks_by_client[r ] for r in stacks_by_client ] @staticmethod def list_stacks ( profiles , regions ) : stacks = fan_out ( Stacker . _list_per_profile , { \"regions\" : regions , \"boto_cache\" : Boto3Cache () } , profiles , threads = 8 , ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _list_per_profile ( profile , regions , boto_cache ) : stacks = fan_out ( Stacker . _get_taskcat_stacks , { \"boto_cache\" : boto_cache , \"profile\" : profile } , regions , threads = len ( regions ), ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _get_taskcat_stacks ( region , boto_cache : Boto3Cache , profile : str ) : stacks = [] try : cfn = boto_cache . client ( \"cloudformation\" , profile = profile , region = region ) for page in cfn . get_paginator ( \"describe_stacks\" ). paginate () : for stack_props in page [ \"Stacks\" ] : if stack_props . get ( \"ParentId\" ) : continue stack_id = stack_props [ \"StackId\" ] stack_name = stack_id . split ( \"/\" ) [ 1 ] stack = { \"region\" : region , \"profile\" : profile , \"stack-id\" : stack_id , \"stack-name\" : stack_name , } for tag in stack_props [ \"Tags\" ] : k , v = ( tag [ \"Key\" ] , tag [ \"Value\" ] ) if k . startswith ( \"taskcat-\" ) : stack [ k ] = v if stack . get ( \"taskcat-id\" ) : stack [ \"taskcat-id\" ] = uuid . UUID ( stack [ \"taskcat-id\" ] ) stacks . append ( stack ) except Exception as e : # pylint : disable = broad - except LOG . warning ( f \"Failed to fetch stacks for region {region} using profile \" f \"{profile} {type(e)} {e}\" ) LOG . debug ( \"Traceback:\" , exc_info = True ) return stacks Class variables NULL_UUID Static methods from_existing def from_existing ( uid : uuid . UUID , project_name : str , tests : Dict [ str , taskcat . _dataclasses . TestObj ], include_deleted = False , recurse = False , threads = 32 ) View Source @classmethod def from_existing ( cls , uid : uuid . UUID , project_name : str , tests : Dict [ str, TestObj ] , include_deleted = False , recurse = False , threads = 32 , ) : if include_deleted : raise NotImplementedError ( \"including deleted stacks not implemented\" ) if recurse : raise NotImplementedError ( \"recurse not implemented\" ) clients : Dict [ boto3.client, List[TestRegion ] ] = {} for test in tests . values () : for region in test . regions : client = region . client ( \"cloudformation\" ) if client not in clients : clients [ client ] = [] clients [ client ] . append ( region ) results = fan_out ( Stacker . _import_stacks_per_client , { \"uid\" : uid , \"project_name\" : project_name , \"tests\" : tests } , clients . items (), threads , ) stacker = Stacker ( project_name , tests , uid ) stacker . stacks = Stacks ( [ item for sublist in results for item in sublist ] ) return stacker list_stacks def list_stacks ( profiles , regions ) View Source @staticmethod def list_stacks ( profiles , regions ) : stacks = fan_out ( Stacker . _list_per_profile , { \"regions\" : regions , \"boto_cache\" : Boto3Cache () } , profiles , threads = 8 , ) return [ stack for sublist in stacks for stack in sublist ] Methods create_stacks def create_stacks ( self , threads : int = 8 ) View Source def create_stacks ( self , threads : int = 8 ) : if self . stacks : raise TaskCatException ( \" Stacker already initialised with stack objects \" ) tests = self . _tests_to_list ( self . tests ) tags = [ Tag ( { \" Key \" : \" taskcat-id \" , \" Value \" : self . uid . hex } ) ] tags += [ Tag ( t ) for t in self . tags if t . key not in [ \" taskcat-project-name \" , \" taskcat-test-name \" , \" taskcat-id \" ] ] fan_out ( self . _create_stacks_for_test , { \" tags \" : tags }, tests , threads ) delete_stacks def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ) View Source def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ) : if deep : raise NotImplementedError ( \" deep delete not yet implemented \" ) fan_out ( self . _delete_stacks_per_client , None , self . _group_stacks ( self . stacks . filter ( criteria )) , threads , ) events def events ( self , recurse = False , threads : int = 32 , ** kwargs ) View Source def events ( self , recurse = False , threads: int = 32 , ** kwargs ) : if recurse: raise NotImplementedError ( \"recurse not implemented\" ) per_region_stacks = self . _group_stacks ( self . stacks ) results = fan_out ( self . _events_per_client , { \"criteria\" : kwargs }, per_region_stacks , threads ) return merge_dicts ( results ) resources def resources ( self , recurse = False , threads : int = 32 , ** kwargs ) View Source def resources ( self , recurse = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \" recurse not implemented \" ) results = fan_out ( self . _resources_per_client , { \" criteria \" : kwargs }, self . _group_stacks ( self . stacks ) , threads , ) return merge_dicts ( results ) status def status ( self , recurse : bool = False , threads : int = 32 , ** kwargs ) View Source def status ( self , recurse: bool = False , threads: int = 32 , ** kwargs ) : if recurse: raise NotImplementedError ( \"recurse not implemented\" ) stacks = self . stacks . filter ( kwargs ) per_region_stacks = self . _group_stacks ( stacks ) results = fan_out ( self . _status_per_client , None , per_region_stacks , threads ) statuses: Dict [ str , dict ] = { \"IN_PROGRESS\" : {}, \"COMPLETE\" : {}, \"FAILED\" : {}} for region in results: for status in region: statuses [ status [ 1 ]][ status [ 0 ]] = status [ 2 ] return statuses update_stacks def update_stacks ( self ) View Source def update_stacks(self): raise NotImplementedError()","title":"Threaded"},{"location":"reference/taskcat/_cfn/threaded.html#module-taskcat_cfnthreaded","text":"None None View Source import logging import uuid from functools import partial from multiprocessing.dummy import Pool as ThreadPool from typing import Dict , List import boto3 from taskcat._cfn.stack import Stack , Stacks , StackStatus from taskcat._client_factory import Boto3Cache from taskcat._common_utils import merge_dicts from taskcat._dataclasses import Tag , TestObj , TestRegion from taskcat.exceptions import TaskCatException LOG = logging . getLogger ( __name__ ) def fan_out ( func , partial_kwargs , payload , threads ): pool = ThreadPool ( threads ) if partial_kwargs : func = partial ( func , ** partial_kwargs ) results = pool . map ( func , payload ) pool . close () pool . join () return results class Stacker : NULL_UUID = uuid . UUID ( int = 0 ) def __init__ ( self , project_name : str , tests : Dict [ str , TestObj ], uid : uuid . UUID = NULL_UUID , stack_name_prefix : str = \"tCaT\" , shorten_stack_name : bool = False , tags : list = None , ): self . tests = tests self . project_name = project_name self . stack_name_prefix = stack_name_prefix self . shorten_stack_name = shorten_stack_name self . tags = tags if tags else [] self . uid = uuid . uuid4 () if uid == Stacker . NULL_UUID else uid self . stacks : Stacks = Stacks () @staticmethod def _tests_to_list ( tests : Dict [ str , TestObj ]): return list ( tests . values ()) def create_stacks ( self , threads : int = 8 ): if self . stacks : raise TaskCatException ( \"Stacker already initialised with stack objects\" ) tests = self . _tests_to_list ( self . tests ) tags = [ Tag ({ \"Key\" : \"taskcat-id\" , \"Value\" : self . uid . hex })] tags += [ Tag ( t ) for t in self . tags if t . key not in [ \"taskcat-project-name\" , \"taskcat-test-name\" , \"taskcat-id\" ] ] fan_out ( self . _create_stacks_for_test , { \"tags\" : tags }, tests , threads ) def _create_stacks_for_test ( self , test , tags , threads : int = 32 ): stack_name = test . stack_name tags . append ( Tag ({ \"Key\" : \"taskcat-project-name\" , \"Value\" : self . project_name })) tags . append ( Tag ({ \"Key\" : \"taskcat-test-name\" , \"Value\" : test . name })) tags += test . tags partial_kwargs = { \"stack_name\" : stack_name , \"template\" : test . template , \"tags\" : tags , \"test_name\" : test . name , } stacks = fan_out ( Stack . create , partial_kwargs , test . regions , threads ) self . stacks += stacks # Not used by tCat at present def update_stacks ( self ): raise NotImplementedError () def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ): if deep : raise NotImplementedError ( \"deep delete not yet implemented\" ) fan_out ( self . _delete_stacks_per_client , None , self . _group_stacks ( self . stacks . filter ( criteria )), threads , ) def _delete_stacks_per_client ( self , stacks , threads = 8 ): fan_out ( self . _delete_stack , None , stacks [ \"Stacks\" ], threads ) @staticmethod def _delete_stack ( stack : Stack ): stack . delete ( stack_id = stack . id , client = stack . client ) stack . refresh () def status ( self , recurse : bool = False , threads : int = 32 , ** kwargs ): if recurse : raise NotImplementedError ( \"recurse not implemented\" ) stacks = self . stacks . filter ( kwargs ) per_region_stacks = self . _group_stacks ( stacks ) results = fan_out ( self . _status_per_client , None , per_region_stacks , threads ) statuses : Dict [ str , dict ] = { \"IN_PROGRESS\" : {}, \"COMPLETE\" : {}, \"FAILED\" : {}} for region in results : for status in region : statuses [ status [ 1 ]][ status [ 0 ]] = status [ 2 ] return statuses def _status_per_client ( self , stacks , threads : int = 8 ): return fan_out ( self . _status , None , stacks [ \"Stacks\" ], threads ) @staticmethod def _status ( stack : Stack ): for status_group in [ \"COMPLETE\" , \"IN_PROGRESS\" , \"FAILED\" ]: if stack . status in getattr ( StackStatus , status_group ): return stack . id , status_group , stack . status_reason raise TaskCatException ( f \"Invalid stack { stack } \" ) def events ( self , recurse = False , threads : int = 32 , ** kwargs ): if recurse : raise NotImplementedError ( \"recurse not implemented\" ) per_region_stacks = self . _group_stacks ( self . stacks ) results = fan_out ( self . _events_per_client , { \"criteria\" : kwargs }, per_region_stacks , threads ) return merge_dicts ( results ) def _events_per_client ( self , stacks , criteria , threads : int = 8 ): results = fan_out ( self . _describe_stack_events , { \"criteria\" : criteria }, stacks [ \"Stacks\" ], threads , ) return merge_dicts ( results ) @staticmethod def _describe_stack_events ( stack : Stack , criteria ): return { stack . id : stack . events () . filter ( criteria )} def resources ( self , recurse = False , threads : int = 32 , ** kwargs ): if recurse : raise NotImplementedError ( \"recurse not implemented\" ) results = fan_out ( self . _resources_per_client , { \"criteria\" : kwargs }, self . _group_stacks ( self . stacks ), threads , ) return merge_dicts ( results ) def _resources_per_client ( self , stacks , criteria , threads : int = 8 ): results = fan_out ( self . _resources , { \"criteria\" : criteria }, stacks [ \"Stacks\" ], threads ) return merge_dicts ( results ) @staticmethod def _resources ( stack : Stack , criteria ): return { stack . id : stack . resources () . filter ( criteria )} @classmethod def from_existing ( cls , uid : uuid . UUID , project_name : str , tests : Dict [ str , TestObj ], include_deleted = False , recurse = False , threads = 32 , ): if include_deleted : raise NotImplementedError ( \"including deleted stacks not implemented\" ) if recurse : raise NotImplementedError ( \"recurse not implemented\" ) clients : Dict [ boto3 . client , List [ TestRegion ]] = {} for test in tests . values (): for region in test . regions : client = region . client ( \"cloudformation\" ) if client not in clients : clients [ client ] = [] clients [ client ] . append ( region ) results = fan_out ( Stacker . _import_stacks_per_client , { \"uid\" : uid , \"project_name\" : project_name , \"tests\" : tests }, clients . items (), threads , ) stacker = Stacker ( project_name , tests , uid ) stacker . stacks = Stacks ([ item for sublist in results for item in sublist ]) return stacker @staticmethod def _import_stacks_per_client ( clients , uid , project_name , tests ): # pylint: disable=too-many-locals stacks = Stacks () client , region = clients for page in client . get_paginator ( \"describe_stacks\" ) . paginate (): for stack_props in page [ \"Stacks\" ]: if stack_props . get ( \"ParentId\" ): continue match = False project = \"\" test = \"\" for tag in stack_props [ \"Tags\" ]: k , v = ( tag [ \"Key\" ], tag [ \"Value\" ]) if k == \"taskcat-id\" and v == uid . hex : match = True elif k == \"taskcat-test-name\" and v in tests : test = v elif k == \"taskcat-project-name\" and v == project_name : project = v if match and test and project : stack = Stack . import_existing ( stack_props , tests [ test ] . template , region [ 0 ], test , uid , ) stacks . append ( stack ) return stacks @staticmethod def _group_stacks ( stacks : Stacks ) -> List [ dict ]: stacks_by_client : dict = {} for stack in stacks : client = stack . client if client not in stacks_by_client : stacks_by_client [ client ] = { \"Client\" : client , \"Stacks\" : []} stacks_by_client [ client ][ \"Stacks\" ] . append ( stack ) return [ stacks_by_client [ r ] for r in stacks_by_client ] @staticmethod def list_stacks ( profiles , regions ): stacks = fan_out ( Stacker . _list_per_profile , { \"regions\" : regions , \"boto_cache\" : Boto3Cache ()}, profiles , threads = 8 , ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _list_per_profile ( profile , regions , boto_cache ): stacks = fan_out ( Stacker . _get_taskcat_stacks , { \"boto_cache\" : boto_cache , \"profile\" : profile }, regions , threads = len ( regions ), ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _get_taskcat_stacks ( region , boto_cache : Boto3Cache , profile : str ): stacks = [] try : cfn = boto_cache . client ( \"cloudformation\" , profile = profile , region = region ) for page in cfn . get_paginator ( \"describe_stacks\" ) . paginate (): for stack_props in page [ \"Stacks\" ]: if stack_props . get ( \"ParentId\" ): continue stack_id = stack_props [ \"StackId\" ] stack_name = stack_id . split ( \"/\" )[ 1 ] stack = { \"region\" : region , \"profile\" : profile , \"stack-id\" : stack_id , \"stack-name\" : stack_name , } for tag in stack_props [ \"Tags\" ]: k , v = ( tag [ \"Key\" ], tag [ \"Value\" ]) if k . startswith ( \"taskcat-\" ): stack [ k ] = v if stack . get ( \"taskcat-id\" ): stack [ \"taskcat-id\" ] = uuid . UUID ( stack [ \"taskcat-id\" ]) stacks . append ( stack ) except Exception as e : # pylint: disable=broad-except LOG . warning ( f \"Failed to fetch stacks for region { region } using profile \" f \" { profile } { type ( e ) } { e } \" ) LOG . debug ( \"Traceback:\" , exc_info = True ) return stacks","title":"Module taskcat._cfn.threaded"},{"location":"reference/taskcat/_cfn/threaded.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cfn/threaded.html#functions","text":"","title":"Functions"},{"location":"reference/taskcat/_cfn/threaded.html#fan_out","text":"def fan_out ( func , partial_kwargs , payload , threads ) View Source def fan_out ( func , partial_kwargs , payload , threads ): pool = ThreadPool ( threads ) if partial_kwargs : func = partial ( func , ** partial_kwargs ) results = pool . map ( func , payload ) pool . close () pool . join () return results","title":"fan_out"},{"location":"reference/taskcat/_cfn/threaded.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cfn/threaded.html#stacker","text":"class Stacker ( project_name : str , tests : Dict [ str , taskcat . _dataclasses . TestObj ], uid : uuid . UUID = UUID ( '00000000-0000-0000-0000-000000000000' ), stack_name_prefix : str = 'tCaT' , shorten_stack_name : bool = False , tags : list = None ) View Source class Stacker : NULL_UUID = uuid . UUID ( int = 0 ) def __init__ ( self , project_name : str , tests : Dict [ str, TestObj ] , uid : uuid . UUID = NULL_UUID , stack_name_prefix : str = \"tCaT\" , shorten_stack_name : bool = False , tags : list = None , ) : self . tests = tests self . project_name = project_name self . stack_name_prefix = stack_name_prefix self . shorten_stack_name = shorten_stack_name self . tags = tags if tags else [] self . uid = uuid . uuid4 () if uid == Stacker . NULL_UUID else uid self . stacks : Stacks = Stacks () @staticmethod def _tests_to_list ( tests : Dict [ str, TestObj ] ) : return list ( tests . values ()) def create_stacks ( self , threads : int = 8 ) : if self . stacks : raise TaskCatException ( \"Stacker already initialised with stack objects\" ) tests = self . _tests_to_list ( self . tests ) tags = [ Tag({\"Key\": \"taskcat-id\", \"Value\": self.uid.hex}) ] tags += [ Tag(t) for t in self.tags if t.key not in [\"taskcat-project-name\", \"taskcat-test-name\", \"taskcat-id\" ] ] fan_out ( self . _create_stacks_for_test , { \"tags\" : tags } , tests , threads ) def _create_stacks_for_test ( self , test , tags , threads : int = 32 ) : stack_name = test . stack_name tags . append ( Tag ( { \"Key\" : \"taskcat-project-name\" , \"Value\" : self . project_name } )) tags . append ( Tag ( { \"Key\" : \"taskcat-test-name\" , \"Value\" : test . name } )) tags += test . tags partial_kwargs = { \"stack_name\" : stack_name , \"template\" : test . template , \"tags\" : tags , \"test_name\" : test . name , } stacks = fan_out ( Stack . create , partial_kwargs , test . regions , threads ) self . stacks += stacks # Not used by tCat at present def update_stacks ( self ) : raise NotImplementedError () def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ) : if deep : raise NotImplementedError ( \"deep delete not yet implemented\" ) fan_out ( self . _delete_stacks_per_client , None , self . _group_stacks ( self . stacks . filter ( criteria )), threads , ) def _delete_stacks_per_client ( self , stacks , threads = 8 ) : fan_out ( self . _delete_stack , None , stacks [ \"Stacks\" ] , threads ) @staticmethod def _delete_stack ( stack : Stack ) : stack . delete ( stack_id = stack . id , client = stack . client ) stack . refresh () def status ( self , recurse : bool = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \"recurse not implemented\" ) stacks = self . stacks . filter ( kwargs ) per_region_stacks = self . _group_stacks ( stacks ) results = fan_out ( self . _status_per_client , None , per_region_stacks , threads ) statuses : Dict [ str, dict ] = { \"IN_PROGRESS\" : {} , \"COMPLETE\" : {} , \"FAILED\" : {}} for region in results : for status in region : statuses [ status[1 ] ] [ status[0 ] ] = status [ 2 ] return statuses def _status_per_client ( self , stacks , threads : int = 8 ) : return fan_out ( self . _status , None , stacks [ \"Stacks\" ] , threads ) @staticmethod def _status ( stack : Stack ) : for status_group in [ \"COMPLETE\", \"IN_PROGRESS\", \"FAILED\" ] : if stack . status in getattr ( StackStatus , status_group ) : return stack . id , status_group , stack . status_reason raise TaskCatException ( f \"Invalid stack {stack}\" ) def events ( self , recurse = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \"recurse not implemented\" ) per_region_stacks = self . _group_stacks ( self . stacks ) results = fan_out ( self . _events_per_client , { \"criteria\" : kwargs } , per_region_stacks , threads ) return merge_dicts ( results ) def _events_per_client ( self , stacks , criteria , threads : int = 8 ) : results = fan_out ( self . _describe_stack_events , { \"criteria\" : criteria } , stacks [ \"Stacks\" ] , threads , ) return merge_dicts ( results ) @staticmethod def _describe_stack_events ( stack : Stack , criteria ) : return { stack . id : stack . events (). filter ( criteria ) } def resources ( self , recurse = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \"recurse not implemented\" ) results = fan_out ( self . _resources_per_client , { \"criteria\" : kwargs } , self . _group_stacks ( self . stacks ), threads , ) return merge_dicts ( results ) def _resources_per_client ( self , stacks , criteria , threads : int = 8 ) : results = fan_out ( self . _resources , { \"criteria\" : criteria } , stacks [ \"Stacks\" ] , threads ) return merge_dicts ( results ) @staticmethod def _resources ( stack : Stack , criteria ) : return { stack . id : stack . resources (). filter ( criteria ) } @classmethod def from_existing ( cls , uid : uuid . UUID , project_name : str , tests : Dict [ str, TestObj ] , include_deleted = False , recurse = False , threads = 32 , ) : if include_deleted : raise NotImplementedError ( \"including deleted stacks not implemented\" ) if recurse : raise NotImplementedError ( \"recurse not implemented\" ) clients : Dict [ boto3.client, List[TestRegion ] ] = {} for test in tests . values () : for region in test . regions : client = region . client ( \"cloudformation\" ) if client not in clients : clients [ client ] = [] clients [ client ] . append ( region ) results = fan_out ( Stacker . _import_stacks_per_client , { \"uid\" : uid , \"project_name\" : project_name , \"tests\" : tests } , clients . items (), threads , ) stacker = Stacker ( project_name , tests , uid ) stacker . stacks = Stacks ( [ item for sublist in results for item in sublist ] ) return stacker @staticmethod def _import_stacks_per_client ( clients , uid , project_name , tests ) : # pylint : disable = too - many - locals stacks = Stacks () client , region = clients for page in client . get_paginator ( \"describe_stacks\" ). paginate () : for stack_props in page [ \"Stacks\" ] : if stack_props . get ( \"ParentId\" ) : continue match = False project = \"\" test = \"\" for tag in stack_props [ \"Tags\" ] : k , v = ( tag [ \"Key\" ] , tag [ \"Value\" ] ) if k == \"taskcat-id\" and v == uid . hex : match = True elif k == \"taskcat-test-name\" and v in tests : test = v elif k == \"taskcat-project-name\" and v == project_name : project = v if match and test and project : stack = Stack . import_existing ( stack_props , tests [ test ] . template , region [ 0 ] , test , uid , ) stacks . append ( stack ) return stacks @staticmethod def _group_stacks ( stacks : Stacks ) -> List [ dict ] : stacks_by_client : dict = {} for stack in stacks : client = stack . client if client not in stacks_by_client : stacks_by_client [ client ] = { \"Client\" : client , \"Stacks\" : []} stacks_by_client [ client ][ \"Stacks\" ] . append ( stack ) return [ stacks_by_client[r ] for r in stacks_by_client ] @staticmethod def list_stacks ( profiles , regions ) : stacks = fan_out ( Stacker . _list_per_profile , { \"regions\" : regions , \"boto_cache\" : Boto3Cache () } , profiles , threads = 8 , ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _list_per_profile ( profile , regions , boto_cache ) : stacks = fan_out ( Stacker . _get_taskcat_stacks , { \"boto_cache\" : boto_cache , \"profile\" : profile } , regions , threads = len ( regions ), ) return [ stack for sublist in stacks for stack in sublist ] @staticmethod def _get_taskcat_stacks ( region , boto_cache : Boto3Cache , profile : str ) : stacks = [] try : cfn = boto_cache . client ( \"cloudformation\" , profile = profile , region = region ) for page in cfn . get_paginator ( \"describe_stacks\" ). paginate () : for stack_props in page [ \"Stacks\" ] : if stack_props . get ( \"ParentId\" ) : continue stack_id = stack_props [ \"StackId\" ] stack_name = stack_id . split ( \"/\" ) [ 1 ] stack = { \"region\" : region , \"profile\" : profile , \"stack-id\" : stack_id , \"stack-name\" : stack_name , } for tag in stack_props [ \"Tags\" ] : k , v = ( tag [ \"Key\" ] , tag [ \"Value\" ] ) if k . startswith ( \"taskcat-\" ) : stack [ k ] = v if stack . get ( \"taskcat-id\" ) : stack [ \"taskcat-id\" ] = uuid . UUID ( stack [ \"taskcat-id\" ] ) stacks . append ( stack ) except Exception as e : # pylint : disable = broad - except LOG . warning ( f \"Failed to fetch stacks for region {region} using profile \" f \"{profile} {type(e)} {e}\" ) LOG . debug ( \"Traceback:\" , exc_info = True ) return stacks","title":"Stacker"},{"location":"reference/taskcat/_cfn/threaded.html#class-variables","text":"NULL_UUID","title":"Class variables"},{"location":"reference/taskcat/_cfn/threaded.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/_cfn/threaded.html#from_existing","text":"def from_existing ( uid : uuid . UUID , project_name : str , tests : Dict [ str , taskcat . _dataclasses . TestObj ], include_deleted = False , recurse = False , threads = 32 ) View Source @classmethod def from_existing ( cls , uid : uuid . UUID , project_name : str , tests : Dict [ str, TestObj ] , include_deleted = False , recurse = False , threads = 32 , ) : if include_deleted : raise NotImplementedError ( \"including deleted stacks not implemented\" ) if recurse : raise NotImplementedError ( \"recurse not implemented\" ) clients : Dict [ boto3.client, List[TestRegion ] ] = {} for test in tests . values () : for region in test . regions : client = region . client ( \"cloudformation\" ) if client not in clients : clients [ client ] = [] clients [ client ] . append ( region ) results = fan_out ( Stacker . _import_stacks_per_client , { \"uid\" : uid , \"project_name\" : project_name , \"tests\" : tests } , clients . items (), threads , ) stacker = Stacker ( project_name , tests , uid ) stacker . stacks = Stacks ( [ item for sublist in results for item in sublist ] ) return stacker","title":"from_existing"},{"location":"reference/taskcat/_cfn/threaded.html#list_stacks","text":"def list_stacks ( profiles , regions ) View Source @staticmethod def list_stacks ( profiles , regions ) : stacks = fan_out ( Stacker . _list_per_profile , { \"regions\" : regions , \"boto_cache\" : Boto3Cache () } , profiles , threads = 8 , ) return [ stack for sublist in stacks for stack in sublist ]","title":"list_stacks"},{"location":"reference/taskcat/_cfn/threaded.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/_cfn/threaded.html#create_stacks","text":"def create_stacks ( self , threads : int = 8 ) View Source def create_stacks ( self , threads : int = 8 ) : if self . stacks : raise TaskCatException ( \" Stacker already initialised with stack objects \" ) tests = self . _tests_to_list ( self . tests ) tags = [ Tag ( { \" Key \" : \" taskcat-id \" , \" Value \" : self . uid . hex } ) ] tags += [ Tag ( t ) for t in self . tags if t . key not in [ \" taskcat-project-name \" , \" taskcat-test-name \" , \" taskcat-id \" ] ] fan_out ( self . _create_stacks_for_test , { \" tags \" : tags }, tests , threads )","title":"create_stacks"},{"location":"reference/taskcat/_cfn/threaded.html#delete_stacks","text":"def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ) View Source def delete_stacks ( self , criteria : dict = None , deep = False , threads = 32 ) : if deep : raise NotImplementedError ( \" deep delete not yet implemented \" ) fan_out ( self . _delete_stacks_per_client , None , self . _group_stacks ( self . stacks . filter ( criteria )) , threads , )","title":"delete_stacks"},{"location":"reference/taskcat/_cfn/threaded.html#events","text":"def events ( self , recurse = False , threads : int = 32 , ** kwargs ) View Source def events ( self , recurse = False , threads: int = 32 , ** kwargs ) : if recurse: raise NotImplementedError ( \"recurse not implemented\" ) per_region_stacks = self . _group_stacks ( self . stacks ) results = fan_out ( self . _events_per_client , { \"criteria\" : kwargs }, per_region_stacks , threads ) return merge_dicts ( results )","title":"events"},{"location":"reference/taskcat/_cfn/threaded.html#resources","text":"def resources ( self , recurse = False , threads : int = 32 , ** kwargs ) View Source def resources ( self , recurse = False , threads : int = 32 , ** kwargs ) : if recurse : raise NotImplementedError ( \" recurse not implemented \" ) results = fan_out ( self . _resources_per_client , { \" criteria \" : kwargs }, self . _group_stacks ( self . stacks ) , threads , ) return merge_dicts ( results )","title":"resources"},{"location":"reference/taskcat/_cfn/threaded.html#status","text":"def status ( self , recurse : bool = False , threads : int = 32 , ** kwargs ) View Source def status ( self , recurse: bool = False , threads: int = 32 , ** kwargs ) : if recurse: raise NotImplementedError ( \"recurse not implemented\" ) stacks = self . stacks . filter ( kwargs ) per_region_stacks = self . _group_stacks ( stacks ) results = fan_out ( self . _status_per_client , None , per_region_stacks , threads ) statuses: Dict [ str , dict ] = { \"IN_PROGRESS\" : {}, \"COMPLETE\" : {}, \"FAILED\" : {}} for region in results: for status in region: statuses [ status [ 1 ]][ status [ 0 ]] = status [ 2 ] return statuses","title":"status"},{"location":"reference/taskcat/_cfn/threaded.html#update_stacks","text":"def update_stacks ( self ) View Source def update_stacks(self): raise NotImplementedError()","title":"update_stacks"},{"location":"reference/taskcat/_cli_modules/index.html","text":"Module taskcat._cli_modules None None View Source from .delete import Delete # noqa: F401 from .deploy import Deploy # noqa: F401 from .lint import Lint # noqa: F401 from .list import List # noqa: F401 from .package import Package # noqa: F401 from .test import Test # noqa: F401 from .update_ami import UpdateAMI # noqa: F401 from .upload import Upload # noqa: F401 Sub-modules taskcat._cli_modules.delete taskcat._cli_modules.deploy taskcat._cli_modules.lint taskcat._cli_modules.list taskcat._cli_modules.package taskcat._cli_modules.test taskcat._cli_modules.update_ami taskcat._cli_modules.upload","title":"Index"},{"location":"reference/taskcat/_cli_modules/index.html#module-taskcat_cli_modules","text":"None None View Source from .delete import Delete # noqa: F401 from .deploy import Deploy # noqa: F401 from .lint import Lint # noqa: F401 from .list import List # noqa: F401 from .package import Package # noqa: F401 from .test import Test # noqa: F401 from .update_ami import UpdateAMI # noqa: F401 from .upload import Upload # noqa: F401","title":"Module taskcat._cli_modules"},{"location":"reference/taskcat/_cli_modules/index.html#sub-modules","text":"taskcat._cli_modules.delete taskcat._cli_modules.deploy taskcat._cli_modules.lint taskcat._cli_modules.list taskcat._cli_modules.package taskcat._cli_modules.test taskcat._cli_modules.update_ami taskcat._cli_modules.upload","title":"Sub-modules"},{"location":"reference/taskcat/_cli_modules/delete.html","text":"Module taskcat._cli_modules.delete None None View Source # pylint: disable=duplicate-code import logging from taskcat._cfn.stack import Stack from taskcat._cfn.threaded import Stacker from taskcat._client_factory import Boto3Cache LOG = logging . getLogger ( __name__ ) class Delete : \"\"\"[ALPHA] Deletes an installed package in an AWS account/region\"\"\" def __init__ ( self , package : str , aws_profile : str = \"default\" , region = \"default\" , _stack_type = \"package\" , ): \"\"\" :param package: installed package to delete, can be an install name or uuid :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will use aws cli configured default \"\"\" LOG . warning ( \"delete is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if region == \"default\" : region = boto3_cache . get_default_region ( aws_profile ) if isinstance ( region , str ): region = [ region ] stacks = Stacker . list_stacks ([ aws_profile ], region ) jobs = [] for stack in stacks : name = stack . get ( \"taskcat-installer\" , stack [ \"taskcat-project-name\" ]) job = { \"name\" : name , \"project_name\" : stack [ \"taskcat-project-name\" ], \"test_name\" : stack [ \"taskcat-test-name\" ], \"taskcat_id\" : stack [ \"taskcat-id\" ] . hex , \"region\" : stack [ \"region\" ], \"type\" : \"package\" if stack . get ( \"taskcat-installer\" ) else \"test\" , \"stack_id\" : stack [ \"stack-id\" ], } if _stack_type == job [ \"type\" ]: if package in [ job [ \"name\" ], job [ \"taskcat_id\" ], \"ALL\" ]: jobs . append ( job ) # TODO: concurrency and wait for complete for job in jobs : client = boto3_cache . client ( \"cloudformation\" , profile = aws_profile , region = job [ \"region\" ] ) Stack . delete ( client = client , stack_id = job [ \"stack_id\" ]) Variables LOG Classes Delete class Delete ( package : str , aws_profile : str = 'default' , region = 'default' , _stack_type = 'package' ) View Source class Delete : \"\"\"[ALPHA] Deletes an installed package in an AWS account/region\"\"\" def __init__ ( self , package : str , aws_profile : str = \"default\" , region = \"default\" , _stack_type = \"package\" , ) : \"\"\" :param package: installed package to delete, can be an install name or uuid :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will use aws cli configured default \"\"\" LOG . warning ( \"delete is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if region == \"default\" : region = boto3_cache . get_default_region ( aws_profile ) if isinstance ( region , str ) : region = [ region ] stacks = Stacker . list_stacks ( [ aws_profile ] , region ) jobs = [] for stack in stacks : name = stack . get ( \"taskcat-installer\" , stack [ \"taskcat-project-name\" ] ) job = { \"name\" : name , \"project_name\" : stack [ \"taskcat-project-name\" ] , \"test_name\" : stack [ \"taskcat-test-name\" ] , \"taskcat_id\" : stack [ \"taskcat-id\" ] . hex , \"region\" : stack [ \"region\" ] , \"type\" : \"package\" if stack . get ( \"taskcat-installer\" ) else \"test\" , \"stack_id\" : stack [ \"stack-id\" ] , } if _stack_type == job [ \"type\" ] : if package in [ job[\"name\" ] , job [ \"taskcat_id\" ] , \"ALL\" ]: jobs . append ( job ) # TODO : concurrency and wait for complete for job in jobs : client = boto3_cache . client ( \"cloudformation\" , profile = aws_profile , region = job [ \"region\" ] ) Stack . delete ( client = client , stack_id = job [ \"stack_id\" ] )","title":"Delete"},{"location":"reference/taskcat/_cli_modules/delete.html#module-taskcat_cli_modulesdelete","text":"None None View Source # pylint: disable=duplicate-code import logging from taskcat._cfn.stack import Stack from taskcat._cfn.threaded import Stacker from taskcat._client_factory import Boto3Cache LOG = logging . getLogger ( __name__ ) class Delete : \"\"\"[ALPHA] Deletes an installed package in an AWS account/region\"\"\" def __init__ ( self , package : str , aws_profile : str = \"default\" , region = \"default\" , _stack_type = \"package\" , ): \"\"\" :param package: installed package to delete, can be an install name or uuid :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will use aws cli configured default \"\"\" LOG . warning ( \"delete is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if region == \"default\" : region = boto3_cache . get_default_region ( aws_profile ) if isinstance ( region , str ): region = [ region ] stacks = Stacker . list_stacks ([ aws_profile ], region ) jobs = [] for stack in stacks : name = stack . get ( \"taskcat-installer\" , stack [ \"taskcat-project-name\" ]) job = { \"name\" : name , \"project_name\" : stack [ \"taskcat-project-name\" ], \"test_name\" : stack [ \"taskcat-test-name\" ], \"taskcat_id\" : stack [ \"taskcat-id\" ] . hex , \"region\" : stack [ \"region\" ], \"type\" : \"package\" if stack . get ( \"taskcat-installer\" ) else \"test\" , \"stack_id\" : stack [ \"stack-id\" ], } if _stack_type == job [ \"type\" ]: if package in [ job [ \"name\" ], job [ \"taskcat_id\" ], \"ALL\" ]: jobs . append ( job ) # TODO: concurrency and wait for complete for job in jobs : client = boto3_cache . client ( \"cloudformation\" , profile = aws_profile , region = job [ \"region\" ] ) Stack . delete ( client = client , stack_id = job [ \"stack_id\" ])","title":"Module taskcat._cli_modules.delete"},{"location":"reference/taskcat/_cli_modules/delete.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/delete.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/delete.html#delete","text":"class Delete ( package : str , aws_profile : str = 'default' , region = 'default' , _stack_type = 'package' ) View Source class Delete : \"\"\"[ALPHA] Deletes an installed package in an AWS account/region\"\"\" def __init__ ( self , package : str , aws_profile : str = \"default\" , region = \"default\" , _stack_type = \"package\" , ) : \"\"\" :param package: installed package to delete, can be an install name or uuid :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will use aws cli configured default \"\"\" LOG . warning ( \"delete is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if region == \"default\" : region = boto3_cache . get_default_region ( aws_profile ) if isinstance ( region , str ) : region = [ region ] stacks = Stacker . list_stacks ( [ aws_profile ] , region ) jobs = [] for stack in stacks : name = stack . get ( \"taskcat-installer\" , stack [ \"taskcat-project-name\" ] ) job = { \"name\" : name , \"project_name\" : stack [ \"taskcat-project-name\" ] , \"test_name\" : stack [ \"taskcat-test-name\" ] , \"taskcat_id\" : stack [ \"taskcat-id\" ] . hex , \"region\" : stack [ \"region\" ] , \"type\" : \"package\" if stack . get ( \"taskcat-installer\" ) else \"test\" , \"stack_id\" : stack [ \"stack-id\" ] , } if _stack_type == job [ \"type\" ] : if package in [ job[\"name\" ] , job [ \"taskcat_id\" ] , \"ALL\" ]: jobs . append ( job ) # TODO : concurrency and wait for complete for job in jobs : client = boto3_cache . client ( \"cloudformation\" , profile = aws_profile , region = job [ \"region\" ] ) Stack . delete ( client = client , stack_id = job [ \"stack_id\" ] )","title":"Delete"},{"location":"reference/taskcat/_cli_modules/deploy.html","text":"Module taskcat._cli_modules.deploy None None View Source # pylint : disable = duplicate - code import logging from io import BytesIO from pathlib import Path from time import sleep from dulwich import porcelain from dulwich . config import ConfigFile , parse_submodules from taskcat . _ cfn . threaded import Stacker from taskcat . _ client_factory import Boto3Cache from taskcat . _ config import Config from taskcat . _ dataclasses import Tag from taskcat . _ name_generator import generate_name from taskcat . _ s3_stage import stage_in_s3 from taskcat . exceptions import TaskCatException LOG = logging . getLogger ( __ name__ ) class Deploy : \"\"\"[ALPHA] installs a stack into an AWS account/region\"\"\" PKG_CACHE_PATH = Path ( \"~/.taskcat_package_cache/\" ). expanduser (). resolve () # pylint : disable = too - many - branches , too - many - locals def __ init__ ( # noqa : C901 self , package : str , aws_profile: str = \"default\" , region= \"default\" , parameters= \"\" , name= \"\" , wait = False , ) : \"\"\" :param package: name of package to install can be a path to a local package, a github org/repo, or an AWS Quick Start name :param aws_profile: aws profile to use for installation :param region: regions to install into, default will use aws cli configured default :param parameters: parameters to pass to the stack, in the format Key=Value,AnotherKey=AnotherValue or providing a path to a json or yaml file containing the parameters :param name: stack name to use, if not specified one will be automatically generated :param wait: if enabled, taskcat will wait for stack to complete before exiting \"\"\" LOG . warning ( \"deploy is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if not name : name = generate_name () if region == \"default\" : region = boto3_cache . get_default_region ( profile_name = aws_profile ) path = Path ( package ). resolve () if Path ( package ). resolve (). is_dir () : package_type = \"local\" elif \"/\" in package : package_type = \"github\" else : # assuming it's an AWS Quick Start package_type = \"github\" package = f\"aws-quickstart/quickstart-{package}\" if package_type == \"github\": if package.startswith(\"https://\") or package.startswith(\"git@\"): url = package org, repo = ( package.replace(\".git\", \"\").replace(\":\", \"/\").split(\"/\")[-2:] ) else: org, repo = package.split(\"/\") url = f\"https://github.com/{org}/{repo}.git\" path = Deploy.PKG_CACHE_PATH / org / repo LOG.info(f\"fetching git repo {url}\") self._git_clone(url, path) self._recurse_submodules(path, url) config = Config.create( args={\"project\": {\"regions\": [region]}}, project_config_path=(path / \".taskcat.yml\"), project_root=path, ) # only use one region for test_name in config.config.tests: config.config.tests[test_name].regions = config.config.project.regions # if there's no test called default , take the 1 st in the list if \"default\" not in config . config . tests : config . config . tests [ \"default\" ] = config . config . tests [ list ( config . config . tests . keys ())[ 0 ] ] # until install offers a way to run different \"plans\" we only need one test for test_name in list ( config . config . tests . keys ()) : if test_name ! = \"default\" : del config . config . tests [ test_name ] buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , path ) regions = config . get_regions ( boto3_cache ) templates = config . get_templates () parameters = config . get_rendered_parameters ( buckets , regions , templates ) tests = config . get_tests ( templates , regions , buckets , parameters ) tags = [ Tag ({ \"Key\" : \"taskcat-installer\" , \"Value\" : name })] stacks = Stacker ( config . config . project . name , tests , tags = tags ) stacks . create_stacks () LOG . error ( f \" {stacks.uid.hex}\" , extra= { \"nametag\" : \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_ID ] \\x1b [ 0 m \"}, ) LOG.error(f\" { name } \", extra={\" nametag \": \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_NAME ] \\x1b [ 0 m \"}) if wait: LOG.info( f\" waiting for stack { stacks . stacks [ 0 ]. name } to complete in \" f\" { stacks . stacks [ 0 ]. region_name } \" ) while stacks.status()[\" IN_PROGRESS \"]: sleep(5) if stacks.status()[\" FAILED \"]: LOG.error(\" Install failed : \") for error in stacks.stacks[0].error_events(): LOG.error(f\" { error . logical_id } : { error . status_reason } \") raise TaskCatException(\" Stack creation failed \") @staticmethod def _git_clone(url, path): outp = BytesIO() if path.exists(): # TODO: handle updating existing repo LOG.warning( \" path already exists , updating from remote is not yet implemented \" ) # shutil.rmtree(path) if not path.exists(): path.mkdir(parents=True) porcelain.clone( url, str(path), checkout=True, errstream=outp, outstream=outp ) LOG.debug(outp.getvalue().decode(\" utf - 8 \")) def _recurse_submodules(self, path: Path, parent_url): gitmodule_path = path / \" . gitmodules \" if not gitmodule_path.is_file(): return conf = ConfigFile.from_path(str(gitmodule_path)) for sub_path, url, name in parse_submodules(conf): sub_path = sub_path.decode(\" utf - 8 \") url = url.decode(\" utf - 8 \") name = name.decode(\" utf - 8 \") if not (path / sub_path).is_dir(): (path / sub_path).mkdir(parents=True) # bizarre process here, but I don't know how else to get the sha for the # submodule... sha = None try: porcelain.get_object_by_path(str(path), sub_path) except KeyError as e: sha = e.args[0].decode(\" utf - 8 \") if not sha: raise ValueError(f\" Could not find sha for submodule { name } \") if url.startswith(\" .. / \"): base_url = parent_url for _ in range(url.count(\" .. / \")): base_url = \" / \".join(base_url.split(\" / \")[:-1]) url = base_url + \" / \" + url.replace(\" .. / \", \"\") outp = BytesIO() if not (path / sub_path / \" . git \").is_dir(): LOG.info(f\" fetching git submodule { url } \") porcelain.clone( url, str(path / sub_path), checkout=sha, errstream=outp, outstream=outp, ) LOG.debug(outp.getvalue().decode(\" utf - 8 \" )) self . _ recurse_submodules (( path / sub_path ), url ) Variables LOG Classes Deploy class Deploy ( package : str , aws_profile : str = 'default' , region = 'default' , parameters = '' , name = '' , wait = False ) View Source class Deploy : \"\"\"[ALPHA] installs a stack into an AWS account/region\"\"\" PKG_CACHE_PATH = Path ( \"~/.taskcat_package_cache/\" ). expanduser (). resolve () # pylint : disable = too - many - branches , too - many - locals def __ init__ ( # noqa : C901 self , package : str , aws_profile: str = \"default\" , region= \"default\" , parameters= \"\" , name= \"\" , wait = False , ) : \"\"\" :param package: name of package to install can be a path to a local package, a github org/repo, or an AWS Quick Start name :param aws_profile: aws profile to use for installation :param region: regions to install into, default will use aws cli configured default :param parameters: parameters to pass to the stack, in the format Key=Value,AnotherKey=AnotherValue or providing a path to a json or yaml file containing the parameters :param name: stack name to use, if not specified one will be automatically generated :param wait: if enabled, taskcat will wait for stack to complete before exiting \"\"\" LOG . warning ( \"deploy is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if not name : name = generate_name () if region == \"default\" : region = boto3_cache . get_default_region ( profile_name = aws_profile ) path = Path ( package ). resolve () if Path ( package ). resolve (). is_dir () : package_type = \"local\" elif \"/\" in package : package_type = \"github\" else : # assuming it's an AWS Quick Start package_type = \"github\" package = f\"aws-quickstart/quickstart-{package}\" if package_type == \"github\": if package.startswith(\"https://\") or package.startswith(\"git@\"): url = package org, repo = ( package.replace(\".git\", \"\").replace(\":\", \"/\").split(\"/\")[-2:] ) else: org, repo = package.split(\"/\") url = f\"https://github.com/{org}/{repo}.git\" path = Deploy.PKG_CACHE_PATH / org / repo LOG.info(f\"fetching git repo {url}\") self._git_clone(url, path) self._recurse_submodules(path, url) config = Config.create( args={\"project\": {\"regions\": [region]}}, project_config_path=(path / \".taskcat.yml\"), project_root=path, ) # only use one region for test_name in config.config.tests: config.config.tests[test_name].regions = config.config.project.regions # if there's no test called default , take the 1 st in the list if \"default\" not in config . config . tests : config . config . tests [ \"default\" ] = config . config . tests [ list ( config . config . tests . keys ())[ 0 ] ] # until install offers a way to run different \"plans\" we only need one test for test_name in list ( config . config . tests . keys ()) : if test_name ! = \"default\" : del config . config . tests [ test_name ] buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , path ) regions = config . get_regions ( boto3_cache ) templates = config . get_templates () parameters = config . get_rendered_parameters ( buckets , regions , templates ) tests = config . get_tests ( templates , regions , buckets , parameters ) tags = [ Tag ({ \"Key\" : \"taskcat-installer\" , \"Value\" : name })] stacks = Stacker ( config . config . project . name , tests , tags = tags ) stacks . create_stacks () LOG . error ( f \" {stacks.uid.hex}\" , extra= { \"nametag\" : \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_ID ] \\x1b [ 0 m \"}, ) LOG.error(f\" { name } \", extra={\" nametag \": \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_NAME ] \\x1b [ 0 m \"}) if wait: LOG.info( f\" waiting for stack { stacks . stacks [ 0 ]. name } to complete in \" f\" { stacks . stacks [ 0 ]. region_name } \" ) while stacks.status()[\" IN_PROGRESS \"]: sleep(5) if stacks.status()[\" FAILED \"]: LOG.error(\" Install failed : \") for error in stacks.stacks[0].error_events(): LOG.error(f\" { error . logical_id } : { error . status_reason } \") raise TaskCatException(\" Stack creation failed \") @staticmethod def _git_clone(url, path): outp = BytesIO() if path.exists(): # TODO: handle updating existing repo LOG.warning( \" path already exists , updating from remote is not yet implemented \" ) # shutil.rmtree(path) if not path.exists(): path.mkdir(parents=True) porcelain.clone( url, str(path), checkout=True, errstream=outp, outstream=outp ) LOG.debug(outp.getvalue().decode(\" utf - 8 \")) def _recurse_submodules(self, path: Path, parent_url): gitmodule_path = path / \" . gitmodules \" if not gitmodule_path.is_file(): return conf = ConfigFile.from_path(str(gitmodule_path)) for sub_path, url, name in parse_submodules(conf): sub_path = sub_path.decode(\" utf - 8 \") url = url.decode(\" utf - 8 \") name = name.decode(\" utf - 8 \") if not (path / sub_path).is_dir(): (path / sub_path).mkdir(parents=True) # bizarre process here, but I don't know how else to get the sha for the # submodule... sha = None try: porcelain.get_object_by_path(str(path), sub_path) except KeyError as e: sha = e.args[0].decode(\" utf - 8 \") if not sha: raise ValueError(f\" Could not find sha for submodule { name } \") if url.startswith(\" .. / \"): base_url = parent_url for _ in range(url.count(\" .. / \")): base_url = \" / \".join(base_url.split(\" / \")[:-1]) url = base_url + \" / \" + url.replace(\" .. / \", \"\") outp = BytesIO() if not (path / sub_path / \" . git \").is_dir(): LOG.info(f\" fetching git submodule { url } \") porcelain.clone( url, str(path / sub_path), checkout=sha, errstream=outp, outstream=outp, ) LOG.debug(outp.getvalue().decode(\" utf - 8 \" )) self . _ recurse_submodules (( path / sub_path ), url ) Class variables PKG_CACHE_PATH","title":"Deploy"},{"location":"reference/taskcat/_cli_modules/deploy.html#module-taskcat_cli_modulesdeploy","text":"None None View Source # pylint : disable = duplicate - code import logging from io import BytesIO from pathlib import Path from time import sleep from dulwich import porcelain from dulwich . config import ConfigFile , parse_submodules from taskcat . _ cfn . threaded import Stacker from taskcat . _ client_factory import Boto3Cache from taskcat . _ config import Config from taskcat . _ dataclasses import Tag from taskcat . _ name_generator import generate_name from taskcat . _ s3_stage import stage_in_s3 from taskcat . exceptions import TaskCatException LOG = logging . getLogger ( __ name__ ) class Deploy : \"\"\"[ALPHA] installs a stack into an AWS account/region\"\"\" PKG_CACHE_PATH = Path ( \"~/.taskcat_package_cache/\" ). expanduser (). resolve () # pylint : disable = too - many - branches , too - many - locals def __ init__ ( # noqa : C901 self , package : str , aws_profile: str = \"default\" , region= \"default\" , parameters= \"\" , name= \"\" , wait = False , ) : \"\"\" :param package: name of package to install can be a path to a local package, a github org/repo, or an AWS Quick Start name :param aws_profile: aws profile to use for installation :param region: regions to install into, default will use aws cli configured default :param parameters: parameters to pass to the stack, in the format Key=Value,AnotherKey=AnotherValue or providing a path to a json or yaml file containing the parameters :param name: stack name to use, if not specified one will be automatically generated :param wait: if enabled, taskcat will wait for stack to complete before exiting \"\"\" LOG . warning ( \"deploy is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if not name : name = generate_name () if region == \"default\" : region = boto3_cache . get_default_region ( profile_name = aws_profile ) path = Path ( package ). resolve () if Path ( package ). resolve (). is_dir () : package_type = \"local\" elif \"/\" in package : package_type = \"github\" else : # assuming it's an AWS Quick Start package_type = \"github\" package = f\"aws-quickstart/quickstart-{package}\" if package_type == \"github\": if package.startswith(\"https://\") or package.startswith(\"git@\"): url = package org, repo = ( package.replace(\".git\", \"\").replace(\":\", \"/\").split(\"/\")[-2:] ) else: org, repo = package.split(\"/\") url = f\"https://github.com/{org}/{repo}.git\" path = Deploy.PKG_CACHE_PATH / org / repo LOG.info(f\"fetching git repo {url}\") self._git_clone(url, path) self._recurse_submodules(path, url) config = Config.create( args={\"project\": {\"regions\": [region]}}, project_config_path=(path / \".taskcat.yml\"), project_root=path, ) # only use one region for test_name in config.config.tests: config.config.tests[test_name].regions = config.config.project.regions # if there's no test called default , take the 1 st in the list if \"default\" not in config . config . tests : config . config . tests [ \"default\" ] = config . config . tests [ list ( config . config . tests . keys ())[ 0 ] ] # until install offers a way to run different \"plans\" we only need one test for test_name in list ( config . config . tests . keys ()) : if test_name ! = \"default\" : del config . config . tests [ test_name ] buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , path ) regions = config . get_regions ( boto3_cache ) templates = config . get_templates () parameters = config . get_rendered_parameters ( buckets , regions , templates ) tests = config . get_tests ( templates , regions , buckets , parameters ) tags = [ Tag ({ \"Key\" : \"taskcat-installer\" , \"Value\" : name })] stacks = Stacker ( config . config . project . name , tests , tags = tags ) stacks . create_stacks () LOG . error ( f \" {stacks.uid.hex}\" , extra= { \"nametag\" : \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_ID ] \\x1b [ 0 m \"}, ) LOG.error(f\" { name } \", extra={\" nametag \": \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_NAME ] \\x1b [ 0 m \"}) if wait: LOG.info( f\" waiting for stack { stacks . stacks [ 0 ]. name } to complete in \" f\" { stacks . stacks [ 0 ]. region_name } \" ) while stacks.status()[\" IN_PROGRESS \"]: sleep(5) if stacks.status()[\" FAILED \"]: LOG.error(\" Install failed : \") for error in stacks.stacks[0].error_events(): LOG.error(f\" { error . logical_id } : { error . status_reason } \") raise TaskCatException(\" Stack creation failed \") @staticmethod def _git_clone(url, path): outp = BytesIO() if path.exists(): # TODO: handle updating existing repo LOG.warning( \" path already exists , updating from remote is not yet implemented \" ) # shutil.rmtree(path) if not path.exists(): path.mkdir(parents=True) porcelain.clone( url, str(path), checkout=True, errstream=outp, outstream=outp ) LOG.debug(outp.getvalue().decode(\" utf - 8 \")) def _recurse_submodules(self, path: Path, parent_url): gitmodule_path = path / \" . gitmodules \" if not gitmodule_path.is_file(): return conf = ConfigFile.from_path(str(gitmodule_path)) for sub_path, url, name in parse_submodules(conf): sub_path = sub_path.decode(\" utf - 8 \") url = url.decode(\" utf - 8 \") name = name.decode(\" utf - 8 \") if not (path / sub_path).is_dir(): (path / sub_path).mkdir(parents=True) # bizarre process here, but I don't know how else to get the sha for the # submodule... sha = None try: porcelain.get_object_by_path(str(path), sub_path) except KeyError as e: sha = e.args[0].decode(\" utf - 8 \") if not sha: raise ValueError(f\" Could not find sha for submodule { name } \") if url.startswith(\" .. / \"): base_url = parent_url for _ in range(url.count(\" .. / \")): base_url = \" / \".join(base_url.split(\" / \")[:-1]) url = base_url + \" / \" + url.replace(\" .. / \", \"\") outp = BytesIO() if not (path / sub_path / \" . git \").is_dir(): LOG.info(f\" fetching git submodule { url } \") porcelain.clone( url, str(path / sub_path), checkout=sha, errstream=outp, outstream=outp, ) LOG.debug(outp.getvalue().decode(\" utf - 8 \" )) self . _ recurse_submodules (( path / sub_path ), url )","title":"Module taskcat._cli_modules.deploy"},{"location":"reference/taskcat/_cli_modules/deploy.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/deploy.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/deploy.html#deploy","text":"class Deploy ( package : str , aws_profile : str = 'default' , region = 'default' , parameters = '' , name = '' , wait = False ) View Source class Deploy : \"\"\"[ALPHA] installs a stack into an AWS account/region\"\"\" PKG_CACHE_PATH = Path ( \"~/.taskcat_package_cache/\" ). expanduser (). resolve () # pylint : disable = too - many - branches , too - many - locals def __ init__ ( # noqa : C901 self , package : str , aws_profile: str = \"default\" , region= \"default\" , parameters= \"\" , name= \"\" , wait = False , ) : \"\"\" :param package: name of package to install can be a path to a local package, a github org/repo, or an AWS Quick Start name :param aws_profile: aws profile to use for installation :param region: regions to install into, default will use aws cli configured default :param parameters: parameters to pass to the stack, in the format Key=Value,AnotherKey=AnotherValue or providing a path to a json or yaml file containing the parameters :param name: stack name to use, if not specified one will be automatically generated :param wait: if enabled, taskcat will wait for stack to complete before exiting \"\"\" LOG . warning ( \"deploy is in alpha feature, use with caution\" ) boto3_cache = Boto3Cache () if not name : name = generate_name () if region == \"default\" : region = boto3_cache . get_default_region ( profile_name = aws_profile ) path = Path ( package ). resolve () if Path ( package ). resolve (). is_dir () : package_type = \"local\" elif \"/\" in package : package_type = \"github\" else : # assuming it's an AWS Quick Start package_type = \"github\" package = f\"aws-quickstart/quickstart-{package}\" if package_type == \"github\": if package.startswith(\"https://\") or package.startswith(\"git@\"): url = package org, repo = ( package.replace(\".git\", \"\").replace(\":\", \"/\").split(\"/\")[-2:] ) else: org, repo = package.split(\"/\") url = f\"https://github.com/{org}/{repo}.git\" path = Deploy.PKG_CACHE_PATH / org / repo LOG.info(f\"fetching git repo {url}\") self._git_clone(url, path) self._recurse_submodules(path, url) config = Config.create( args={\"project\": {\"regions\": [region]}}, project_config_path=(path / \".taskcat.yml\"), project_root=path, ) # only use one region for test_name in config.config.tests: config.config.tests[test_name].regions = config.config.project.regions # if there's no test called default , take the 1 st in the list if \"default\" not in config . config . tests : config . config . tests [ \"default\" ] = config . config . tests [ list ( config . config . tests . keys ())[ 0 ] ] # until install offers a way to run different \"plans\" we only need one test for test_name in list ( config . config . tests . keys ()) : if test_name ! = \"default\" : del config . config . tests [ test_name ] buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , path ) regions = config . get_regions ( boto3_cache ) templates = config . get_templates () parameters = config . get_rendered_parameters ( buckets , regions , templates ) tests = config . get_tests ( templates , regions , buckets , parameters ) tags = [ Tag ({ \"Key\" : \"taskcat-installer\" , \"Value\" : name })] stacks = Stacker ( config . config . project . name , tests , tags = tags ) stacks . create_stacks () LOG . error ( f \" {stacks.uid.hex}\" , extra= { \"nametag\" : \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_ID ] \\x1b [ 0 m \"}, ) LOG.error(f\" { name } \", extra={\" nametag \": \" \\x1b [ 0 ; 30 ; 47 m [ INSTALL_NAME ] \\x1b [ 0 m \"}) if wait: LOG.info( f\" waiting for stack { stacks . stacks [ 0 ]. name } to complete in \" f\" { stacks . stacks [ 0 ]. region_name } \" ) while stacks.status()[\" IN_PROGRESS \"]: sleep(5) if stacks.status()[\" FAILED \"]: LOG.error(\" Install failed : \") for error in stacks.stacks[0].error_events(): LOG.error(f\" { error . logical_id } : { error . status_reason } \") raise TaskCatException(\" Stack creation failed \") @staticmethod def _git_clone(url, path): outp = BytesIO() if path.exists(): # TODO: handle updating existing repo LOG.warning( \" path already exists , updating from remote is not yet implemented \" ) # shutil.rmtree(path) if not path.exists(): path.mkdir(parents=True) porcelain.clone( url, str(path), checkout=True, errstream=outp, outstream=outp ) LOG.debug(outp.getvalue().decode(\" utf - 8 \")) def _recurse_submodules(self, path: Path, parent_url): gitmodule_path = path / \" . gitmodules \" if not gitmodule_path.is_file(): return conf = ConfigFile.from_path(str(gitmodule_path)) for sub_path, url, name in parse_submodules(conf): sub_path = sub_path.decode(\" utf - 8 \") url = url.decode(\" utf - 8 \") name = name.decode(\" utf - 8 \") if not (path / sub_path).is_dir(): (path / sub_path).mkdir(parents=True) # bizarre process here, but I don't know how else to get the sha for the # submodule... sha = None try: porcelain.get_object_by_path(str(path), sub_path) except KeyError as e: sha = e.args[0].decode(\" utf - 8 \") if not sha: raise ValueError(f\" Could not find sha for submodule { name } \") if url.startswith(\" .. / \"): base_url = parent_url for _ in range(url.count(\" .. / \")): base_url = \" / \".join(base_url.split(\" / \")[:-1]) url = base_url + \" / \" + url.replace(\" .. / \", \"\") outp = BytesIO() if not (path / sub_path / \" . git \").is_dir(): LOG.info(f\" fetching git submodule { url } \") porcelain.clone( url, str(path / sub_path), checkout=sha, errstream=outp, outstream=outp, ) LOG.debug(outp.getvalue().decode(\" utf - 8 \" )) self . _ recurse_submodules (( path / sub_path ), url )","title":"Deploy"},{"location":"reference/taskcat/_cli_modules/deploy.html#class-variables","text":"PKG_CACHE_PATH","title":"Class variables"},{"location":"reference/taskcat/_cli_modules/lint.html","text":"Module taskcat._cli_modules.lint None None View Source import logging from pathlib import Path from taskcat._cfn_lint import Lint as TaskCatLint from taskcat._config import Config from taskcat.exceptions import TaskCatException LOG = logging . getLogger ( __name__ ) class Lint : \"\"\"checks CloudFormation templates for issues using cfn-python-lint\"\"\" def __init__ ( self , input_file : str = \".taskcat.yml\" , project_root : str = \"./\" , strict : bool = False , ): \"\"\" :param input_file: path to project config or CloudFormation template :param project_root: base path for project :param strict: fail on lint warnings as well as errors \"\"\" project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / input_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) templates = config . get_templates () lint = TaskCatLint ( config , templates , strict ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed : raise TaskCatException ( \"Lint failed with errors\" ) Variables LOG Classes Lint class Lint ( input_file : str = '.taskcat.yml' , project_root : str = './' , strict : bool = False ) View Source class Lint: \"\"\"checks CloudFormation templates for issues using cfn-python-lint\"\"\" def __init__ ( self , input_file: str = \".taskcat.yml\" , project_root: str = \"./\" , strict: bool = False , ): \"\"\" :param input_file: path to project config or CloudFormation template :param project_root: base path for project :param strict: fail on lint warnings as well as errors \"\"\" project_root_path: Path = Path ( project_root ). expanduser (). resolve () input_file_path: Path = project_root_path / input_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) templates = config . get_templates () lint = TaskCatLint ( config , templates , strict ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed: raise TaskCatException ( \"Lint failed with errors\" )","title":"Lint"},{"location":"reference/taskcat/_cli_modules/lint.html#module-taskcat_cli_moduleslint","text":"None None View Source import logging from pathlib import Path from taskcat._cfn_lint import Lint as TaskCatLint from taskcat._config import Config from taskcat.exceptions import TaskCatException LOG = logging . getLogger ( __name__ ) class Lint : \"\"\"checks CloudFormation templates for issues using cfn-python-lint\"\"\" def __init__ ( self , input_file : str = \".taskcat.yml\" , project_root : str = \"./\" , strict : bool = False , ): \"\"\" :param input_file: path to project config or CloudFormation template :param project_root: base path for project :param strict: fail on lint warnings as well as errors \"\"\" project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / input_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) templates = config . get_templates () lint = TaskCatLint ( config , templates , strict ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed : raise TaskCatException ( \"Lint failed with errors\" )","title":"Module taskcat._cli_modules.lint"},{"location":"reference/taskcat/_cli_modules/lint.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/lint.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/lint.html#lint","text":"class Lint ( input_file : str = '.taskcat.yml' , project_root : str = './' , strict : bool = False ) View Source class Lint: \"\"\"checks CloudFormation templates for issues using cfn-python-lint\"\"\" def __init__ ( self , input_file: str = \".taskcat.yml\" , project_root: str = \"./\" , strict: bool = False , ): \"\"\" :param input_file: path to project config or CloudFormation template :param project_root: base path for project :param strict: fail on lint warnings as well as errors \"\"\" project_root_path: Path = Path ( project_root ). expanduser (). resolve () input_file_path: Path = project_root_path / input_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) templates = config . get_templates () lint = TaskCatLint ( config , templates , strict ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed: raise TaskCatException ( \"Lint failed with errors\" )","title":"Lint"},{"location":"reference/taskcat/_cli_modules/list.html","text":"Module taskcat._cli_modules.list None None View Source # pylint: disable=duplicate-code import logging from typing import List as ListType , Union import boto3 from taskcat._cfn.threaded import Stacker LOG = logging . getLogger ( __name__ ) class List : \"\"\"[ALPHA] lists taskcat jobs with active stacks\"\"\" # pylint: disable=too-many-locals,too-many-branches def __init__ ( # noqa: C901 self , profiles : Union [ str , ListType [ str ]] = \"default\" , regions = \"ALL\" , _stack_type = \"package\" , ): \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" LOG . warning ( \"list is in alpha feature, use with caution\" ) if isinstance ( profiles , str ): profiles = profiles . split ( \",\" ) if regions == \"ALL\" : region_set : set = set () for profile in profiles : region_set = region_set . union ( set ( boto3 . Session ( profile_name = profile ) . get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = regions . split ( \",\" ) stacks = Stacker . list_stacks ( profiles , regions ) jobs : dict = {} for stack in stacks : stack_key = stack [ \"taskcat-id\" ] . hex + \"-\" + stack [ \"region\" ] if stack_key not in jobs : name = stack . get ( \"taskcat-installer\" ) if _stack_type == \"test\" and not name : name = stack [ \"taskcat-project-name\" ] jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ], \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ], } elif name and _stack_type == \"package\" : jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ], \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ], } else : jobs [ stack_key ][ \"active_stacks\" ] += 1 def longest ( things : list ): lengths = [ len ( thing ) for thing in things ] return sorted ( lengths )[ - 1 ] if lengths else 0 def spaces ( number ): ret = \"\" for _ in range ( number ): ret += \" \" return ret def pad ( string , length ): while len ( string ) < length : string += \" \" return string longest_name = longest ([ v [ \"name\" ] for _ , v in jobs . items ()]) longest_project_name = longest ([ v [ \"project_name\" ] for _ , v in jobs . items ()]) if not jobs : LOG . info ( \"no stacks found\" ) return if _stack_type != \"test\" : header = ( f \"NAME { spaces ( longest_name ) } PROJECT { spaces ( longest_project_name ) } \" f \"ID { spaces ( 34 ) } REGION\" ) column = \" {} {} {} {} \" else : header = f \"NAME { spaces ( longest_name ) } ID { spaces ( 34 ) } REGION\" column = \" {} {} {} \" LOG . error ( header , extra = { \"nametag\" : \"\" }) for job in jobs . values (): args = [ pad ( job [ \"name\" ], longest_name ), pad ( job [ \"project_name\" ], longest_project_name ), job [ \"id\" ], job [ \"region\" ], ] if _stack_type == \"test\" : args = [ pad ( job [ \"name\" ], longest_name ), job [ \"id\" ], job [ \"region\" ]] LOG . error ( column . format ( * args ), extra = { \"nametag\" : \"\" }) Variables LOG Classes List class List ( profiles : Union [ str , List [ str ]] = 'default' , regions = 'ALL' , _stack_type = 'package' ) View Source class List : \"\"\"[ALPHA] lists taskcat jobs with active stacks\"\"\" # pylint : disable = too - many - locals , too - many - branches def __init__ ( # noqa : C901 self , profiles : Union [ str, ListType[str ] ] = \"default\" , regions = \"ALL\" , _stack_type = \"package\" , ) : \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" LOG . warning ( \"list is in alpha feature, use with caution\" ) if isinstance ( profiles , str ) : profiles = profiles . split ( \",\" ) if regions == \"ALL\" : region_set : set = set () for profile in profiles : region_set = region_set . union ( set ( boto3 . Session ( profile_name = profile ). get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = regions . split ( \",\" ) stacks = Stacker . list_stacks ( profiles , regions ) jobs : dict = {} for stack in stacks : stack_key = stack [ \"taskcat-id\" ] . hex + \"-\" + stack [ \"region\" ] if stack_key not in jobs : name = stack . get ( \"taskcat-installer\" ) if _stack_type == \"test\" and not name : name = stack [ \"taskcat-project-name\" ] jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ] , \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ] , } elif name and _stack_type == \"package\" : jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ] , \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ] , } else : jobs [ stack_key ][ \"active_stacks\" ] += 1 def longest ( things : list ) : lengths = [ len(thing) for thing in things ] return sorted ( lengths ) [ -1 ] if lengths else 0 def spaces ( number ) : ret = \"\" for _ in range ( number ) : ret += \" \" return ret def pad ( string , length ) : while len ( string ) < length : string += \" \" return string longest_name = longest ( [ v[\"name\" ] for _ , v in jobs . items () ] ) longest_project_name = longest ( [ v[\"project_name\" ] for _ , v in jobs . items () ] ) if not jobs : LOG . info ( \"no stacks found\" ) return if _stack_type != \"test\" : header = ( f \"NAME{spaces(longest_name)}PROJECT{spaces(longest_project_name)}\" f \"ID{spaces(34)}REGION\" ) column = \"{} {} {} {}\" else : header = f \"NAME{spaces(longest_name)}ID{spaces(34)}REGION\" column = \"{} {} {}\" LOG . error ( header , extra = { \"nametag\" : \"\" } ) for job in jobs . values () : args = [ pad(job[\"name\" ] , longest_name ), pad ( job [ \"project_name\" ] , longest_project_name ), job [ \"id\" ] , job [ \"region\" ] , ] if _stack_type == \"test\" : args = [ pad(job[\"name\" ] , longest_name ), job [ \"id\" ] , job [ \"region\" ] ] LOG . error ( column . format ( * args ), extra = { \"nametag\" : \"\" } )","title":"List"},{"location":"reference/taskcat/_cli_modules/list.html#module-taskcat_cli_moduleslist","text":"None None View Source # pylint: disable=duplicate-code import logging from typing import List as ListType , Union import boto3 from taskcat._cfn.threaded import Stacker LOG = logging . getLogger ( __name__ ) class List : \"\"\"[ALPHA] lists taskcat jobs with active stacks\"\"\" # pylint: disable=too-many-locals,too-many-branches def __init__ ( # noqa: C901 self , profiles : Union [ str , ListType [ str ]] = \"default\" , regions = \"ALL\" , _stack_type = \"package\" , ): \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" LOG . warning ( \"list is in alpha feature, use with caution\" ) if isinstance ( profiles , str ): profiles = profiles . split ( \",\" ) if regions == \"ALL\" : region_set : set = set () for profile in profiles : region_set = region_set . union ( set ( boto3 . Session ( profile_name = profile ) . get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = regions . split ( \",\" ) stacks = Stacker . list_stacks ( profiles , regions ) jobs : dict = {} for stack in stacks : stack_key = stack [ \"taskcat-id\" ] . hex + \"-\" + stack [ \"region\" ] if stack_key not in jobs : name = stack . get ( \"taskcat-installer\" ) if _stack_type == \"test\" and not name : name = stack [ \"taskcat-project-name\" ] jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ], \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ], } elif name and _stack_type == \"package\" : jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ], \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ], } else : jobs [ stack_key ][ \"active_stacks\" ] += 1 def longest ( things : list ): lengths = [ len ( thing ) for thing in things ] return sorted ( lengths )[ - 1 ] if lengths else 0 def spaces ( number ): ret = \"\" for _ in range ( number ): ret += \" \" return ret def pad ( string , length ): while len ( string ) < length : string += \" \" return string longest_name = longest ([ v [ \"name\" ] for _ , v in jobs . items ()]) longest_project_name = longest ([ v [ \"project_name\" ] for _ , v in jobs . items ()]) if not jobs : LOG . info ( \"no stacks found\" ) return if _stack_type != \"test\" : header = ( f \"NAME { spaces ( longest_name ) } PROJECT { spaces ( longest_project_name ) } \" f \"ID { spaces ( 34 ) } REGION\" ) column = \" {} {} {} {} \" else : header = f \"NAME { spaces ( longest_name ) } ID { spaces ( 34 ) } REGION\" column = \" {} {} {} \" LOG . error ( header , extra = { \"nametag\" : \"\" }) for job in jobs . values (): args = [ pad ( job [ \"name\" ], longest_name ), pad ( job [ \"project_name\" ], longest_project_name ), job [ \"id\" ], job [ \"region\" ], ] if _stack_type == \"test\" : args = [ pad ( job [ \"name\" ], longest_name ), job [ \"id\" ], job [ \"region\" ]] LOG . error ( column . format ( * args ), extra = { \"nametag\" : \"\" })","title":"Module taskcat._cli_modules.list"},{"location":"reference/taskcat/_cli_modules/list.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/list.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/list.html#list","text":"class List ( profiles : Union [ str , List [ str ]] = 'default' , regions = 'ALL' , _stack_type = 'package' ) View Source class List : \"\"\"[ALPHA] lists taskcat jobs with active stacks\"\"\" # pylint : disable = too - many - locals , too - many - branches def __init__ ( # noqa : C901 self , profiles : Union [ str, ListType[str ] ] = \"default\" , regions = \"ALL\" , _stack_type = \"package\" , ) : \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" LOG . warning ( \"list is in alpha feature, use with caution\" ) if isinstance ( profiles , str ) : profiles = profiles . split ( \",\" ) if regions == \"ALL\" : region_set : set = set () for profile in profiles : region_set = region_set . union ( set ( boto3 . Session ( profile_name = profile ). get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = regions . split ( \",\" ) stacks = Stacker . list_stacks ( profiles , regions ) jobs : dict = {} for stack in stacks : stack_key = stack [ \"taskcat-id\" ] . hex + \"-\" + stack [ \"region\" ] if stack_key not in jobs : name = stack . get ( \"taskcat-installer\" ) if _stack_type == \"test\" and not name : name = stack [ \"taskcat-project-name\" ] jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ] , \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ] , } elif name and _stack_type == \"package\" : jobs [ stack_key ] = { \"name\" : name , \"id\" : stack [ \"taskcat-id\" ] . hex , \"project_name\" : stack [ \"taskcat-project-name\" ] , \"active_stacks\" : 1 , \"region\" : stack [ \"region\" ] , } else : jobs [ stack_key ][ \"active_stacks\" ] += 1 def longest ( things : list ) : lengths = [ len(thing) for thing in things ] return sorted ( lengths ) [ -1 ] if lengths else 0 def spaces ( number ) : ret = \"\" for _ in range ( number ) : ret += \" \" return ret def pad ( string , length ) : while len ( string ) < length : string += \" \" return string longest_name = longest ( [ v[\"name\" ] for _ , v in jobs . items () ] ) longest_project_name = longest ( [ v[\"project_name\" ] for _ , v in jobs . items () ] ) if not jobs : LOG . info ( \"no stacks found\" ) return if _stack_type != \"test\" : header = ( f \"NAME{spaces(longest_name)}PROJECT{spaces(longest_project_name)}\" f \"ID{spaces(34)}REGION\" ) column = \"{} {} {} {}\" else : header = f \"NAME{spaces(longest_name)}ID{spaces(34)}REGION\" column = \"{} {} {}\" LOG . error ( header , extra = { \"nametag\" : \"\" } ) for job in jobs . values () : args = [ pad(job[\"name\" ] , longest_name ), pad ( job [ \"project_name\" ] , longest_project_name ), job [ \"id\" ] , job [ \"region\" ] , ] if _stack_type == \"test\" : args = [ pad(job[\"name\" ] , longest_name ), job [ \"id\" ] , job [ \"region\" ] ] LOG . error ( column . format ( * args ), extra = { \"nametag\" : \"\" } )","title":"List"},{"location":"reference/taskcat/_cli_modules/package.html","text":"Module taskcat._cli_modules.package None None View Source import logging from pathlib import Path from taskcat._config import Config from taskcat._lambda_build import LambdaBuild LOG = logging . getLogger ( __name__ ) class Package : \"\"\"packages lambda source files into zip files. If a dockerfile is present in a source folder, it will be run prior to zipping the contents\"\"\" def __init__ ( self , project_root : str = \"./\" , source_folder : str = \"lambda_functions/source\" , zip_folder : str = \"lambda_functions/packages\" , config_file : str = \".taskcat.yml\" , ): \"\"\" :param project_root: base path for project :param source_folder: folder containing the lambda source files, relative to the project_root :param zip_folder: folder to output zip files, relative to the project root :param config_file: path to taskcat project config file \"\"\" project_root_path : Path = Path ( project_root ) . expanduser () . resolve () project_config : Path = project_root_path / config_file config = Config . create ( project_config_path = project_config , project_root = project_root_path , args = { \"project\" : { \"lambda_zip_path\" : zip_folder , \"lambda_source_path\" : source_folder , } }, ) if not config . config . project . package_lambda : LOG . info ( \"Lambda packaging disabled by config\" ) return LambdaBuild ( config , project_root_path ) Variables LOG Classes Package class Package ( project_root : str = './' , source_folder : str = 'lambda_functions/source' , zip_folder : str = 'lambda_functions/packages' , config_file : str = '.taskcat.yml' ) View Source class Package: \"\"\"packages lambda source files into zip files. If a dockerfile is present in a source folder, it will be run prior to zipping the contents\"\"\" def __init__ ( self , project_root: str = \"./\" , source_folder: str = \"lambda_functions/source\" , zip_folder: str = \"lambda_functions/packages\" , config_file: str = \".taskcat.yml\" , ): \"\"\" :param project_root: base path for project :param source_folder: folder containing the lambda source files, relative to the project_root :param zip_folder: folder to output zip files, relative to the project root :param config_file: path to taskcat project config file \"\"\" project_root_path: Path = Path ( project_root ). expanduser (). resolve () project_config: Path = project_root_path / config_file config = Config . create ( project_config_path = project_config , project_root = project_root_path , args ={ \"project\" : { \"lambda_zip_path\" : zip_folder , \"lambda_source_path\" : source_folder , } }, ) if not config . config . project . package_lambda: LOG . info ( \"Lambda packaging disabled by config\" ) return LambdaBuild ( config , project_root_path )","title":"Package"},{"location":"reference/taskcat/_cli_modules/package.html#module-taskcat_cli_modulespackage","text":"None None View Source import logging from pathlib import Path from taskcat._config import Config from taskcat._lambda_build import LambdaBuild LOG = logging . getLogger ( __name__ ) class Package : \"\"\"packages lambda source files into zip files. If a dockerfile is present in a source folder, it will be run prior to zipping the contents\"\"\" def __init__ ( self , project_root : str = \"./\" , source_folder : str = \"lambda_functions/source\" , zip_folder : str = \"lambda_functions/packages\" , config_file : str = \".taskcat.yml\" , ): \"\"\" :param project_root: base path for project :param source_folder: folder containing the lambda source files, relative to the project_root :param zip_folder: folder to output zip files, relative to the project root :param config_file: path to taskcat project config file \"\"\" project_root_path : Path = Path ( project_root ) . expanduser () . resolve () project_config : Path = project_root_path / config_file config = Config . create ( project_config_path = project_config , project_root = project_root_path , args = { \"project\" : { \"lambda_zip_path\" : zip_folder , \"lambda_source_path\" : source_folder , } }, ) if not config . config . project . package_lambda : LOG . info ( \"Lambda packaging disabled by config\" ) return LambdaBuild ( config , project_root_path )","title":"Module taskcat._cli_modules.package"},{"location":"reference/taskcat/_cli_modules/package.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/package.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/package.html#package","text":"class Package ( project_root : str = './' , source_folder : str = 'lambda_functions/source' , zip_folder : str = 'lambda_functions/packages' , config_file : str = '.taskcat.yml' ) View Source class Package: \"\"\"packages lambda source files into zip files. If a dockerfile is present in a source folder, it will be run prior to zipping the contents\"\"\" def __init__ ( self , project_root: str = \"./\" , source_folder: str = \"lambda_functions/source\" , zip_folder: str = \"lambda_functions/packages\" , config_file: str = \".taskcat.yml\" , ): \"\"\" :param project_root: base path for project :param source_folder: folder containing the lambda source files, relative to the project_root :param zip_folder: folder to output zip files, relative to the project root :param config_file: path to taskcat project config file \"\"\" project_root_path: Path = Path ( project_root ). expanduser (). resolve () project_config: Path = project_root_path / config_file config = Config . create ( project_config_path = project_config , project_root = project_root_path , args ={ \"project\" : { \"lambda_zip_path\" : zip_folder , \"lambda_source_path\" : source_folder , } }, ) if not config . config . project . package_lambda: LOG . info ( \"Lambda packaging disabled by config\" ) return LambdaBuild ( config , project_root_path )","title":"Package"},{"location":"reference/taskcat/_cli_modules/test.html","text":"Module taskcat._cli_modules.test None None View Source # pylint: disable=duplicate-code # noqa: B950,F841 import inspect import logging from pathlib import Path import boto3 import yaml from taskcat._common_utils import determine_profile_for_region from taskcat._config import Config from taskcat._tui import TerminalPrinter from taskcat.testing import CFNTest from .delete import Delete from .list import List LOG = logging . getLogger ( __name__ ) class Test : \"\"\" Performs functional tests on CloudFormation templates. \"\"\" # pylint: disable=too-many-locals @staticmethod def retry ( region : str , stack_name : str , resource_name : str , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False , ): \"\"\"[ALPHA] re-launches a child stack using the same parameters as previous launch :param region: region stack is in :param stack_name: name of parent stack :param resource_name: logical id of child stack that will be re-launched :param config_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param keep_failed: do not delete failed stacks :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete \"\"\" LOG . warning ( \"test retry is in alpha feature, use with caution\" ) project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / config_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) profile = determine_profile_for_region ( config . config . general . auth , region ) cfn = boto3 . Session ( profile_name = profile ) . client ( \"cloudformation\" , region_name = region ) events = cfn . describe_stack_events ( StackName = stack_name )[ \"StackEvents\" ] resource = [ i for i in events if i [ \"LogicalResourceId\" ] == resource_name ][ 0 ] properties = yaml . safe_load ( resource [ \"ResourceProperties\" ]) with open ( str ( input_file_path ), \"r\" ) as filepointer : config_yaml = yaml . safe_load ( filepointer ) config_yaml [ \"project\" ][ \"regions\" ] = [ region ] config_yaml [ \"project\" ][ \"parameters\" ] = properties [ \"Parameters\" ] config_yaml [ \"project\" ][ \"template\" ] = \"/\" . join ( properties [ \"TemplateURL\" ] . split ( \"/\" )[ 4 :] ) config_yaml [ \"tests\" ] = { \"default\" : {}} with open ( \"/tmp/.taskcat.yml.temp\" , \"w\" ) as filepointer : # nosec yaml . safe_dump ( config_yaml , filepointer ) if resource [ \"PhysicalResourceId\" ]: cfn . delete_stack ( StackName = resource [ \"PhysicalResourceId\" ]) LOG . info ( \"waiting for old stack to delete...\" ) cfn . get_waiter ( \"stack_delete_complete\" ) . wait ( StackName = resource [ \"PhysicalResourceId\" ] ) Test . run ( input_file = \"/tmp/.taskcat.yml.temp\" , # nosec project_root = project_root , lint_disable = True , no_delete = no_delete , keep_failed = keep_failed , minimal_output = minimal_output , dont_wait_for_delete = dont_wait_for_delete , ) @staticmethod # pylint: disable=too-many-arguments,W0613,line-too-long def run ( # noqa: C901 test_names : str = \"ALL\" , regions : str = \"ALL\" , input_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = \"./taskcat_outputs\" , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False , ): \"\"\"tests whether CloudFormation templates are able to successfully launch :param test_names: comma separated list of tests to run :param regions: comma separated list of regions to test in :param input_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param lint_disable: disable cfn-lint checks :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param keep_failed: do not delete failed stacks :param output_directory: Where to store generated logfiles :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete :param skip_upload: Use templates in an existing cloudformation bucket. \"\"\" # noqa: B950 test = CFNTest . from_file ( project_root = project_root , input_file = input_file , regions = regions , enable_sig_v2 = enable_sig_v2 , ) # This code is temporary and should be removed once its easier # to create a config object frame = inspect . currentframe () if frame is not None : args , _ , _ , values = inspect . getargvalues ( frame ) for i in args : if hasattr ( test , i ): setattr ( test , i , values [ i ]) terminal_printer = TerminalPrinter ( minimalist = minimal_output ) test . printer = terminal_printer with test : test . report ( output_directory ) def resume ( self , run_id ): # pylint: disable=no-self-use \"\"\"resumes a monitoring of a previously started test run\"\"\" # do some stuff raise NotImplementedError () @staticmethod def list ( profiles : str = \"default\" , regions = \"ALL\" , _stack_type = \"package\" ): \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" List ( profiles = profiles , regions = regions , _stack_type = \"test\" ) @staticmethod def clean ( project : str , aws_profile : str = \"default\" , region = \"ALL\" ): \"\"\" :param project: project to delete, can be an name or uuid, or ALL to clean all tests :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will scan all regions \"\"\" if region == \"ALL\" : region_set : set = set () region_set = region_set . union ( # pylint: disable=duplicate-code set ( boto3 . Session ( profile_name = aws_profile ) . get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = [ region ] Delete ( package = project , aws_profile = aws_profile , region = regions , _stack_type = \"test\" ) Variables LOG Classes Test class Test ( / , * args , ** kwargs ) View Source class Test : \"\"\" Performs functional tests on CloudFormation templates. \"\"\" # pylint : disable = too - many - locals @staticmethod def retry ( region : str , stack_name : str , resource_name : str , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False , ) : \"\"\"[ALPHA] re-launches a child stack using the same parameters as previous launch :param region: region stack is in :param stack_name: name of parent stack :param resource_name: logical id of child stack that will be re-launched :param config_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param keep_failed: do not delete failed stacks :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete \"\"\" LOG . warning ( \"test retry is in alpha feature, use with caution\" ) project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / config_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) profile = determine_profile_for_region ( config . config . general . auth , region ) cfn = boto3 . Session ( profile_name = profile ). client ( \"cloudformation\" , region_name = region ) events = cfn . describe_stack_events ( StackName = stack_name ) [ \"StackEvents\" ] resource = [ i for i in events if i[\"LogicalResourceId\" ] == resource_name ] [ 0 ] properties = yaml . safe_load ( resource [ \"ResourceProperties\" ] ) with open ( str ( input_file_path ), \"r\" ) as filepointer : config_yaml = yaml . safe_load ( filepointer ) config_yaml [ \"project\" ][ \"regions\" ] = [ region ] config_yaml [ \"project\" ][ \"parameters\" ] = properties [ \"Parameters\" ] config_yaml [ \"project\" ][ \"template\" ] = \"/\" . join ( properties [ \"TemplateURL\" ] . split ( \"/\" ) [ 4: ] ) config_yaml [ \"tests\" ] = { \"default\" : {}} with open ( \"/tmp/.taskcat.yml.temp\" , \"w\" ) as filepointer : # nosec yaml . safe_dump ( config_yaml , filepointer ) if resource [ \"PhysicalResourceId\" ] : cfn . delete_stack ( StackName = resource [ \"PhysicalResourceId\" ] ) LOG . info ( \"waiting for old stack to delete...\" ) cfn . get_waiter ( \"stack_delete_complete\" ). wait ( StackName = resource [ \"PhysicalResourceId\" ] ) Test . run ( input_file = \"/tmp/.taskcat.yml.temp\" , # nosec project_root = project_root , lint_disable = True , no_delete = no_delete , keep_failed = keep_failed , minimal_output = minimal_output , dont_wait_for_delete = dont_wait_for_delete , ) @staticmethod # pylint : disable = too - many - arguments , W0613 , line - too - long def run ( # noqa : C901 test_names : str = \"ALL\" , regions : str = \"ALL\" , input_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = \"./taskcat_outputs\" , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False , ) : \"\"\"tests whether CloudFormation templates are able to successfully launch :param test_names: comma separated list of tests to run :param regions: comma separated list of regions to test in :param input_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param lint_disable: disable cfn-lint checks :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param keep_failed: do not delete failed stacks :param output_directory: Where to store generated logfiles :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete :param skip_upload: Use templates in an existing cloudformation bucket. \"\"\" # noqa : B950 test = CFNTest . from_file ( project_root = project_root , input_file = input_file , regions = regions , enable_sig_v2 = enable_sig_v2 , ) # This code is temporary and should be removed once its easier # to create a config object frame = inspect . currentframe () if frame is not None : args , _ , _ , values = inspect . getargvalues ( frame ) for i in args : if hasattr ( test , i ) : setattr ( test , i , values [ i ] ) terminal_printer = TerminalPrinter ( minimalist = minimal_output ) test . printer = terminal_printer with test : test . report ( output_directory ) def resume ( self , run_id ) : # pylint : disable = no - self - use \"\"\"resumes a monitoring of a previously started test run\"\"\" # do some stuff raise NotImplementedError () @staticmethod def list ( profiles : str = \"default\" , regions = \"ALL\" , _stack_type = \"package\" ) : \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" List ( profiles = profiles , regions = regions , _stack_type = \"test\" ) @staticmethod def clean ( project : str , aws_profile : str = \"default\" , region = \"ALL\" ) : \"\"\" :param project: project to delete, can be an name or uuid, or ALL to clean all tests :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will scan all regions \"\"\" if region == \"ALL\" : region_set : set = set () region_set = region_set . union ( # pylint : disable = duplicate - code set ( boto3 . Session ( profile_name = aws_profile ). get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = [ region ] Delete ( package = project , aws_profile = aws_profile , region = regions , _stack_type = \"test\" ) Static methods clean def clean ( project : str , aws_profile : str = 'default' , region = 'ALL' ) Parameters: Name Type Description Default project None project to delete, can be an name or uuid, or ALL to clean all tests None aws_profile None aws profile to use for deletion None region None region to delete from, default will scan all regions None View Source @staticmethod def clean ( project : str , aws_profile : str = \"default\" , region = \"ALL\" ) : \"\"\" :param project: project to delete, can be an name or uuid, or ALL to clean all tests :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will scan all regions \"\"\" if region == \"ALL\" : region_set : set = set () region_set = region_set . union ( # pylint : disable = duplicate - code set ( boto3 . Session ( profile_name = aws_profile ). get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = [ region ] Delete ( package = project , aws_profile = aws_profile , region = regions , _stack_type = \"test\" ) list def list ( profiles : str = 'default' , regions = 'ALL' , _stack_type = 'package' ) Parameters: Name Type Description Default profiles None comma separated list of aws profiles to search None regions None comma separated list of regions to search, default is to check all commercial regions None View Source @staticmethod def list ( profiles : str = \"default\" , regions = \"ALL\" , _stack_type = \"package\" ) : \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" List ( profiles = profiles , regions = regions , _stack_type = \"test\" ) retry def retry ( region : str , stack_name : str , resource_name : str , config_file : str = './.taskcat.yml' , project_root : str = './' , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False ) [ALPHA] re-launches a child stack using the same parameters as previous launch Parameters: Name Type Description Default region None region stack is in None stack_name None name of parent stack None resource_name None logical id of child stack that will be re-launched None config_file None path to either a taskat project config file or a CloudFormation template None project_root None root path of the project relative to input_file None no_delete None don't delete stacks after test is complete None keep_failed None do not delete failed stacks None minimal_output None Reduces output during test runs None dont_wait_for_delete None Exits immediately after calling stack_delete None View Source @staticmethod def retry ( region : str , stack_name : str , resource_name : str , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False , ) : \"\"\"[ALPHA] re-launches a child stack using the same parameters as previous launch :param region: region stack is in :param stack_name: name of parent stack :param resource_name: logical id of child stack that will be re-launched :param config_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param keep_failed: do not delete failed stacks :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete \"\"\" LOG . warning ( \"test retry is in alpha feature, use with caution\" ) project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / config_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) profile = determine_profile_for_region ( config . config . general . auth , region ) cfn = boto3 . Session ( profile_name = profile ). client ( \"cloudformation\" , region_name = region ) events = cfn . describe_stack_events ( StackName = stack_name ) [ \"StackEvents\" ] resource = [ i for i in events if i[\"LogicalResourceId\" ] == resource_name ] [ 0 ] properties = yaml . safe_load ( resource [ \"ResourceProperties\" ] ) with open ( str ( input_file_path ), \"r\" ) as filepointer : config_yaml = yaml . safe_load ( filepointer ) config_yaml [ \"project\" ][ \"regions\" ] = [ region ] config_yaml [ \"project\" ][ \"parameters\" ] = properties [ \"Parameters\" ] config_yaml [ \"project\" ][ \"template\" ] = \"/\" . join ( properties [ \"TemplateURL\" ] . split ( \"/\" ) [ 4: ] ) config_yaml [ \"tests\" ] = { \"default\" : {}} with open ( \"/tmp/.taskcat.yml.temp\" , \"w\" ) as filepointer : # nosec yaml . safe_dump ( config_yaml , filepointer ) if resource [ \"PhysicalResourceId\" ] : cfn . delete_stack ( StackName = resource [ \"PhysicalResourceId\" ] ) LOG . info ( \"waiting for old stack to delete...\" ) cfn . get_waiter ( \"stack_delete_complete\" ). wait ( StackName = resource [ \"PhysicalResourceId\" ] ) Test . run ( input_file = \"/tmp/.taskcat.yml.temp\" , # nosec project_root = project_root , lint_disable = True , no_delete = no_delete , keep_failed = keep_failed , minimal_output = minimal_output , dont_wait_for_delete = dont_wait_for_delete , ) run def run ( test_names : str = 'ALL' , regions : str = 'ALL' , input_file : str = './.taskcat.yml' , project_root : str = './' , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = './taskcat_outputs' , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False ) tests whether CloudFormation templates are able to successfully launch Parameters: Name Type Description Default test_names None comma separated list of tests to run None regions None comma separated list of regions to test in None input_file None path to either a taskat project config file or a CloudFormation template None project_root None root path of the project relative to input_file None no_delete None don't delete stacks after test is complete None lint_disable None disable cfn-lint checks None enable_sig_v2 None enable legacy sigv2 requests for auto-created buckets None keep_failed None do not delete failed stacks None output_directory None Where to store generated logfiles None minimal_output None Reduces output during test runs None dont_wait_for_delete None Exits immediately after calling stack_delete None skip_upload None Use templates in an existing cloudformation bucket. None View Source @staticmethod # pylint : disable = too - many - arguments , W0613 , line - too - long def run ( # noqa : C901 test_names : str = \"ALL\" , regions : str = \"ALL\" , input_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = \"./taskcat_outputs\" , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False , ) : \"\"\"tests whether CloudFormation templates are able to successfully launch :param test_names: comma separated list of tests to run :param regions: comma separated list of regions to test in :param input_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param lint_disable: disable cfn-lint checks :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param keep_failed: do not delete failed stacks :param output_directory: Where to store generated logfiles :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete :param skip_upload: Use templates in an existing cloudformation bucket. \"\"\" # noqa : B950 test = CFNTest . from_file ( project_root = project_root , input_file = input_file , regions = regions , enable_sig_v2 = enable_sig_v2 , ) # This code is temporary and should be removed once its easier # to create a config object frame = inspect . currentframe () if frame is not None : args , _ , _ , values = inspect . getargvalues ( frame ) for i in args : if hasattr ( test , i ) : setattr ( test , i , values [ i ] ) terminal_printer = TerminalPrinter ( minimalist = minimal_output ) test . printer = terminal_printer with test : test . report ( output_directory ) Methods resume def resume ( self , run_id ) resumes a monitoring of a previously started test run View Source def resume ( self , run_id ) : # pylint : disable = no - self - use \"\"\" resumes a monitoring of a previously started test run \"\"\" # do some stuff raise NotImplementedError ()","title":"Test"},{"location":"reference/taskcat/_cli_modules/test.html#module-taskcat_cli_modulestest","text":"None None View Source # pylint: disable=duplicate-code # noqa: B950,F841 import inspect import logging from pathlib import Path import boto3 import yaml from taskcat._common_utils import determine_profile_for_region from taskcat._config import Config from taskcat._tui import TerminalPrinter from taskcat.testing import CFNTest from .delete import Delete from .list import List LOG = logging . getLogger ( __name__ ) class Test : \"\"\" Performs functional tests on CloudFormation templates. \"\"\" # pylint: disable=too-many-locals @staticmethod def retry ( region : str , stack_name : str , resource_name : str , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False , ): \"\"\"[ALPHA] re-launches a child stack using the same parameters as previous launch :param region: region stack is in :param stack_name: name of parent stack :param resource_name: logical id of child stack that will be re-launched :param config_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param keep_failed: do not delete failed stacks :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete \"\"\" LOG . warning ( \"test retry is in alpha feature, use with caution\" ) project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / config_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) profile = determine_profile_for_region ( config . config . general . auth , region ) cfn = boto3 . Session ( profile_name = profile ) . client ( \"cloudformation\" , region_name = region ) events = cfn . describe_stack_events ( StackName = stack_name )[ \"StackEvents\" ] resource = [ i for i in events if i [ \"LogicalResourceId\" ] == resource_name ][ 0 ] properties = yaml . safe_load ( resource [ \"ResourceProperties\" ]) with open ( str ( input_file_path ), \"r\" ) as filepointer : config_yaml = yaml . safe_load ( filepointer ) config_yaml [ \"project\" ][ \"regions\" ] = [ region ] config_yaml [ \"project\" ][ \"parameters\" ] = properties [ \"Parameters\" ] config_yaml [ \"project\" ][ \"template\" ] = \"/\" . join ( properties [ \"TemplateURL\" ] . split ( \"/\" )[ 4 :] ) config_yaml [ \"tests\" ] = { \"default\" : {}} with open ( \"/tmp/.taskcat.yml.temp\" , \"w\" ) as filepointer : # nosec yaml . safe_dump ( config_yaml , filepointer ) if resource [ \"PhysicalResourceId\" ]: cfn . delete_stack ( StackName = resource [ \"PhysicalResourceId\" ]) LOG . info ( \"waiting for old stack to delete...\" ) cfn . get_waiter ( \"stack_delete_complete\" ) . wait ( StackName = resource [ \"PhysicalResourceId\" ] ) Test . run ( input_file = \"/tmp/.taskcat.yml.temp\" , # nosec project_root = project_root , lint_disable = True , no_delete = no_delete , keep_failed = keep_failed , minimal_output = minimal_output , dont_wait_for_delete = dont_wait_for_delete , ) @staticmethod # pylint: disable=too-many-arguments,W0613,line-too-long def run ( # noqa: C901 test_names : str = \"ALL\" , regions : str = \"ALL\" , input_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = \"./taskcat_outputs\" , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False , ): \"\"\"tests whether CloudFormation templates are able to successfully launch :param test_names: comma separated list of tests to run :param regions: comma separated list of regions to test in :param input_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param lint_disable: disable cfn-lint checks :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param keep_failed: do not delete failed stacks :param output_directory: Where to store generated logfiles :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete :param skip_upload: Use templates in an existing cloudformation bucket. \"\"\" # noqa: B950 test = CFNTest . from_file ( project_root = project_root , input_file = input_file , regions = regions , enable_sig_v2 = enable_sig_v2 , ) # This code is temporary and should be removed once its easier # to create a config object frame = inspect . currentframe () if frame is not None : args , _ , _ , values = inspect . getargvalues ( frame ) for i in args : if hasattr ( test , i ): setattr ( test , i , values [ i ]) terminal_printer = TerminalPrinter ( minimalist = minimal_output ) test . printer = terminal_printer with test : test . report ( output_directory ) def resume ( self , run_id ): # pylint: disable=no-self-use \"\"\"resumes a monitoring of a previously started test run\"\"\" # do some stuff raise NotImplementedError () @staticmethod def list ( profiles : str = \"default\" , regions = \"ALL\" , _stack_type = \"package\" ): \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" List ( profiles = profiles , regions = regions , _stack_type = \"test\" ) @staticmethod def clean ( project : str , aws_profile : str = \"default\" , region = \"ALL\" ): \"\"\" :param project: project to delete, can be an name or uuid, or ALL to clean all tests :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will scan all regions \"\"\" if region == \"ALL\" : region_set : set = set () region_set = region_set . union ( # pylint: disable=duplicate-code set ( boto3 . Session ( profile_name = aws_profile ) . get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = [ region ] Delete ( package = project , aws_profile = aws_profile , region = regions , _stack_type = \"test\" )","title":"Module taskcat._cli_modules.test"},{"location":"reference/taskcat/_cli_modules/test.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/test.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/test.html#test","text":"class Test ( / , * args , ** kwargs ) View Source class Test : \"\"\" Performs functional tests on CloudFormation templates. \"\"\" # pylint : disable = too - many - locals @staticmethod def retry ( region : str , stack_name : str , resource_name : str , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False , ) : \"\"\"[ALPHA] re-launches a child stack using the same parameters as previous launch :param region: region stack is in :param stack_name: name of parent stack :param resource_name: logical id of child stack that will be re-launched :param config_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param keep_failed: do not delete failed stacks :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete \"\"\" LOG . warning ( \"test retry is in alpha feature, use with caution\" ) project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / config_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) profile = determine_profile_for_region ( config . config . general . auth , region ) cfn = boto3 . Session ( profile_name = profile ). client ( \"cloudformation\" , region_name = region ) events = cfn . describe_stack_events ( StackName = stack_name ) [ \"StackEvents\" ] resource = [ i for i in events if i[\"LogicalResourceId\" ] == resource_name ] [ 0 ] properties = yaml . safe_load ( resource [ \"ResourceProperties\" ] ) with open ( str ( input_file_path ), \"r\" ) as filepointer : config_yaml = yaml . safe_load ( filepointer ) config_yaml [ \"project\" ][ \"regions\" ] = [ region ] config_yaml [ \"project\" ][ \"parameters\" ] = properties [ \"Parameters\" ] config_yaml [ \"project\" ][ \"template\" ] = \"/\" . join ( properties [ \"TemplateURL\" ] . split ( \"/\" ) [ 4: ] ) config_yaml [ \"tests\" ] = { \"default\" : {}} with open ( \"/tmp/.taskcat.yml.temp\" , \"w\" ) as filepointer : # nosec yaml . safe_dump ( config_yaml , filepointer ) if resource [ \"PhysicalResourceId\" ] : cfn . delete_stack ( StackName = resource [ \"PhysicalResourceId\" ] ) LOG . info ( \"waiting for old stack to delete...\" ) cfn . get_waiter ( \"stack_delete_complete\" ). wait ( StackName = resource [ \"PhysicalResourceId\" ] ) Test . run ( input_file = \"/tmp/.taskcat.yml.temp\" , # nosec project_root = project_root , lint_disable = True , no_delete = no_delete , keep_failed = keep_failed , minimal_output = minimal_output , dont_wait_for_delete = dont_wait_for_delete , ) @staticmethod # pylint : disable = too - many - arguments , W0613 , line - too - long def run ( # noqa : C901 test_names : str = \"ALL\" , regions : str = \"ALL\" , input_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = \"./taskcat_outputs\" , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False , ) : \"\"\"tests whether CloudFormation templates are able to successfully launch :param test_names: comma separated list of tests to run :param regions: comma separated list of regions to test in :param input_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param lint_disable: disable cfn-lint checks :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param keep_failed: do not delete failed stacks :param output_directory: Where to store generated logfiles :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete :param skip_upload: Use templates in an existing cloudformation bucket. \"\"\" # noqa : B950 test = CFNTest . from_file ( project_root = project_root , input_file = input_file , regions = regions , enable_sig_v2 = enable_sig_v2 , ) # This code is temporary and should be removed once its easier # to create a config object frame = inspect . currentframe () if frame is not None : args , _ , _ , values = inspect . getargvalues ( frame ) for i in args : if hasattr ( test , i ) : setattr ( test , i , values [ i ] ) terminal_printer = TerminalPrinter ( minimalist = minimal_output ) test . printer = terminal_printer with test : test . report ( output_directory ) def resume ( self , run_id ) : # pylint : disable = no - self - use \"\"\"resumes a monitoring of a previously started test run\"\"\" # do some stuff raise NotImplementedError () @staticmethod def list ( profiles : str = \"default\" , regions = \"ALL\" , _stack_type = \"package\" ) : \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" List ( profiles = profiles , regions = regions , _stack_type = \"test\" ) @staticmethod def clean ( project : str , aws_profile : str = \"default\" , region = \"ALL\" ) : \"\"\" :param project: project to delete, can be an name or uuid, or ALL to clean all tests :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will scan all regions \"\"\" if region == \"ALL\" : region_set : set = set () region_set = region_set . union ( # pylint : disable = duplicate - code set ( boto3 . Session ( profile_name = aws_profile ). get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = [ region ] Delete ( package = project , aws_profile = aws_profile , region = regions , _stack_type = \"test\" )","title":"Test"},{"location":"reference/taskcat/_cli_modules/test.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/_cli_modules/test.html#clean","text":"def clean ( project : str , aws_profile : str = 'default' , region = 'ALL' ) Parameters: Name Type Description Default project None project to delete, can be an name or uuid, or ALL to clean all tests None aws_profile None aws profile to use for deletion None region None region to delete from, default will scan all regions None View Source @staticmethod def clean ( project : str , aws_profile : str = \"default\" , region = \"ALL\" ) : \"\"\" :param project: project to delete, can be an name or uuid, or ALL to clean all tests :param aws_profile: aws profile to use for deletion :param region: region to delete from, default will scan all regions \"\"\" if region == \"ALL\" : region_set : set = set () region_set = region_set . union ( # pylint : disable = duplicate - code set ( boto3 . Session ( profile_name = aws_profile ). get_available_regions ( \"cloudformation\" ) ) ) regions = list ( region_set ) else : regions = [ region ] Delete ( package = project , aws_profile = aws_profile , region = regions , _stack_type = \"test\" )","title":"clean"},{"location":"reference/taskcat/_cli_modules/test.html#list","text":"def list ( profiles : str = 'default' , regions = 'ALL' , _stack_type = 'package' ) Parameters: Name Type Description Default profiles None comma separated list of aws profiles to search None regions None comma separated list of regions to search, default is to check all commercial regions None View Source @staticmethod def list ( profiles : str = \"default\" , regions = \"ALL\" , _stack_type = \"package\" ) : \"\"\" :param profiles: comma separated list of aws profiles to search :param regions: comma separated list of regions to search, default is to check all commercial regions \"\"\" List ( profiles = profiles , regions = regions , _stack_type = \"test\" )","title":"list"},{"location":"reference/taskcat/_cli_modules/test.html#retry","text":"def retry ( region : str , stack_name : str , resource_name : str , config_file : str = './.taskcat.yml' , project_root : str = './' , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False ) [ALPHA] re-launches a child stack using the same parameters as previous launch Parameters: Name Type Description Default region None region stack is in None stack_name None name of parent stack None resource_name None logical id of child stack that will be re-launched None config_file None path to either a taskat project config file or a CloudFormation template None project_root None root path of the project relative to input_file None no_delete None don't delete stacks after test is complete None keep_failed None do not delete failed stacks None minimal_output None Reduces output during test runs None dont_wait_for_delete None Exits immediately after calling stack_delete None View Source @staticmethod def retry ( region : str , stack_name : str , resource_name : str , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , keep_failed : bool = False , minimal_output : bool = False , dont_wait_for_delete : bool = False , ) : \"\"\"[ALPHA] re-launches a child stack using the same parameters as previous launch :param region: region stack is in :param stack_name: name of parent stack :param resource_name: logical id of child stack that will be re-launched :param config_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param keep_failed: do not delete failed stacks :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete \"\"\" LOG . warning ( \"test retry is in alpha feature, use with caution\" ) project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / config_file config = Config . create ( project_root = project_root_path , project_config_path = input_file_path ) profile = determine_profile_for_region ( config . config . general . auth , region ) cfn = boto3 . Session ( profile_name = profile ). client ( \"cloudformation\" , region_name = region ) events = cfn . describe_stack_events ( StackName = stack_name ) [ \"StackEvents\" ] resource = [ i for i in events if i[\"LogicalResourceId\" ] == resource_name ] [ 0 ] properties = yaml . safe_load ( resource [ \"ResourceProperties\" ] ) with open ( str ( input_file_path ), \"r\" ) as filepointer : config_yaml = yaml . safe_load ( filepointer ) config_yaml [ \"project\" ][ \"regions\" ] = [ region ] config_yaml [ \"project\" ][ \"parameters\" ] = properties [ \"Parameters\" ] config_yaml [ \"project\" ][ \"template\" ] = \"/\" . join ( properties [ \"TemplateURL\" ] . split ( \"/\" ) [ 4: ] ) config_yaml [ \"tests\" ] = { \"default\" : {}} with open ( \"/tmp/.taskcat.yml.temp\" , \"w\" ) as filepointer : # nosec yaml . safe_dump ( config_yaml , filepointer ) if resource [ \"PhysicalResourceId\" ] : cfn . delete_stack ( StackName = resource [ \"PhysicalResourceId\" ] ) LOG . info ( \"waiting for old stack to delete...\" ) cfn . get_waiter ( \"stack_delete_complete\" ). wait ( StackName = resource [ \"PhysicalResourceId\" ] ) Test . run ( input_file = \"/tmp/.taskcat.yml.temp\" , # nosec project_root = project_root , lint_disable = True , no_delete = no_delete , keep_failed = keep_failed , minimal_output = minimal_output , dont_wait_for_delete = dont_wait_for_delete , )","title":"retry"},{"location":"reference/taskcat/_cli_modules/test.html#run","text":"def run ( test_names : str = 'ALL' , regions : str = 'ALL' , input_file : str = './.taskcat.yml' , project_root : str = './' , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = './taskcat_outputs' , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False ) tests whether CloudFormation templates are able to successfully launch Parameters: Name Type Description Default test_names None comma separated list of tests to run None regions None comma separated list of regions to test in None input_file None path to either a taskat project config file or a CloudFormation template None project_root None root path of the project relative to input_file None no_delete None don't delete stacks after test is complete None lint_disable None disable cfn-lint checks None enable_sig_v2 None enable legacy sigv2 requests for auto-created buckets None keep_failed None do not delete failed stacks None output_directory None Where to store generated logfiles None minimal_output None Reduces output during test runs None dont_wait_for_delete None Exits immediately after calling stack_delete None skip_upload None Use templates in an existing cloudformation bucket. None View Source @staticmethod # pylint : disable = too - many - arguments , W0613 , line - too - long def run ( # noqa : C901 test_names : str = \"ALL\" , regions : str = \"ALL\" , input_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , no_delete : bool = False , lint_disable : bool = False , enable_sig_v2 : bool = False , keep_failed : bool = False , output_directory : str = \"./taskcat_outputs\" , minimal_output : bool = False , dont_wait_for_delete : bool = False , skip_upload : bool = False , ) : \"\"\"tests whether CloudFormation templates are able to successfully launch :param test_names: comma separated list of tests to run :param regions: comma separated list of regions to test in :param input_file: path to either a taskat project config file or a CloudFormation template :param project_root: root path of the project relative to input_file :param no_delete: don't delete stacks after test is complete :param lint_disable: disable cfn-lint checks :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param keep_failed: do not delete failed stacks :param output_directory: Where to store generated logfiles :param minimal_output: Reduces output during test runs :param dont_wait_for_delete: Exits immediately after calling stack_delete :param skip_upload: Use templates in an existing cloudformation bucket. \"\"\" # noqa : B950 test = CFNTest . from_file ( project_root = project_root , input_file = input_file , regions = regions , enable_sig_v2 = enable_sig_v2 , ) # This code is temporary and should be removed once its easier # to create a config object frame = inspect . currentframe () if frame is not None : args , _ , _ , values = inspect . getargvalues ( frame ) for i in args : if hasattr ( test , i ) : setattr ( test , i , values [ i ] ) terminal_printer = TerminalPrinter ( minimalist = minimal_output ) test . printer = terminal_printer with test : test . report ( output_directory )","title":"run"},{"location":"reference/taskcat/_cli_modules/test.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/_cli_modules/test.html#resume","text":"def resume ( self , run_id ) resumes a monitoring of a previously started test run View Source def resume ( self , run_id ) : # pylint : disable = no - self - use \"\"\" resumes a monitoring of a previously started test run \"\"\" # do some stuff raise NotImplementedError ()","title":"resume"},{"location":"reference/taskcat/_cli_modules/update_ami.html","text":"Module taskcat._cli_modules.update_ami None None View Source import logging import os from pathlib import Path from taskcat._amiupdater import ( AMIUpdater , AMIUpdaterCommitNeededException , AMIUpdaterFatalException , ) from taskcat._common_utils import exit_with_code from taskcat._config import Config LOG = logging . getLogger ( __name__ ) class UpdateAMI : \"\"\" Updates AMI IDs within CloudFormation templates \"\"\" CLINAME = \"update-ami\" def __init__ ( self , project_root : str = \"./\" ): \"\"\" :param project_root: base path for project \"\"\" if project_root == \"./\" : _project_root = Path ( os . getcwd ()) else : _project_root = Path ( project_root ) config = Config . create ( project_root = _project_root , project_config_path = Path ( _project_root / \".taskcat.yml\" ), ) amiupdater = AMIUpdater ( config = config ) try : amiupdater . update_amis () except AMIUpdaterCommitNeededException : exit_with_code ( 100 ) except AMIUpdaterFatalException : exit_with_code ( 1 ) Variables LOG Classes UpdateAMI class UpdateAMI ( project_root : str = './' ) View Source class UpdateAMI: \"\"\" Updates AMI IDs within CloudFormation templates \"\"\" CLINAME = \"update-ami\" def __init__ ( self , project_root: str = \"./\" ): \"\"\" :param project_root: base path for project \"\"\" if project_root == \"./\" : _project_root = Path ( os . getcwd ()) else: _project_root = Path ( project_root ) config = Config . create ( project_root = _project_root , project_config_path = Path ( _project_root / \".taskcat.yml\" ), ) amiupdater = AMIUpdater ( config = config ) try: amiupdater . update_amis () except AMIUpdaterCommitNeededException: exit_with_code ( 100 ) except AMIUpdaterFatalException: exit_with_code ( 1 ) Class variables CLINAME","title":"Update Ami"},{"location":"reference/taskcat/_cli_modules/update_ami.html#module-taskcat_cli_modulesupdate_ami","text":"None None View Source import logging import os from pathlib import Path from taskcat._amiupdater import ( AMIUpdater , AMIUpdaterCommitNeededException , AMIUpdaterFatalException , ) from taskcat._common_utils import exit_with_code from taskcat._config import Config LOG = logging . getLogger ( __name__ ) class UpdateAMI : \"\"\" Updates AMI IDs within CloudFormation templates \"\"\" CLINAME = \"update-ami\" def __init__ ( self , project_root : str = \"./\" ): \"\"\" :param project_root: base path for project \"\"\" if project_root == \"./\" : _project_root = Path ( os . getcwd ()) else : _project_root = Path ( project_root ) config = Config . create ( project_root = _project_root , project_config_path = Path ( _project_root / \".taskcat.yml\" ), ) amiupdater = AMIUpdater ( config = config ) try : amiupdater . update_amis () except AMIUpdaterCommitNeededException : exit_with_code ( 100 ) except AMIUpdaterFatalException : exit_with_code ( 1 )","title":"Module taskcat._cli_modules.update_ami"},{"location":"reference/taskcat/_cli_modules/update_ami.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/update_ami.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/update_ami.html#updateami","text":"class UpdateAMI ( project_root : str = './' ) View Source class UpdateAMI: \"\"\" Updates AMI IDs within CloudFormation templates \"\"\" CLINAME = \"update-ami\" def __init__ ( self , project_root: str = \"./\" ): \"\"\" :param project_root: base path for project \"\"\" if project_root == \"./\" : _project_root = Path ( os . getcwd ()) else: _project_root = Path ( project_root ) config = Config . create ( project_root = _project_root , project_config_path = Path ( _project_root / \".taskcat.yml\" ), ) amiupdater = AMIUpdater ( config = config ) try: amiupdater . update_amis () except AMIUpdaterCommitNeededException: exit_with_code ( 100 ) except AMIUpdaterFatalException: exit_with_code ( 1 )","title":"UpdateAMI"},{"location":"reference/taskcat/_cli_modules/update_ami.html#class-variables","text":"CLINAME","title":"Class variables"},{"location":"reference/taskcat/_cli_modules/upload.html","text":"Module taskcat._cli_modules.upload None None View Source import logging from pathlib import Path from typing import Any , Dict from taskcat._cli_core import CliCore from taskcat._client_factory import Boto3Cache from taskcat._config import Config from taskcat._lambda_build import LambdaBuild from taskcat._s3_stage import stage_in_s3 LOG = logging . getLogger ( __name__ ) class Upload : \"\"\" Uploads project to S3. \"\"\" @CliCore . longform_param_required ( \"dry_run\" ) def __init__ ( self , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , enable_sig_v2 : bool = False , bucket_name : str = \"\" , disable_lambda_packaging : bool = False , key_prefix : str = \"\" , dry_run : bool = False , ): \"\"\"does lambda packaging and uploads to s3 :param config_file: path to taskat project config file :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param bucket_name: set bucket name instead of generating it. If regional buckets are enabled, will use this as a prefix :param disable_lambda_packaging: skip packaging step :param key_prefix: provide a custom key-prefix for uploading to S3. This will be used instead of `project` => `name` in the config :param dry_run: identify changes needed but do not upload to S3. \"\"\" project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / config_file args : Dict [ str , Any ] = { \"project\" : { \"s3_enable_sig_v2\" : enable_sig_v2 }} if bucket_name : args [ \"project\" ][ \"bucket_name\" ] = bucket_name if key_prefix : args [ \"project\" ][ \"name\" ] = key_prefix config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args , ) boto3_cache = Boto3Cache () if ( config . config . project . package_lambda and disable_lambda_packaging is not True ): LambdaBuild ( config , project_root_path ) buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , config . project_root , dry_run ) Variables LOG Classes Upload class Upload ( config_file : str = './.taskcat.yml' , project_root : str = './' , enable_sig_v2 : bool = False , bucket_name : str = '' , disable_lambda_packaging : bool = False , key_prefix : str = '' , dry_run : bool = False ) View Source class Upload : \" \"\" Uploads project to S3. \"\" \" @CliCore.longform_param_required ( \"dry_run\" ) def __init__ ( self , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , enable_sig_v2 : bool = False , bucket_name : str = \"\" , disable_lambda_packaging : bool = False , key_prefix : str = \"\" , dry_run : bool = False , ) : \" \"\" does lambda packaging and uploads to s3 :param config_file: path to taskat project config file :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param bucket_name: set bucket name instead of generating it. If regional buckets are enabled, will use this as a prefix :param disable_lambda_packaging: skip packaging step :param key_prefix: provide a custom key-prefix for uploading to S3. This will be used instead of `project` => `name` in the config :param dry_run: identify changes needed but do not upload to S3. \"\" \" project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / config_file args : Dict [ str , Any ] = { \"project\" : { \"s3_enable_sig_v2\" : enable_sig_v2 }} if bucket_name : args [ \"project\" ][ \"bucket_name\" ] = bucket_name if key_prefix : args [ \"project\" ][ \"name\" ] = key_prefix config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args , ) boto3_cache = Boto3Cache () if ( config . config . project . package_lambda and disable_lambda_packaging is not True ) : LambdaBuild ( config , project_root_path ) buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , config . project_root , dry_run )","title":"Upload"},{"location":"reference/taskcat/_cli_modules/upload.html#module-taskcat_cli_modulesupload","text":"None None View Source import logging from pathlib import Path from typing import Any , Dict from taskcat._cli_core import CliCore from taskcat._client_factory import Boto3Cache from taskcat._config import Config from taskcat._lambda_build import LambdaBuild from taskcat._s3_stage import stage_in_s3 LOG = logging . getLogger ( __name__ ) class Upload : \"\"\" Uploads project to S3. \"\"\" @CliCore . longform_param_required ( \"dry_run\" ) def __init__ ( self , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , enable_sig_v2 : bool = False , bucket_name : str = \"\" , disable_lambda_packaging : bool = False , key_prefix : str = \"\" , dry_run : bool = False , ): \"\"\"does lambda packaging and uploads to s3 :param config_file: path to taskat project config file :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param bucket_name: set bucket name instead of generating it. If regional buckets are enabled, will use this as a prefix :param disable_lambda_packaging: skip packaging step :param key_prefix: provide a custom key-prefix for uploading to S3. This will be used instead of `project` => `name` in the config :param dry_run: identify changes needed but do not upload to S3. \"\"\" project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / config_file args : Dict [ str , Any ] = { \"project\" : { \"s3_enable_sig_v2\" : enable_sig_v2 }} if bucket_name : args [ \"project\" ][ \"bucket_name\" ] = bucket_name if key_prefix : args [ \"project\" ][ \"name\" ] = key_prefix config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args , ) boto3_cache = Boto3Cache () if ( config . config . project . package_lambda and disable_lambda_packaging is not True ): LambdaBuild ( config , project_root_path ) buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , config . project_root , dry_run )","title":"Module taskcat._cli_modules.upload"},{"location":"reference/taskcat/_cli_modules/upload.html#variables","text":"LOG","title":"Variables"},{"location":"reference/taskcat/_cli_modules/upload.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/_cli_modules/upload.html#upload","text":"class Upload ( config_file : str = './.taskcat.yml' , project_root : str = './' , enable_sig_v2 : bool = False , bucket_name : str = '' , disable_lambda_packaging : bool = False , key_prefix : str = '' , dry_run : bool = False ) View Source class Upload : \" \"\" Uploads project to S3. \"\" \" @CliCore.longform_param_required ( \"dry_run\" ) def __init__ ( self , config_file : str = \"./.taskcat.yml\" , project_root : str = \"./\" , enable_sig_v2 : bool = False , bucket_name : str = \"\" , disable_lambda_packaging : bool = False , key_prefix : str = \"\" , dry_run : bool = False , ) : \" \"\" does lambda packaging and uploads to s3 :param config_file: path to taskat project config file :param enable_sig_v2: enable legacy sigv2 requests for auto-created buckets :param bucket_name: set bucket name instead of generating it. If regional buckets are enabled, will use this as a prefix :param disable_lambda_packaging: skip packaging step :param key_prefix: provide a custom key-prefix for uploading to S3. This will be used instead of `project` => `name` in the config :param dry_run: identify changes needed but do not upload to S3. \"\" \" project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / config_file args : Dict [ str , Any ] = { \"project\" : { \"s3_enable_sig_v2\" : enable_sig_v2 }} if bucket_name : args [ \"project\" ][ \"bucket_name\" ] = bucket_name if key_prefix : args [ \"project\" ][ \"name\" ] = key_prefix config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args , ) boto3_cache = Boto3Cache () if ( config . config . project . package_lambda and disable_lambda_packaging is not True ) : LambdaBuild ( config , project_root_path ) buckets = config . get_buckets ( boto3_cache ) stage_in_s3 ( buckets , config . config . project . name , config . project_root , dry_run )","title":"Upload"},{"location":"reference/taskcat/testing/index.html","text":"Module taskcat.testing None None View Source from ._cfn_test import CFNTest # noqa: F401 from ._lint_test import LintTest # noqa: F401 from ._unit_test import UnitTest # noqa: F401 __all__ = [ \"CFNTest\" ] Sub-modules taskcat.testing.base_test Classes CFNTest class CFNTest ( config : taskcat . _config . Config , printer : Union [ taskcat . _tui . TerminalPrinter , NoneType ] = None , test_names : str = 'ALL' , regions : str = 'ALL' , skip_upload : bool = False , lint_disable : bool = False , no_delete : bool = False , keep_failed : bool = False , dont_wait_for_delete : bool = True ) View Source class CFNTest ( BaseTest ): # pylint: disable=too-many-instance-attributes \"\"\" Tests Cloudformation template by making sure the stack can properly deploy in the specified regions. \"\"\" def __init__ ( self , config : Config , printer : Union [ TerminalPrinter , None ] = None , test_names : str = \"ALL\" , regions : str = \"ALL\" , skip_upload : bool = False , lint_disable : bool = False , no_delete : bool = False , keep_failed : bool = False , dont_wait_for_delete : bool = True , ): \"\"\"The constructor creates a test from the given Config object. Args: config (Config): A pre-configured Taskcat Config instance. printer (Union[TerminalPrinter, None], optional): A printer object that will handle Test output. Defaults to TerminalPrinter. test_names (str, optional): A comma separated list of tests to run. Defaults to \"ALL\". regions (str, optional): A comma separated list of regions to test in. Defaults to \"ALL\". skip_upload (bool, optional): Use templates in an existing cloudformation bucket. Defaults to False. lint_disable (bool, optional): Disable linting with cfn-lint. Defaults to False. no_delete (bool, optional): Don't delete stacks after test is complete. Defaults to False. keep_failed (bool, optional): Don't delete failed stacks. Defaults to False. dont_wait_for_delete (bool, optional): Exits immediately after calling stack_delete. Defaults to True. \"\"\" # noqa: B950 super () . __init__ ( config ) self . test_definition : Stacker self . test_names = test_names self . regions = regions self . skip_upload = skip_upload self . lint_disable = lint_disable self . no_delete = no_delete self . keep_failed = keep_failed self . dont_wait_for_delete = dont_wait_for_delete if printer is None : self . printer = TerminalPrinter ( minimalist = True ) else : self . printer = printer def run ( self ) -> None : \"\"\"Deploys the required Test resources in AWS. Raises: TaskCatException: If skip_upload is set without specifying s3_bucket in config. TaskCatException: If linting fails with errors. \"\"\" _trim_regions ( self . regions , self . config ) _trim_tests ( self . test_names , self . config ) boto3_cache = Boto3Cache () templates = self . config . get_templates () if self . skip_upload and not self . config . config . project . s3_bucket : raise TaskCatException ( \"cannot skip_buckets without specifying s3_bucket in config\" ) buckets = self . config . get_buckets ( boto3_cache ) if not self . skip_upload : # 1. lint if not self . lint_disable : lint = TaskCatLint ( self . config , templates ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed : raise TaskCatException ( \"Lint failed with errors\" ) # 2. build lambdas if self . config . config . project . package_lambda : LambdaBuild ( self . config , self . config . project_root ) # 3. s3 sync stage_in_s3 ( buckets , self . config . config . project . name , self . config . project_root ) regions = self . config . get_regions ( boto3_cache ) parameters = self . config . get_rendered_parameters ( buckets , regions , templates ) tests = self . config . get_tests ( templates , regions , buckets , parameters ) # pre-hooks execute_hooks ( \"prehooks\" , self . config , tests , parameters ) self . test_definition = Stacker ( self . config . config . project . name , tests , shorten_stack_name = self . config . config . project . shorten_stack_name , ) self . test_definition . create_stacks () # post-hooks # TODO: pass in outputs, once there is a standard interface for a test_definition execute_hooks ( \"posthooks\" , self . config , tests , parameters ) self . printer . report_test_progress ( stacker = self . test_definition ) self . passed = True self . result = self . test_definition . stacks def clean_up ( self ) -> None : # noqa: C901 \"\"\"Deletes the Test related resources in AWS. Raises: TaskCatException: If one or more stacks failed to create. \"\"\" if not hasattr ( self , \"test_definition\" ): LOG . warning ( \"No stacks were created... skipping cleanup.\" ) return status = self . test_definition . status () # Delete Stacks if self . no_delete : LOG . info ( \"Skipping delete due to cli argument\" ) elif self . keep_failed : if len ( status [ \"COMPLETE\" ]) > 0 : LOG . info ( \"deleting successful stacks\" ) self . test_definition . delete_stacks ({ \"status\" : \"CREATE_COMPLETE\" }) else : self . test_definition . delete_stacks () if not self . dont_wait_for_delete : self . printer . report_test_progress ( stacker = self . test_definition ) # TODO: summarise stack statusses (did they complete/delete ok) and print any # error events # Delete Templates and Buckets buckets = self . config . get_buckets () if not self . no_delete or ( self . keep_failed is True and len ( status [ \"FAILED\" ]) == 0 ): deleted : ListType [ str ] = [] for test in buckets . values (): for bucket in test . values (): if ( bucket . name not in deleted ) and not bucket . regional_buckets : bucket . delete ( delete_objects = True ) deleted . append ( bucket . name ) # 9. raise if something failed # - grabbing the status again to ensure everything deleted OK. status = self . test_definition . status () if len ( status [ \"FAILED\" ]) > 0 : raise TaskCatException ( f 'One or more stacks failed to create: {status[\"FAILED\"]}' ) def report ( self , output_directory : str = \"./taskcat_outputs\" , ): \"\"\"Generates a report of the status of Cloudformation stacks. Args: output_directory (str, optional): The directory to save the report in. Defaults to \"./taskcat_outputs\". \"\"\" # noqa: B950 report_path = Path ( output_directory ) . resolve () report_path . mkdir ( exist_ok = True ) cfn_logs = _CfnLogTools () cfn_logs . createcfnlogs ( self . test_definition , report_path ) ReportBuilder ( self . test_definition , report_path / \"index.html\" ) . generate_report () Ancestors (in MRO) taskcat.testing.base_test.BaseTest taskcat.testing._abstract_test.Test abc.ABC Static methods from_dict def from_dict ( input_config : dict , project_root : str = './' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat configuration in dictionary form. Parameters: Name Type Description Default input_config dict A Taskcat configuration in the form of a dict. None project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_dict ( cls : Type [ T ] , input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ {\"source\": \"Manual\", \"config\": input_config}, {\"source\": \"CliArgument\", \"config\": args}, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config ) from_file def from_file ( project_root : str = './' , input_file : str = './.taskcat.yml' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat config file. Parameters: Name Type Description Default project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" input_file str The name of the Taskcat confile file. Defaults to \"./.taskcat.yml\". \"./.taskcat.yml\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_file ( cls : Type [ T ] , project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". input_file (str, optional): The name of the Taskcat confile file. Defaults to \" . / . taskcat . yml \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / input_file # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO : detect if input file is taskcat config or CloudFormation template ) return cls ( config ) Instance variables config passed result Methods clean_up def clean_up ( self ) -> None Deletes the Test related resources in AWS. Raises: Type Description TaskCatException If one or more stacks failed to create. View Source def clean_up ( self ) -> None : # noqa : C901 \"\"\"Deletes the Test related resources in AWS. Raises: TaskCatException: If one or more stacks failed to create. \"\"\" if not hasattr ( self , \"test_definition\" ) : LOG . warning ( \"No stacks were created... skipping cleanup.\" ) return status = self . test_definition . status () # Delete Stacks if self . no_delete : LOG . info ( \"Skipping delete due to cli argument\" ) elif self . keep_failed : if len ( status [ \"COMPLETE\" ] ) > 0 : LOG . info ( \"deleting successful stacks\" ) self . test_definition . delete_stacks ( { \"status\" : \"CREATE_COMPLETE\" } ) else : self . test_definition . delete_stacks () if not self . dont_wait_for_delete : self . printer . report_test_progress ( stacker = self . test_definition ) # TODO : summarise stack statusses ( did they complete / delete ok ) and print any # error events # Delete Templates and Buckets buckets = self . config . get_buckets () if not self . no_delete or ( self . keep_failed is True and len ( status [ \"FAILED\" ] ) == 0 ) : deleted : ListType [ str ] = [] for test in buckets . values () : for bucket in test . values () : if ( bucket . name not in deleted ) and not bucket . regional_buckets : bucket . delete ( delete_objects = True ) deleted . append ( bucket . name ) # 9. raise if something failed # - grabbing the status again to ensure everything deleted OK . status = self . test_definition . status () if len ( status [ \"FAILED\" ] ) > 0 : raise TaskCatException ( f 'One or more stacks failed to create: {status[\"FAILED\"]}' ) report def report ( self , output_directory : str = './taskcat_outputs' ) Generates a report of the status of Cloudformation stacks. Parameters: Name Type Description Default output_directory str The directory to save the report in. Defaults to \"./taskcat_outputs\". \"./taskcat_outputs\" View Source def report( self, output_directory: str = \"./taskcat_outputs\", ): \"\"\"Generates a report of the status of Cloudformation stacks. Args: output_directory (str, optional): The directory to save the report in. Defaults to \"./taskcat_outputs\". \"\"\" # noqa: B950 report_path = Path(output_directory).resolve() report_path.mkdir(exist_ok=True) cfn_logs = _CfnLogTools() cfn_logs.createcfnlogs(self.test_definition, report_path) ReportBuilder( self.test_definition, report_path / \"index.html\" ).generate_report() run def run ( self ) -> None Deploys the required Test resources in AWS. Raises: Type Description TaskCatException If skip_upload is set without specifying s3_bucket in config. TaskCatException If linting fails with errors. View Source def run ( self ) -> None : \"\"\"Deploys the required Test resources in AWS. Raises: TaskCatException: If skip_upload is set without specifying s3_bucket in config. TaskCatException: If linting fails with errors. \"\"\" _trim_regions ( self . regions , self . config ) _trim_tests ( self . test_names , self . config ) boto3_cache = Boto3Cache () templates = self . config . get_templates () if self . skip_upload and not self . config . config . project . s3_bucket : raise TaskCatException ( \"cannot skip_buckets without specifying s3_bucket in config\" ) buckets = self . config . get_buckets ( boto3_cache ) if not self . skip_upload : # 1. lint if not self . lint_disable : lint = TaskCatLint ( self . config , templates ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed : raise TaskCatException ( \"Lint failed with errors\" ) # 2. build lambdas if self . config . config . project . package_lambda : LambdaBuild ( self . config , self . config . project_root ) # 3. s3 sync stage_in_s3 ( buckets , self . config . config . project . name , self . config . project_root ) regions = self . config . get_regions ( boto3_cache ) parameters = self . config . get_rendered_parameters ( buckets , regions , templates ) tests = self . config . get_tests ( templates , regions , buckets , parameters ) # pre-hooks execute_hooks ( \"prehooks\" , self . config , tests , parameters ) self . test_definition = Stacker ( self . config . config . project . name , tests , shorten_stack_name = self . config . config . project . shorten_stack_name , ) self . test_definition . create_stacks () # post-hooks # TODO: pass in outputs, once there is a standard interface for a test_definition execute_hooks ( \"posthooks\" , self . config , tests , parameters ) self . printer . report_test_progress ( stacker = self . test_definition ) self . passed = True self . result = self . test_definition . stacks","title":"Index"},{"location":"reference/taskcat/testing/index.html#module-taskcattesting","text":"None None View Source from ._cfn_test import CFNTest # noqa: F401 from ._lint_test import LintTest # noqa: F401 from ._unit_test import UnitTest # noqa: F401 __all__ = [ \"CFNTest\" ]","title":"Module taskcat.testing"},{"location":"reference/taskcat/testing/index.html#sub-modules","text":"taskcat.testing.base_test","title":"Sub-modules"},{"location":"reference/taskcat/testing/index.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/testing/index.html#cfntest","text":"class CFNTest ( config : taskcat . _config . Config , printer : Union [ taskcat . _tui . TerminalPrinter , NoneType ] = None , test_names : str = 'ALL' , regions : str = 'ALL' , skip_upload : bool = False , lint_disable : bool = False , no_delete : bool = False , keep_failed : bool = False , dont_wait_for_delete : bool = True ) View Source class CFNTest ( BaseTest ): # pylint: disable=too-many-instance-attributes \"\"\" Tests Cloudformation template by making sure the stack can properly deploy in the specified regions. \"\"\" def __init__ ( self , config : Config , printer : Union [ TerminalPrinter , None ] = None , test_names : str = \"ALL\" , regions : str = \"ALL\" , skip_upload : bool = False , lint_disable : bool = False , no_delete : bool = False , keep_failed : bool = False , dont_wait_for_delete : bool = True , ): \"\"\"The constructor creates a test from the given Config object. Args: config (Config): A pre-configured Taskcat Config instance. printer (Union[TerminalPrinter, None], optional): A printer object that will handle Test output. Defaults to TerminalPrinter. test_names (str, optional): A comma separated list of tests to run. Defaults to \"ALL\". regions (str, optional): A comma separated list of regions to test in. Defaults to \"ALL\". skip_upload (bool, optional): Use templates in an existing cloudformation bucket. Defaults to False. lint_disable (bool, optional): Disable linting with cfn-lint. Defaults to False. no_delete (bool, optional): Don't delete stacks after test is complete. Defaults to False. keep_failed (bool, optional): Don't delete failed stacks. Defaults to False. dont_wait_for_delete (bool, optional): Exits immediately after calling stack_delete. Defaults to True. \"\"\" # noqa: B950 super () . __init__ ( config ) self . test_definition : Stacker self . test_names = test_names self . regions = regions self . skip_upload = skip_upload self . lint_disable = lint_disable self . no_delete = no_delete self . keep_failed = keep_failed self . dont_wait_for_delete = dont_wait_for_delete if printer is None : self . printer = TerminalPrinter ( minimalist = True ) else : self . printer = printer def run ( self ) -> None : \"\"\"Deploys the required Test resources in AWS. Raises: TaskCatException: If skip_upload is set without specifying s3_bucket in config. TaskCatException: If linting fails with errors. \"\"\" _trim_regions ( self . regions , self . config ) _trim_tests ( self . test_names , self . config ) boto3_cache = Boto3Cache () templates = self . config . get_templates () if self . skip_upload and not self . config . config . project . s3_bucket : raise TaskCatException ( \"cannot skip_buckets without specifying s3_bucket in config\" ) buckets = self . config . get_buckets ( boto3_cache ) if not self . skip_upload : # 1. lint if not self . lint_disable : lint = TaskCatLint ( self . config , templates ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed : raise TaskCatException ( \"Lint failed with errors\" ) # 2. build lambdas if self . config . config . project . package_lambda : LambdaBuild ( self . config , self . config . project_root ) # 3. s3 sync stage_in_s3 ( buckets , self . config . config . project . name , self . config . project_root ) regions = self . config . get_regions ( boto3_cache ) parameters = self . config . get_rendered_parameters ( buckets , regions , templates ) tests = self . config . get_tests ( templates , regions , buckets , parameters ) # pre-hooks execute_hooks ( \"prehooks\" , self . config , tests , parameters ) self . test_definition = Stacker ( self . config . config . project . name , tests , shorten_stack_name = self . config . config . project . shorten_stack_name , ) self . test_definition . create_stacks () # post-hooks # TODO: pass in outputs, once there is a standard interface for a test_definition execute_hooks ( \"posthooks\" , self . config , tests , parameters ) self . printer . report_test_progress ( stacker = self . test_definition ) self . passed = True self . result = self . test_definition . stacks def clean_up ( self ) -> None : # noqa: C901 \"\"\"Deletes the Test related resources in AWS. Raises: TaskCatException: If one or more stacks failed to create. \"\"\" if not hasattr ( self , \"test_definition\" ): LOG . warning ( \"No stacks were created... skipping cleanup.\" ) return status = self . test_definition . status () # Delete Stacks if self . no_delete : LOG . info ( \"Skipping delete due to cli argument\" ) elif self . keep_failed : if len ( status [ \"COMPLETE\" ]) > 0 : LOG . info ( \"deleting successful stacks\" ) self . test_definition . delete_stacks ({ \"status\" : \"CREATE_COMPLETE\" }) else : self . test_definition . delete_stacks () if not self . dont_wait_for_delete : self . printer . report_test_progress ( stacker = self . test_definition ) # TODO: summarise stack statusses (did they complete/delete ok) and print any # error events # Delete Templates and Buckets buckets = self . config . get_buckets () if not self . no_delete or ( self . keep_failed is True and len ( status [ \"FAILED\" ]) == 0 ): deleted : ListType [ str ] = [] for test in buckets . values (): for bucket in test . values (): if ( bucket . name not in deleted ) and not bucket . regional_buckets : bucket . delete ( delete_objects = True ) deleted . append ( bucket . name ) # 9. raise if something failed # - grabbing the status again to ensure everything deleted OK. status = self . test_definition . status () if len ( status [ \"FAILED\" ]) > 0 : raise TaskCatException ( f 'One or more stacks failed to create: {status[\"FAILED\"]}' ) def report ( self , output_directory : str = \"./taskcat_outputs\" , ): \"\"\"Generates a report of the status of Cloudformation stacks. Args: output_directory (str, optional): The directory to save the report in. Defaults to \"./taskcat_outputs\". \"\"\" # noqa: B950 report_path = Path ( output_directory ) . resolve () report_path . mkdir ( exist_ok = True ) cfn_logs = _CfnLogTools () cfn_logs . createcfnlogs ( self . test_definition , report_path ) ReportBuilder ( self . test_definition , report_path / \"index.html\" ) . generate_report ()","title":"CFNTest"},{"location":"reference/taskcat/testing/index.html#ancestors-in-mro","text":"taskcat.testing.base_test.BaseTest taskcat.testing._abstract_test.Test abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/testing/index.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/testing/index.html#from_dict","text":"def from_dict ( input_config : dict , project_root : str = './' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat configuration in dictionary form. Parameters: Name Type Description Default input_config dict A Taskcat configuration in the form of a dict. None project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_dict ( cls : Type [ T ] , input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ {\"source\": \"Manual\", \"config\": input_config}, {\"source\": \"CliArgument\", \"config\": args}, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config )","title":"from_dict"},{"location":"reference/taskcat/testing/index.html#from_file","text":"def from_file ( project_root : str = './' , input_file : str = './.taskcat.yml' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat config file. Parameters: Name Type Description Default project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" input_file str The name of the Taskcat confile file. Defaults to \"./.taskcat.yml\". \"./.taskcat.yml\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_file ( cls : Type [ T ] , project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". input_file (str, optional): The name of the Taskcat confile file. Defaults to \" . / . taskcat . yml \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / input_file # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO : detect if input file is taskcat config or CloudFormation template ) return cls ( config )","title":"from_file"},{"location":"reference/taskcat/testing/index.html#instance-variables","text":"config passed result","title":"Instance variables"},{"location":"reference/taskcat/testing/index.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/testing/index.html#clean_up","text":"def clean_up ( self ) -> None Deletes the Test related resources in AWS. Raises: Type Description TaskCatException If one or more stacks failed to create. View Source def clean_up ( self ) -> None : # noqa : C901 \"\"\"Deletes the Test related resources in AWS. Raises: TaskCatException: If one or more stacks failed to create. \"\"\" if not hasattr ( self , \"test_definition\" ) : LOG . warning ( \"No stacks were created... skipping cleanup.\" ) return status = self . test_definition . status () # Delete Stacks if self . no_delete : LOG . info ( \"Skipping delete due to cli argument\" ) elif self . keep_failed : if len ( status [ \"COMPLETE\" ] ) > 0 : LOG . info ( \"deleting successful stacks\" ) self . test_definition . delete_stacks ( { \"status\" : \"CREATE_COMPLETE\" } ) else : self . test_definition . delete_stacks () if not self . dont_wait_for_delete : self . printer . report_test_progress ( stacker = self . test_definition ) # TODO : summarise stack statusses ( did they complete / delete ok ) and print any # error events # Delete Templates and Buckets buckets = self . config . get_buckets () if not self . no_delete or ( self . keep_failed is True and len ( status [ \"FAILED\" ] ) == 0 ) : deleted : ListType [ str ] = [] for test in buckets . values () : for bucket in test . values () : if ( bucket . name not in deleted ) and not bucket . regional_buckets : bucket . delete ( delete_objects = True ) deleted . append ( bucket . name ) # 9. raise if something failed # - grabbing the status again to ensure everything deleted OK . status = self . test_definition . status () if len ( status [ \"FAILED\" ] ) > 0 : raise TaskCatException ( f 'One or more stacks failed to create: {status[\"FAILED\"]}' )","title":"clean_up"},{"location":"reference/taskcat/testing/index.html#report","text":"def report ( self , output_directory : str = './taskcat_outputs' ) Generates a report of the status of Cloudformation stacks. Parameters: Name Type Description Default output_directory str The directory to save the report in. Defaults to \"./taskcat_outputs\". \"./taskcat_outputs\" View Source def report( self, output_directory: str = \"./taskcat_outputs\", ): \"\"\"Generates a report of the status of Cloudformation stacks. Args: output_directory (str, optional): The directory to save the report in. Defaults to \"./taskcat_outputs\". \"\"\" # noqa: B950 report_path = Path(output_directory).resolve() report_path.mkdir(exist_ok=True) cfn_logs = _CfnLogTools() cfn_logs.createcfnlogs(self.test_definition, report_path) ReportBuilder( self.test_definition, report_path / \"index.html\" ).generate_report()","title":"report"},{"location":"reference/taskcat/testing/index.html#run","text":"def run ( self ) -> None Deploys the required Test resources in AWS. Raises: Type Description TaskCatException If skip_upload is set without specifying s3_bucket in config. TaskCatException If linting fails with errors. View Source def run ( self ) -> None : \"\"\"Deploys the required Test resources in AWS. Raises: TaskCatException: If skip_upload is set without specifying s3_bucket in config. TaskCatException: If linting fails with errors. \"\"\" _trim_regions ( self . regions , self . config ) _trim_tests ( self . test_names , self . config ) boto3_cache = Boto3Cache () templates = self . config . get_templates () if self . skip_upload and not self . config . config . project . s3_bucket : raise TaskCatException ( \"cannot skip_buckets without specifying s3_bucket in config\" ) buckets = self . config . get_buckets ( boto3_cache ) if not self . skip_upload : # 1. lint if not self . lint_disable : lint = TaskCatLint ( self . config , templates ) errors = lint . lints [ 1 ] lint . output_results () if errors or not lint . passed : raise TaskCatException ( \"Lint failed with errors\" ) # 2. build lambdas if self . config . config . project . package_lambda : LambdaBuild ( self . config , self . config . project_root ) # 3. s3 sync stage_in_s3 ( buckets , self . config . config . project . name , self . config . project_root ) regions = self . config . get_regions ( boto3_cache ) parameters = self . config . get_rendered_parameters ( buckets , regions , templates ) tests = self . config . get_tests ( templates , regions , buckets , parameters ) # pre-hooks execute_hooks ( \"prehooks\" , self . config , tests , parameters ) self . test_definition = Stacker ( self . config . config . project . name , tests , shorten_stack_name = self . config . config . project . shorten_stack_name , ) self . test_definition . create_stacks () # post-hooks # TODO: pass in outputs, once there is a standard interface for a test_definition execute_hooks ( \"posthooks\" , self . config , tests , parameters ) self . printer . report_test_progress ( stacker = self . test_definition ) self . passed = True self . result = self . test_definition . stacks","title":"run"},{"location":"reference/taskcat/testing/base_test.html","text":"Module taskcat.testing.base_test None None View Source # pylint: disable=line-too-long import uuid from pathlib import Path from typing import Any , Dict , Type , TypeVar from taskcat._cli_core import GLOBAL_ARGS from taskcat._config import Config from ._abstract_test import Test T = TypeVar ( \"T\" , bound = \"BaseTest\" ) # pylint: disable=invalid-name class BaseTest ( Test ): \"\"\"A Generic Test Class that implements the passed and uid properties. Any subclass will still need to implement the the run and clean_up methods. \"\"\" def __init__ ( self , config : Config ): self . config : Config = config self . passed : bool = False self . result : Any = None @property def config ( self ) -> Config : return self . _config @config . setter def config ( self , config : Config ) -> None : # It should be possible to check if config is already set # and if it is throw an exception. Might be needed since # child objects rely on the configs uid. self . _config = config @property def passed ( self ) -> bool : return self . _passed @passed . setter def passed ( self , new_value : bool ) -> None : self . _passed = new_value @property def result ( self ) -> Any : return self . _result @result . setter def result ( self , new_value : Any ) -> None : self . _result = new_value def __enter__ ( self ): try : self . run () except BaseException as ex : self . clean_up () raise ex return self . result def __exit__ ( self , exc_type , exc_val , exc_tb ): # we could optionally call self.report() on exiting. self . clean_up () @classmethod def from_file ( cls : Type [ T ], project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \"./\". input_file (str, optional): The name of the Taskcat confile file. Defaults to \"./.taskcat.yml\". regions (str, optional): A comma separated list of regions to test in. Defaults to \"ALL\". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa: B950 project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / input_file # pylint: disable=too-many-arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO: detect if input file is taskcat config or CloudFormation template ) return cls ( config ) @classmethod def from_dict ( cls : Type [ T ], input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \"./\". regions (str, optional): A comma separated list of regions to test in. Defaults to \"ALL\". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa: B950 project_root_path : Path = Path ( project_root ) . expanduser () . resolve () # pylint: disable=too-many-arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ { \"source\" : \"Manual\" , \"config\" : input_config }, { \"source\" : \"CliArgument\" , \"config\" : args }, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config ) def _build_args ( enable_sig_v2 , regions , default_profile ): args : Dict [ str , Any ] = {} if enable_sig_v2 : args [ \"project\" ] = { \"s3_enable_sig_v2\" : enable_sig_v2 } if regions != \"ALL\" : if \"project\" not in args : args [ \"project\" ] = {} args [ \"project\" ][ \"regions\" ] = regions . split ( \",\" ) if default_profile : _auth_dict = { \"default\" : default_profile } if not args . get ( \"project\" ): args [ \"project\" ] = { \"auth\" : _auth_dict } else : args [ \"project\" ][ \"auth\" ] = _auth_dict return args Variables T Classes BaseTest class BaseTest ( config : taskcat . _config . Config ) View Source class BaseTest ( Test ) : \"\"\"A Generic Test Class that implements the passed and uid properties. Any subclass will still need to implement the the run and clean_up methods. \"\"\" def __init__ ( self , config : Config ) : self . config : Config = config self . passed : bool = False self . result : Any = None @property def config ( self ) -> Config : return self . _config @config . setter def config ( self , config : Config ) -> None : # It should be possible to check if config is already set # and if it is throw an exception . Might be needed since # child objects rely on the configs uid . self . _config = config @property def passed ( self ) -> bool : return self . _passed @passed . setter def passed ( self , new_value : bool ) -> None : self . _passed = new_value @property def result ( self ) -> Any : return self . _result @result . setter def result ( self , new_value : Any ) -> None : self . _result = new_value def __enter__ ( self ) : try : self . run () except BaseException as ex : self . clean_up () raise ex return self . result def __exit__ ( self , exc_type , exc_val , exc_tb ) : # we could optionally call self . report () on exiting . self . clean_up () @classmethod def from_file ( cls : Type [ T ] , project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". input_file (str, optional): The name of the Taskcat confile file. Defaults to \" . / . taskcat . yml \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / input_file # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO : detect if input file is taskcat config or CloudFormation template ) return cls ( config ) @classmethod def from_dict ( cls : Type [ T ] , input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ {\"source\": \"Manual\", \"config\": input_config}, {\"source\": \"CliArgument\", \"config\": args}, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config ) Ancestors (in MRO) taskcat.testing._abstract_test.Test abc.ABC Descendants taskcat.testing._cfn_test.CFNTest taskcat.testing._lint_test.LintTest taskcat.testing._unit_test.UnitTest Static methods from_dict def from_dict ( input_config : dict , project_root : str = './' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat configuration in dictionary form. Parameters: Name Type Description Default input_config dict A Taskcat configuration in the form of a dict. None project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_dict ( cls : Type [ T ] , input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ {\"source\": \"Manual\", \"config\": input_config}, {\"source\": \"CliArgument\", \"config\": args}, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config ) from_file def from_file ( project_root : str = './' , input_file : str = './.taskcat.yml' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat config file. Parameters: Name Type Description Default project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" input_file str The name of the Taskcat confile file. Defaults to \"./.taskcat.yml\". \"./.taskcat.yml\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_file ( cls : Type [ T ] , project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". input_file (str, optional): The name of the Taskcat confile file. Defaults to \" . / . taskcat . yml \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / input_file # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO : detect if input file is taskcat config or CloudFormation template ) return cls ( config ) Instance variables config passed result Methods clean_up def clean_up ( self ) -> None Clean up after the Test. View Source @abstractmethod def clean_up ( self ) -> None : \"\"\"Clean up after the Test.\"\"\" run def run ( self ) -> None Run the Test. View Source @abstractmethod def run ( self ) -> None : \"\"\"Run the Test.\"\"\"","title":"Base Test"},{"location":"reference/taskcat/testing/base_test.html#module-taskcattestingbase_test","text":"None None View Source # pylint: disable=line-too-long import uuid from pathlib import Path from typing import Any , Dict , Type , TypeVar from taskcat._cli_core import GLOBAL_ARGS from taskcat._config import Config from ._abstract_test import Test T = TypeVar ( \"T\" , bound = \"BaseTest\" ) # pylint: disable=invalid-name class BaseTest ( Test ): \"\"\"A Generic Test Class that implements the passed and uid properties. Any subclass will still need to implement the the run and clean_up methods. \"\"\" def __init__ ( self , config : Config ): self . config : Config = config self . passed : bool = False self . result : Any = None @property def config ( self ) -> Config : return self . _config @config . setter def config ( self , config : Config ) -> None : # It should be possible to check if config is already set # and if it is throw an exception. Might be needed since # child objects rely on the configs uid. self . _config = config @property def passed ( self ) -> bool : return self . _passed @passed . setter def passed ( self , new_value : bool ) -> None : self . _passed = new_value @property def result ( self ) -> Any : return self . _result @result . setter def result ( self , new_value : Any ) -> None : self . _result = new_value def __enter__ ( self ): try : self . run () except BaseException as ex : self . clean_up () raise ex return self . result def __exit__ ( self , exc_type , exc_val , exc_tb ): # we could optionally call self.report() on exiting. self . clean_up () @classmethod def from_file ( cls : Type [ T ], project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \"./\". input_file (str, optional): The name of the Taskcat confile file. Defaults to \"./.taskcat.yml\". regions (str, optional): A comma separated list of regions to test in. Defaults to \"ALL\". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa: B950 project_root_path : Path = Path ( project_root ) . expanduser () . resolve () input_file_path : Path = project_root_path / input_file # pylint: disable=too-many-arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO: detect if input file is taskcat config or CloudFormation template ) return cls ( config ) @classmethod def from_dict ( cls : Type [ T ], input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \"./\". regions (str, optional): A comma separated list of regions to test in. Defaults to \"ALL\". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa: B950 project_root_path : Path = Path ( project_root ) . expanduser () . resolve () # pylint: disable=too-many-arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ { \"source\" : \"Manual\" , \"config\" : input_config }, { \"source\" : \"CliArgument\" , \"config\" : args }, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config ) def _build_args ( enable_sig_v2 , regions , default_profile ): args : Dict [ str , Any ] = {} if enable_sig_v2 : args [ \"project\" ] = { \"s3_enable_sig_v2\" : enable_sig_v2 } if regions != \"ALL\" : if \"project\" not in args : args [ \"project\" ] = {} args [ \"project\" ][ \"regions\" ] = regions . split ( \",\" ) if default_profile : _auth_dict = { \"default\" : default_profile } if not args . get ( \"project\" ): args [ \"project\" ] = { \"auth\" : _auth_dict } else : args [ \"project\" ][ \"auth\" ] = _auth_dict return args","title":"Module taskcat.testing.base_test"},{"location":"reference/taskcat/testing/base_test.html#variables","text":"T","title":"Variables"},{"location":"reference/taskcat/testing/base_test.html#classes","text":"","title":"Classes"},{"location":"reference/taskcat/testing/base_test.html#basetest","text":"class BaseTest ( config : taskcat . _config . Config ) View Source class BaseTest ( Test ) : \"\"\"A Generic Test Class that implements the passed and uid properties. Any subclass will still need to implement the the run and clean_up methods. \"\"\" def __init__ ( self , config : Config ) : self . config : Config = config self . passed : bool = False self . result : Any = None @property def config ( self ) -> Config : return self . _config @config . setter def config ( self , config : Config ) -> None : # It should be possible to check if config is already set # and if it is throw an exception . Might be needed since # child objects rely on the configs uid . self . _config = config @property def passed ( self ) -> bool : return self . _passed @passed . setter def passed ( self , new_value : bool ) -> None : self . _passed = new_value @property def result ( self ) -> Any : return self . _result @result . setter def result ( self , new_value : Any ) -> None : self . _result = new_value def __enter__ ( self ) : try : self . run () except BaseException as ex : self . clean_up () raise ex return self . result def __exit__ ( self , exc_type , exc_val , exc_tb ) : # we could optionally call self . report () on exiting . self . clean_up () @classmethod def from_file ( cls : Type [ T ] , project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". input_file (str, optional): The name of the Taskcat confile file. Defaults to \" . / . taskcat . yml \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / input_file # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO : detect if input file is taskcat config or CloudFormation template ) return cls ( config ) @classmethod def from_dict ( cls : Type [ T ] , input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ {\"source\": \"Manual\", \"config\": input_config}, {\"source\": \"CliArgument\", \"config\": args}, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config )","title":"BaseTest"},{"location":"reference/taskcat/testing/base_test.html#ancestors-in-mro","text":"taskcat.testing._abstract_test.Test abc.ABC","title":"Ancestors (in MRO)"},{"location":"reference/taskcat/testing/base_test.html#descendants","text":"taskcat.testing._cfn_test.CFNTest taskcat.testing._lint_test.LintTest taskcat.testing._unit_test.UnitTest","title":"Descendants"},{"location":"reference/taskcat/testing/base_test.html#static-methods","text":"","title":"Static methods"},{"location":"reference/taskcat/testing/base_test.html#from_dict","text":"def from_dict ( input_config : dict , project_root : str = './' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat configuration in dictionary form. Parameters: Name Type Description Default input_config dict A Taskcat configuration in the form of a dict. None project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_dict ( cls : Type [ T ] , input_config : dict , project_root : str = \"./\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat configuration in dictionary form. Args: input_config (dict): A Taskcat configuration in the form of a dict. project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) sources = [ {\"source\": \"Manual\", \"config\": input_config}, {\"source\": \"CliArgument\", \"config\": args}, ] config = Config ( uid = uuid . uuid4 (), project_root = project_root_path , sources = sources ) return cls ( config )","title":"from_dict"},{"location":"reference/taskcat/testing/base_test.html#from_file","text":"def from_file ( project_root : str = './' , input_file : str = './.taskcat.yml' , regions : str = 'ALL' , enable_sig_v2 : bool = False ) -> ~ T Creates a Test from a Taskcat config file. Parameters: Name Type Description Default project_root str The path to the directory with your template and config file. Defaults to \"./\". \"./\" input_file str The name of the Taskcat confile file. Defaults to \"./.taskcat.yml\". \"./.taskcat.yml\" regions str A comma separated list of regions to test in. Defaults to \"ALL\". \"ALL\" enable_sig_v2 bool Enable legacy sigv2 requests for auto-created buckets. Defaults to False. False Returns: Type Description T Returns a Test instance. View Source @classmethod def from_file ( cls : Type [ T ] , project_root : str = \"./\" , input_file : str = \"./.taskcat.yml\" , regions : str = \"ALL\" , enable_sig_v2 : bool = False , ) -> T : \"\"\"Creates a Test from a Taskcat config file. Args: project_root (str, optional): The path to the directory with your template and config file. Defaults to \" . / \". input_file (str, optional): The name of the Taskcat confile file. Defaults to \" . / . taskcat . yml \". regions (str, optional): A comma separated list of regions to test in. Defaults to \" ALL \". enable_sig_v2 (bool, optional): Enable legacy sigv2 requests for auto-created buckets. Defaults to False. Returns: T: Returns a Test instance. \"\"\" # noqa : B950 project_root_path : Path = Path ( project_root ). expanduser (). resolve () input_file_path : Path = project_root_path / input_file # pylint : disable = too - many - arguments args = _build_args ( enable_sig_v2 , regions , GLOBAL_ARGS . profile ) config = Config . create ( project_root = project_root_path , project_config_path = input_file_path , args = args # TODO : detect if input file is taskcat config or CloudFormation template ) return cls ( config )","title":"from_file"},{"location":"reference/taskcat/testing/base_test.html#instance-variables","text":"config passed result","title":"Instance variables"},{"location":"reference/taskcat/testing/base_test.html#methods","text":"","title":"Methods"},{"location":"reference/taskcat/testing/base_test.html#clean_up","text":"def clean_up ( self ) -> None Clean up after the Test. View Source @abstractmethod def clean_up ( self ) -> None : \"\"\"Clean up after the Test.\"\"\"","title":"clean_up"},{"location":"reference/taskcat/testing/base_test.html#run","text":"def run ( self ) -> None Run the Test. View Source @abstractmethod def run ( self ) -> None : \"\"\"Run the Test.\"\"\"","title":"run"}]}